{"meta":{"title":"Lishuai's博客","subtitle":null,"description":"承载着太多希望，怎敢轻易辜负","author":"李帅","url":"http://yoursite.com"},"pages":[{"title":"关于博主","date":"2018-02-24T11:36:41.000Z","updated":"2018-02-24T12:46:34.022Z","comments":false,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"博主是一个正在努力进步的小菜，欢迎大家一起来交流学习！"},{"title":"分类","date":"2018-02-24T11:38:30.000Z","updated":"2018-02-24T12:44:22.899Z","comments":false,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2018-02-24T11:37:58.000Z","updated":"2018-02-24T12:45:30.238Z","comments":false,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"ARP协议","slug":"ARP协议","date":"2018-05-17T07:55:10.000Z","updated":"2018-05-17T12:34:42.519Z","comments":true,"path":"2018/05/17/ARP协议/","link":"","permalink":"http://yoursite.com/2018/05/17/ARP协议/","excerpt":"","text":"地址解析协议ARP的简介作用 如果一台主机要将一个帧发送到另一台主机, 仅知道这台主机的I P 地址是不够的, 还需要知道主机在网络中的有效硬件地址。操作系统软件( 即以太网驱动程序) 必须知道目的主机的硬件地址, 以便直接向它发送数据。对于T C P / I P 网络,地址解析协议( A R P ) [ R F C O 8 2 6 ] 提供了一种在I P v 4 地址和各种网络技术使用的硬件地址之间的映射。 地址解析是发现两个地址之间的映射关系的过程。对于使用I P v 4 的T C P / I P 协议族, 这是由运行的A R P 来实现的o A R P 是一个通用的协议, 从这个意义上来看, 它被设计为支持多种地址之间的映射。实际上, A R P 几乎总是用于3 2 位I P v 4 地址和以太网的4 8 位M A C地址之间的映射。 A R P 提供从网络层地址到相关硬件地址的动态映射。我们使用动态这个术语是因为它会自动执行和随时间变化, 而不需要系统管理员重新配置。也就是说, 如果一台主机改变它的网络接日卡, 从而改变了它的硬件地址( 但保留其分配的I P 地址) , A R P 可以在一定延时后继续正常运作o A R P 操作通常与用户或系统管理员无关 层次 由于IP协议使用了ARP协议，因此通常就把ARP协议划归网络层。但是ARP协议的用途是为了从网络层使用的IP地址解析出在数据链路层使用的硬件地址。因为有的时候按照协议所用将其划分在链路层，这样做当然也是可以的。 ARP分层的位置是TCP/IP的网络层 ARP报文是由以太网帧进行封装传输的。没有封装进IP包。 实际上，对网络接口层的以太网帧来讲，它们同样是帧的上层协议，当收到以太帧时，根据帧的协议字段判断是送到ARP还是IP。 之所以不把它放在数据链路层，是因为它并不具备数据链路层的功能，它的作用是为数据链路层提供接收方的帧地地址 ARP缓存 A R P 高效运行的关键是维护每个主机和路由器上的A R P 缓存( 或表) 。该缓存使用地址解析为每个接日维护从网络层地址到硬件地址的最新映射。当I P v 4 地址映射到硬件地址时, 它对应于高速缓存中的一个条目,这个映射表会经常的动态更新（新增或者超时删除），一般存储时间是20分钟左右，这种机制是很重要的。因为某个电脑的网络适配器坏了，那么意味着他就要换一个新的网络适配器，即有一个新的MAC地址，但是可能他的IP并不变，所以我们需要随时更新ARP缓存表中的内容，保存最新的实时映射状态。 我们使用arp-a命令查看ARP缓存的条目时可以看见动态的和静态的类型。那么什么是动态的，什么是静态的呢？ 动态条目：表示动态获取到的条目 静态条目：表示手动配置的条目https://blog.csdn.net/daxueba/article/details/44956123 一次ARP的执行过程 这里的例子是同一个局域网中的 当主机A要向本局域网上的主机B发送IP数据报的时候(需要将逻辑地址转换为物理地址的，不然的话发送不出去的)，首先在其ARP缓存中查看有无主机B的ip地址。如果有则根据映射关系找到对应的主机B的MAC地址，将这个MAC地址直接写入数据帧。通过局域网将此数据报发送给主机B。 如果没有在ARP缓存中没有查询到主机B的IP地址的项目。这有可能是主机B刚接入网络，也可能是主机A刚通电，其高速缓存还是空的。在这种情况下，主机A就自动运行ARP ARP进程在本局域网上广播一个ARP请求分组，ARP请求分组的主要内容是我的IP是209.0.0.5,硬件地址是:00-00-c0-15-ad-18.我想知道IP地址为209.0.0.6的主机的硬件地址。 在本局域网上所有主机上运行的ARP进程都收到此ARP的请求分组 主机B的IP地址与ARP请求分组中要查询的IP地址一致，则手下这个ARP请求分组，并且向主机A回应ARP相应分组，在这个相应分组中写入自己的硬件地址。因为其他的主机的IP地址和ARP请求得IP地址不一致，则丢弃ARP请求包。ARP响应分组的主要内容是：我的IP是209.0.0.6，我的硬件地址是:08-00-2b-00-ee-0a.注意arp响应是单播 主机A收到ARP响应分组以后，就在其中的ARP缓存中写入主机B的IP地址到硬件地址的映射。然后可以进行引起这次ARP请求得数据报的传送 致此一次ARP的请求过程就执行完了。注意:主机B在发送ARP请求得时候，将自己的MAC地址和IP也写入ARP请求数据报中了，所以主机B在接收到ARP请求得时候，就顺便将主机A的IP和硬件地址存入缓存，那么主机B给主机A发送数据的时候就不需要在进行ARP请求了，就会方便很多 对于不同局域网上的ARP请求，只是重读上述的过程，通过主机-路由器-主机这样的方式一跳一跳的传递。 ARP的协议报格式 ARP协议报是封装在以太网帧中被的发送的 目的地址：目的主机的MAC地址（上例子中为主机B的MAC地址） 源地址：发送数据报的MAC地址（上例子中为主机A的MAC地址） 帧类型 0x0800表示后面的报文是IP协议报文 0x0806表示后面的报文是ARP协议报文 硬件类型：表示硬件地址的类型，值为1表示以太网地址 协议类型：表示要映射的协议地址类型。它的值为0x0800表示IP地址类型 硬件地址长度和协议地址长度以字节为单位，对于以太网上的IP地址的ARP请求或应答来说，他们的值分别为6和4； 操作类型：1表示ARP请求，2表示ARP应答 发送端MAC地址：发送方设备的硬件地址； 发送端IP地址：发送方设备的IP地址； 目标MAC地址：接收方设备的硬件地址。 目标IP地址：接收方设备的IP地址。 ARP相关的攻击 ARP攻击就是通过伪造IP地址和MAC地址实现ARP欺骗，能够在网络中产生大量的ARP通信量使网络阻塞，攻击者只要持续不断的发出伪造的ARP响应包就能更改目标主机ARP缓存中的IP-MAC条目，造成网络中断或中间人攻击。 ARP的主要攻击就是ARP欺骗（FAQ） 什么是ARP欺骗？ 在局域网中，黑客经过收到的ARP Request广播包，能够偷听到其它节点的 (IP, MAC) 地址, 黑客就伪装为A，告诉B (受害者) 一个假地址，使得B在发送给A 的数据包都被黑客截取，而A, B 浑然不知。 `因为这种攻击伤害不是特别大，一般来说也就是让别人的电脑断断网，，详细的了解希望大家自行查阅相关的资料。","categories":[],"tags":[]},{"title":"图","slug":"图","date":"2018-05-17T01:49:03.000Z","updated":"2018-05-17T03:08:07.957Z","comments":true,"path":"2018/05/17/图/","link":"","permalink":"http://yoursite.com/2018/05/17/图/","excerpt":"","text":"图的基本概念图的认知 图是由顶点集合及顶点间的关系组成的一种数据结构：G = (V， E)，其中顶点集合V = {x|x属于某个数据对象集}是有穷非空集合；E = {(x,y)|x,y属于V}或者E = {&lt;x, y&gt;|x,y属于V&amp;&amp; Path(x, y)}是顶点间关系的有穷集合，也叫做边的集合。(x, y)表示x到y的一条双向通路，即(x, y)是无方向的；Path(x, y)表示从x到y的一条单向通路，即Path(x, y)是有方向的。 注意：(x,y):表示的没有方向，即双向通路；&lt;x,y&gt;：表示的有方向即x,y和y,x的含义就不一样来了，即单向通路 图的专业术语图的存储结构邻接矩阵 将所有顶点的信息组织成一个顶点表，然后利用一个矩阵来表示个顶点之间的邻接关系。设图G = (V, E)包含n个顶点，则A的邻接矩阵是一个二维数组G.Edge[n][n], 无向图邻接矩阵示意图 可以说是一个对称的矩阵 有向图邻接矩阵示意图 是一个没有任何规则的矩阵 注意：带权值的图只需要将其中的1换成具体的权值就可以了 无向图的邻接矩阵是对称的，第i行(列)元素之和，就是顶点i的度。有向图的邻接矩阵则不一定是对称的，第i行(列)元素之后就是顶点i 的出(入)度。即有向图要区分出度和入度，而无向图直接看一行或者一列就可以了 邻接矩阵的优点是可以很直观的看出来哪些路径是连通的，但是对于去查找路径就不是很方便了","categories":[{"name":"数据结构随笔","slug":"数据结构随笔","permalink":"http://yoursite.com/categories/数据结构随笔/"}],"tags":[]},{"title":"并查集","slug":"并查集","date":"2018-05-16T23:12:24.000Z","updated":"2018-05-17T14:50:24.652Z","comments":true,"path":"2018/05/17/并查集/","link":"","permalink":"http://yoursite.com/2018/05/17/并查集/","excerpt":"","text":"引入 首先我们来看一道题 假如已知有n个人和m对好友关系（存于数字r）。如果两个人是直接或间接的好友（好友的好友的好友…），则认为他们属于同一个朋友圈，请写程序求出这n个人里一共有多少个朋友圈。 假如：n = 5，m = 3，r = {{1 , 2} , {2 , 3} , {4 , 5}}，表示有5个人，1和2是好友，2和3是好友，4和5是好友，则1、2、3属于一个朋友圈，4、5属于另一个朋友圈，结果为2个朋友圈。 最后请分析所写代码的时间、空间复杂度。评分会参考代码的正确性和效率。 C/C++： int friends(int n , int m , int* r[]); 问题分析 解决方法1 使用set，有初始数据有几个圈子则创建几个set，然后分别用一个set中的元素在其他set中找，找到了证明有共同的朋友，则合并这两个set，最后判断有几个set不为空就得出有几个朋友圈的结果。 解决方法2 使用位图，分别将每个朋友圈映射到位图中，然后两个分别&amp;，如果&amp;后有1存在的话，那么就有交集，则将两个位图|起来就可以了 解决方法3 前两种方法都不是最好的，第三种就是我们引入的并查集 并查集概念 在这里我就不按照那就标准的定义来了，我直接按照自己的理解去讲了。 并查集的作用 其实就是将你已知的集合中元素之间的关系，去建立并查集（建立的过程就是合并有关联的集合），在这个并查集中我们可以很方便的统计出一共有多少个集合。 就是用来求两个集合的并集的。 并查集建立过程 举个例子: 有集合{0,1,2},{2,3,5},{4,6},{7,8},现在如何建立并查集 一共有n元素则建立n+1个容量的并查集（重复的不算，如果编号不标准，则自己 按照他们的关系去编号,这里尽量从0开始，并且是连续的编号），所以在这里建立9个容量的并查集数据结构，并将其初始化为-1，这是为了方便我们后面的统计 最开始肯定是两个元素去合并，那么选取一个作为表示其老大，用来保存他们这个集合中的元素的个数，这个老大的下标就是这个集合的标号，属于这个集合的元素的值就是这个老大的下标。 由例子集合的关系，我们的集合是这样建立的 （0,1）（1,2）（2,3）（3,5）（4,6）（6,7） (0,1)我们首先判断0,1是否是一个老大如果是则说明是一个集合的，不用合并，如果不是则合并，这里的合并就是选取0作为合并后集合的老大，里面存的就是0,1合并后集合的大小即为2，那么下标为1的位置的值就是0，表示自己的老大是0，后面所有的合并都是重复这个过程。则合并完就是这个样子 当我们判断上述集合可以合并为几个集合的时候，直接遍历数组，有几个位置的值小于0，则有几个集合。 上述的例子主要是针对于并查集的应用来讲的。 并查集的代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#pragma once#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std;class UFS &#123;private: vector&lt;int&gt; _set;public: UFS(int size)//一共有多少个元素开辟多少个空间 :_set(size, -1)&#123;&#125; int Find(int x)//查找根 &#123; while (_set[x] &gt;= 0) &#123; x = _set[x]; &#125; return x;//一旦小于0直接返回去就是根 &#125; void Union(int x1, int x2)//合并两个元素 &#123; //首先找到两个元素的根 int root1 = Find(x1); int root2 = Find(x2); if (root1 != root2) &#123; _set[root1] += _set[root2];//将两个集合的元素总数加起来给集合1 _set[root2] = root1;//集合2的根也属于集合1了 &#125; &#125; int SetCount()//统计元素 &#123; int count = 0; for (size_t i = 0; i &lt; _set.size(); ++i) &#123; if (_set[i] &lt; 0) ++count; &#125; return count; &#125;&#125;;void Test()&#123; UFS u(6); cout &lt;&lt; u.SetCount() &lt;&lt; endl;//得到的结果在-1，因为没有0号元素&#125;","categories":[],"tags":[]},{"title":"set和map简单模拟实现","slug":"set和map简单模拟实现","date":"2018-05-16T01:13:36.000Z","updated":"2018-05-16T15:56:34.935Z","comments":true,"path":"2018/05/16/set和map简单模拟实现/","link":"","permalink":"http://yoursite.com/2018/05/16/set和map简单模拟实现/","excerpt":"","text":"铺垫 底层 首先set和map的底层都是基于红黑树实现的，只需要将红黑树封装起来就可以了，所以在这里给出我之前博客的红黑树的实现 https://blog.csdn.net/it_iverson/article/details/79299039 迭代器 其实迭代器和智能指针一样，将原类的遍历，++，–等操作用一个类封装起来，然后将其迭代器类型typedef到原类中方便其使用（一般typedef 成iterator类型），封装后直接对这个对象进行操作就可以了，这个类就是迭代器。 12345678910111213141516171819//红黑树的迭代器template&lt;class V,class Ref,class Ptr&gt;//分别传V V* V&amp;struct _RBTreeIterator&#123; typedef _RBTreeIterator&lt;V,Ref,Ptr&gt; Self; typedef RBTreeNode&lt;V&gt; Node; Node* _node;//用来接头结点的指针，其实迭代器就是一个智能指针只不过他的功能是++和--还有一些解引用而已 _RBTreeIterator(Node* node) :_node(node)&#123;&#125;//这里只需要 浅拷贝就可以了，和迭代器的功能有关 _RBTreeIterator() &#123;&#125; Ref operator*();//返回引用 Ptr operator-&gt;();//返回指针,只是用模板来看更加的灵活 Self operator++();//前置++ Self operator++(int); bool operator!=(const Self&amp; s); Self operator--(); Self operator--(int);&#125;; 改造后的红黑树123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282//Myset-&gt;RBtree&lt;K,K&gt;//Myset-&gt;RBtree&lt;K,pair&lt;K,V&gt;&gt;template&lt; class V,class KeyOfValue&gt;class RBTree&#123;public: typedef RBTreeNode&lt; V&gt; Node; typedef Node* PNode; typedef _RBTreeIterator&lt;V, V&amp;, V*&gt; Iterator; typedef _RBTreeIterator&lt;V, const V&amp;, const V*&gt; ConstIterator;//让在红黑树中可以使用迭代器private: PNode _pRoot;public: RBTree() :_pRoot(NULL)&#123;&#125; Iterator Begin() &#123; Node* left=_pRoot; while (left-&gt;_pLeft) &#123; left = left-&gt;_pLeft; &#125; return left; &#125; Iterator End() &#123; return NULL; &#125; pair&lt;Iterator,bool&gt; Insert(const V&amp; value) &#123; if (NULL == _pRoot)//根节点为黑色 &#123; _pRoot = new Node( value); _pRoot-&gt;_color = Black; return make_pair(Iterator(_pRoot),true);//make_pair&lt;&gt;生成一个pair对象返回去 &#125; KeyOfValue kof; PNode cur = _pRoot; PNode pParent = NULL; while (cur)//找插入的位置 &#123; if (kof(cur-&gt;_v)==kof(value)) return make_pair(Iterator(cur),false); else if (kof(cur-&gt;_v)&gt;kof(value))//这里用仿函数巧妙的 处理了 set和map中值不同的问题 &#123; pParent = cur; cur = cur-&gt;_pLeft; &#125; else &#123; pParent = cur; cur = cur-&gt;_pRight; &#125; &#125; PNode pNewNode = new Node(value);//新插入的结点的颜色默认是红的 PNode ret = pNewNode; //找到插入的位置以后开始插入 if (kof(pParent-&gt;_v)&gt;kof(value)) &#123; pParent-&gt;_pLeft = pNewNode; pNewNode-&gt;_pParent = pParent; &#125; else &#123; pParent-&gt;_pRight = pNewNode; pNewNode-&gt;_pParent = pParent; &#125; ////当结点插入好了以后我们就要根据红黑树的性质来判断结点是否满足，从而调整结点 while (pParent) &#123; if (pParent-&gt;_color == Black)//父结点是黑的,不用调整直接退出 &#123; break; &#125; //记录祖父结点和定义保存叔叔结点 PNode gparent = pParent-&gt;_pParent; PNode uncle = NULL; if (pParent == gparent-&gt;_pLeft)//在其左子节点上 &#123; uncle = gparent-&gt;_pRight; if (uncle&amp;&amp; uncle-&gt;_color == Red)//叔叔结点存在切为红情况3,4 &#123; gparent-&gt;_color = Red; uncle-&gt;_color = pParent-&gt;_color = Black; pNewNode = gparent;//保存gg结点 pParent = gparent-&gt;_pParent; continue; &#125; else if (uncle == NULL || uncle-&gt;_color == Black)//叔叔不存在或者为黑 &#123; if (pNewNode == pParent-&gt;_pLeft)//外侧插入 &#123; _RBRolateR(gparent); gparent-&gt;_color = Red; pParent-&gt;_color = Black; &#125; else//内测插入 &#123; _RBRolateL(pParent); std::swap(pParent, pNewNode);//交换pParent和插入结点指针的值 _RBRolateR(gparent); gparent-&gt;_color = Red; pParent-&gt;_color = Black; &#125; &#125; break;//直接跳出循环 &#125; else//右边的情况 &#123; uncle = gparent-&gt;_pLeft; if (uncle&amp;&amp;uncle-&gt;_color == Red)//叔叔存在而且为红色 &#123; gparent-&gt;_color = Red; uncle-&gt;_color = pParent-&gt;_color = Black; pNewNode = gparent; pParent = pNewNode-&gt;_pParent; continue; &#125; else if (uncle == NULL || uncle-&gt;_color == Black)//叔叔不存在或者为黑 &#123; if (pNewNode == pParent-&gt;_pRight) &#123; _RBRolateL(gparent); gparent-&gt;_color = Red; pParent-&gt;_color = Black; &#125; else &#123; _RBRolateR(pParent); std::swap(pParent, pNewNode); _RBRolateL(gparent); gparent-&gt;_color = Red; pParent-&gt;_color = Black; &#125; &#125; break; &#125; &#125; _pRoot-&gt;_color = Black; return make_pair(Iterator(ret), true); &#125; void InOrder() &#123; _InOrder(_pRoot); &#125; bool IsRBTree() &#123; if (_pRoot == NULL)//根节点 为空是红黑树 return true; if (_pRoot-&gt;_color == Red)//根节点为红色肯定不是红黑树 return false; int count = 0;//统计黑色结点的数目 PNode cur = _pRoot; while (cur)//根出一条参考路径的黑色结点的数目 &#123; if (cur-&gt;_color == Black) ++count; cur = cur-&gt;_pLeft; &#125; int k = 0; return _IsRBTree(_pRoot, count, k); &#125; Iterator Find(const V&amp; key) &#123; KeyOfValue kov; PNode cur = _pRoot; while (cur) &#123; if (kov(cur-&gt;_v &gt; key)) &#123; cur = cur-&gt;_pLeft; &#125; else if (kov(cur-&gt;_v) &lt; key) &#123; cur = cur-&gt;_pRight; &#125; else &#123; //return cur; return Iterator(cur); &#125; &#125; &#125;private: bool _IsRBTree(PNode pRoot, int&amp; count, int k)//这里的K不能传引用 &#123; if (pRoot == NULL) return true; //出现两个连续的红色的结点 if (pRoot-&gt;_pParent&amp;&amp;pRoot-&gt;_color == Red&amp;&amp;pRoot-&gt;_pParent-&gt;_color == Red) return false; //如果是黑色结点k++ if (pRoot-&gt;_color == Black) k++; if (pRoot-&gt;_pLeft == NULL&amp;&amp;pRoot-&gt;_pRight == NULL)//如果是叶子结点的话进行判断k和count &#123; if (k == count) return true; else return false; &#125; return _IsRBTree(pRoot-&gt;_pLeft, count, k) &amp;&amp; _IsRBTree(pRoot-&gt;_pRight, count, k); &#125; //右单旋转 void _RBRolateR(PNode parent) &#123; if (NULL == parent) return; PNode SubL = parent-&gt;_pLeft;// PNode SubLR = SubL-&gt;_pRight; parent-&gt;_pLeft = SubLR; if (SubLR != NULL) SubLR-&gt;_pParent = parent; PNode pParent = parent-&gt;_pParent; SubL-&gt;_pRight = parent; parent-&gt;_pParent = SubL; if (pParent == NULL) &#123; _pRoot = SubL; SubL-&gt;_pParent = NULL; &#125; else &#123; if (pParent-&gt;_pLeft == parent) &#123; pParent-&gt;_pLeft = SubL; SubL-&gt;_pParent = parent; &#125; else &#123; pParent-&gt;_pRight = SubL; SubL-&gt;_pParent = parent; &#125; &#125; &#125; void _RBRolateL(PNode parent) &#123; if (NULL == parent) return; PNode SubR = parent-&gt;_pRight; PNode SubRL = SubR-&gt;_pLeft; parent-&gt;_pRight = SubRL; if (SubRL) &#123; SubRL-&gt;_pParent = parent; &#125; PNode pParent = parent-&gt;_pParent; SubR-&gt;_pLeft = parent; parent-&gt;_pParent = SubR; if (pParent == NULL) &#123; _pRoot = SubR; SubR-&gt;_pParent = NULL; &#125; else &#123; if (pParent-&gt;_pLeft == parent) &#123; pParent-&gt;_pLeft = SubR; SubR-&gt;_pParent = pParent; &#125; else &#123; pParent-&gt;_pRight = SubR; SubR-&gt;_pRight = pParent; &#125; &#125; &#125; void _InOrder(PNode pRoot) &#123; if (pRoot) &#123; _InOrder(pRoot-&gt;_pLeft); // cout &lt;&lt; pRoot-&gt;_key &lt;&lt; \" \"; _InOrder(pRoot-&gt;_pRight); &#125; &#125;&#125;; Setset的特性 所有的元素都会根据元素的键值自动被排序。set的元素不像map那样可以同时拥有实值(value)和键值(key),set元素的键值就是实值，实值就是键值，set不允许两个元素有相同的值。我们也不允许通过set的迭代器改变set元素，因为set元素值就是其关键值，关系到set元素的排列规则。如果任意改变set的元素值得话，会严重破坏set的组织。所以在set的底层RBtree中定义的是const_iterator,用来防止修改值的，在上述的红黑树中也有体现1typedef _RBTreeIterator&lt;V, const V&amp;, const V*&gt; ConstIterator set实现 因为红黑树是一种平衡二叉搜索树，自动排序的效果很不错，所以标准的STL set以红黑树为底层。由于set所开放的接口，红黑树都提供了，所以几乎所有的set的行为都是红黑树接口的调转。 如何区分set和map呢？ 因为如果是set的话，其key就是键值也是实值,而map的话插入的是pair&lt;k,v&gt;结构后面map中详细介绍，而我们需要其中的键值key来进行相关的操作，所以这里我们使用仿函数就可以很容易的实现。123456789101112131415161718 //set的仿函数,因为直接在类中，所以少了模板 struct SetKeyOfValue &#123; const K&amp; operator()(const K&amp; key) &#123; return key; &#125; &#125;;//map的仿函数,因为写在类外所以就带了模板参数template&lt;class K,class V&gt;struct MapKeyOfvalue&#123; const K&amp; operator()(const pair&lt;K, V&gt;&amp; kv) &#123; return kv.first; &#125;&#125;; set的简单模拟实现代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#pragma once#include \"RBTree.h\"//template&lt;class K&gt;template&lt;typename K&gt;class Set&#123;public: struct SetKeyOfValue &#123; const K&amp; operator()(const K&amp; key) &#123; return key; &#125; &#125;; typedef typename RBTree&lt; K, SetKeyOfValue&gt;::Iterator Iterator; pair&lt;Iterator, bool&gt; Insert(const K&amp; key) &#123; return _t.Insert(key); &#125; Iterator Find(const K&amp; key) &#123; return _t.Find(key); &#125; Iterator Begin() &#123; return _t.Begin(); &#125; Iterator End() &#123; return _t.End(); &#125;protected: RBTree&lt;K, SetKeyOfValue&gt; _t;&#125;;void TestMySet()&#123; Set&lt;string&gt; s; s.Insert(\"sort\"); s.Insert(\"insert\"); s.Insert(\"set\"); s.Insert(\"map\"); s.Insert(\"iterator\"); s.Insert(\"value\"); s.Insert(\"value\"); Set&lt;string&gt;::Iterator it = s.Begin(); while (it != s.End()) &#123; cout &lt;&lt; *it &lt;&lt; \" \"; ++it; &#125; cout &lt;&lt; endl;&#125; mapmap的特性 所有的元素都会根据元素的键值(key)自动被排序.map的所有元素都是pair，同时拥有实值(value)和键值(key),pair的第一个元素被视为键值,第二元素被视为实值，map不允许有两个相同的键值。 pair的结构给出pair的源代码 12345678910111213141516171819202122232425262728293031323334353637383940414243#ifndef __SGI_STL_INTERNAL_PAIR_H#define __SGI_STL_INTERNAL_PAIR_H__STL_BEGIN_NAMESPACEtemplate &lt;class T1, class T2&gt;struct pair &#123; typedef T1 first_type; typedef T2 second_type; T1 first; T2 second; pair() : first(T1()), second(T2()) &#123;&#125; pair(const T1&amp; a, const T2&amp; b) : first(a), second(b) &#123;&#125;#ifdef __STL_MEMBER_TEMPLATES template &lt;class U1, class U2&gt; pair(const pair&lt;U1, U2&gt;&amp; p) : first(p.first), second(p.second) &#123;&#125;#endif&#125;;template &lt;class T1, class T2&gt;inline bool operator==(const pair&lt;T1, T2&gt;&amp; x, const pair&lt;T1, T2&gt;&amp; y) &#123; return x.first == y.first &amp;&amp; x.second == y.second; &#125;template &lt;class T1, class T2&gt;inline bool operator&lt;(const pair&lt;T1, T2&gt;&amp; x, const pair&lt;T1, T2&gt;&amp; y) &#123; return x.first &lt; y.first || (!(y.first &lt; x.first) &amp;&amp; x.second &lt; y.second); &#125;template &lt;class T1, class T2&gt;inline pair&lt;T1, T2&gt; make_pair(const T1&amp; x, const T2&amp; y) &#123; return pair&lt;T1, T2&gt;(x, y);&#125;__STL_END_NAMESPACE#endif /* __SGI_STL_INTERNAL_PAIR_H */// Local Variables:// mode:C++// End: 其实简单的理解就这这个样子的，其实就是一个自定义的类型123456789101112template&lt;class K,class V&gt;struct pair&#123; K first; V second; pair()//无参构造函数 :_first(K()) , second(V())&#123;&#125; pair(const K&amp; a, const V&amp; b)//有构造函数 :_first(a) , second(b)&#123;&#125;&#125;; map简单模拟的实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#pragma once#include\"RBTree.h\"template&lt;class K,class V&gt;struct MapKeyOfvalue&#123; const K&amp; operator()(const pair&lt;K, V&gt;&amp; kv) &#123; return kv.first; &#125;&#125;;template&lt;class K, class V, class MapKeyOfvalue = MapKeyOfvalue&lt;K,V&gt; &gt;class Map&#123;protected: RBTree&lt;/*K,*/ pair&lt;K, V&gt;,MapKeyOfvalue&gt; _t;//定义红黑树的对象public: typedef typename RBTree&lt;/*K,*/ pair&lt;K, V&gt;, MapKeyOfvalue&gt;::Iterator Iterator; pair&lt;Iterator, bool&gt; Insert(const pair&lt;K,V&gt;&amp; kv) &#123; return _t.Insert(kv); &#125; V&amp; operator[](const K&amp; key) &#123; pair&lt;Iterator, bool&gt; ret = Insert(make_pair(key, V())); return (ret.first)-&gt;second; &#125; Iterator Find(const K&amp; key) &#123; return _t.Find(key); &#125; Iterator Begin() &#123; return _t.Begin(); &#125; Iterator end() &#123; return _t.End(); &#125;&#125;;void TestMyMap()&#123; Map&lt;string, string&gt; dict; dict[\"hehe\"] = \"haha\"; dict.Insert(make_pair(\"left\", \"左边\")); Map&lt;string, string&gt;::Iterator it = dict.Begin(); while (it != dict.end()) &#123; cout &lt;&lt; (*it).first &lt;&lt;\" \"&lt;&lt;(*it).second&lt;&lt;endl; ++it; &#125;&#125; 在次梳理一下，在红黑树中如果是set的则V直接就是set的key,而如果是map的话，那么V的类型就是pair这个自定义的类型，这里自己注意区分。还有就是set的迭代器使用constiterator而map使用iterator就可以了。 map中的operator[]","categories":[],"tags":[]},{"title":"位图（哈希应用）","slug":"位图","date":"2018-05-15T11:13:07.000Z","updated":"2018-05-15T13:10:41.100Z","comments":true,"path":"2018/05/15/位图/","link":"","permalink":"http://yoursite.com/2018/05/15/位图/","excerpt":"","text":"位图的引入 首先我们由一道题来引入位图的概念 给40亿个不重复的无符号整形，没排过序。给一个无符号的整数，如何判断一哥数是否在这40亿个中？ 40亿个无符号的整形，大概就需要40亿*4这么些字节，下来大概就是16G的内存，首先我们想将这些数据加载到内存中去判断是不现实的，因为16G的内存还仅仅是用来处理你这个数据。。所以在这里我们就需要用到位图，即用每一个比特位去表示一个数字，举个例子：一个个字节，8个比特位，就可以表示8个数字，那么1G=1024MB=1024x1024KB=1024x1024x1024字节=8589934592个比特位，大概能表示80亿个数字了。但是仅仅只占用了1G的内存 位图实现的功能 Bitset(size_t rang) 设置位图所能表示的范围:因为我们封装的vector，所以开辟是以一个int为单位的，所以我们给出的rang的数值以后要除32，用来判断开辟几个整形 void Set(size_t x) 将我们要判断的数据放入位图当中，比如说我们要存48，则将第48个比特位置1，那么怎么将48比特位置1呢？首先我们要判断48实在第几个整形当中（48&gt;&gt;5），然后判断在第几个比特位(48%32),然后将当前的整形左移多少个比特位就好了 void ReSet(size_t x) 将放置的元素删除，只需要将元素对应的标志位置0，步骤和Set一样，找到那个位置以后取反 bool Test(size_t x) 判断元素是否在位图中，步骤同上最后按位与就得到结果 位图的代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344#pragma once#include\"MyUnorderedSet.h\"class BitSet&#123;public: BitSet(size_t range)//给出位图能表示的范围，一般是比特位 &#123; //_bits.resize(range/32+1, 0); _bits.resize((range&gt;&gt;5)+1, 0); &#125; void Set(size_t x)//放入位图中 &#123; size_t num = (x &gt;&gt; 5); size_t pos = x % 32; _bits[num] |= 1 &lt;&lt; pos; &#125; void ReSet(size_t x)//从位图中删除 &#123; size_t num = (x &gt;&gt; 5); size_t pos = x % 32; _bits[num] &amp;= ~(1 &lt;&lt; pos); &#125; bool Test(size_t x)//判断是否在位图中 &#123; size_t num = (x &gt;&gt; 5); size_t pos = x % 32; return _bits[num] &amp; (1 &lt;&lt; pos); &#125;protected: vector&lt;size_t&gt; _bits;&#125;；void test()&#123; BitSet bs(32); bs.Set(110); bs.Set(1); bs.Set(100000); bs.Set(100001); cout &lt;&lt; bs.Test(110) &lt;&lt; endl;&#125;","categories":[{"name":"数据结构随笔","slug":"数据结构随笔","permalink":"http://yoursite.com/categories/数据结构随笔/"}],"tags":[]},{"title":"B树","slug":"B树","date":"2018-05-14T03:10:47.000Z","updated":"2018-05-15T03:08:46.150Z","comments":true,"path":"2018/05/14/B树/","link":"","permalink":"http://yoursite.com/2018/05/14/B树/","excerpt":"","text":"B树的基本概念 B树是R.Bayer和E.mccreight提出的一种适合外查找的树（在磁盘上查找），他是一种平衡的多叉树，成为B树（有些地方写的是B-树，注意不要读成了”B减树”） 一个B数应该满足下列的性质 根节点至少有两个孩子，[2,M]个孩子 每个非根节点有[M/2,M]个孩子 每个非根节点有[M/2-1,M-1]个关键字，并且以升序排列 每个结点孩子的数量比关键字的数量多一个 key[i]和key[i+1]之间的孩子结点的值介于key[i]、key[i+1]之间 所有的叶子结点都在同一层 给出B树的结构框架1234567891011121314151617template&lt;class K,class V,size_t M&gt;struct BTreeNode&#123; pair&lt;K, V&gt; _kvs[M - 1];//关键字 BTreeNode&lt;K, V, M&gt;* subs[M];//孩子的指针集 size_t _size;//关键字的数量&#125;;template&lt;class K,class V,size_t M&gt;class BTree&#123;public: typedef BTree&lt;K, V, M&gt; Node; typedef Node* PNode;private: PNode _pRoot;&#125;; 这只是简单的最基础的框架，后面我们还要在此基础上进行修改！ B树的代码实现B树的应用B+树是B树的变形，在实际中B+树用的最多，数据库这里剩下的东西需要自己去了解。","categories":[{"name":"数据结构随笔","slug":"数据结构随笔","permalink":"http://yoursite.com/categories/数据结构随笔/"}],"tags":[]},{"title":"海量数据面试题","slug":"海量数据面试题","date":"2018-05-13T23:18:40.000Z","updated":"2018-05-14T02:39:25.379Z","comments":true,"path":"2018/05/14/海量数据面试题/","link":"","permalink":"http://yoursite.com/2018/05/14/海量数据面试题/","excerpt":"","text":"给一个超过100G大小的log file,log中村着IP地址，设计算法找到出现次数最多的IP地址？问题分析 首先从题目可以看出来主要的问题是100G的文件容量过大内存无法一次性放下 其次我们可以看到需要统计IP出现的次数，一旦出现统计次数这种关键字眼我们就应该想到&lt;key,value&gt;这种数据结构，所在在这里我们用HashTable. 解决办法 首先使用哈希切割将其分成1000分文件，即将每个IP地址讲过散列函数以后放到于其对应的文件中，这样做的好处首先是将大文件拆分成了小文件，其次将相同的IP地址放在了一个文件中。那么为什么切成1000份呢而不是100份呢？因为哈希切割是不均匀的，切割后的文件大小不一致，如果我们分成了1000份，平均下来每个大小也就100Mb,即时不均匀，文件也不会太大。 1hashfunc(ip)%1000;//哈希分割,将这些ip放入对应的文件 然后根据哈希表去统计每个文件中出现次数最多的Ip地址，然后从10个文件中，找出出现数字最多的Ip,即就是我们要找的答案 1hashtable[ip]++;//统计每个文件中ip出现的次数 问题延伸 如果我们要找前出现次数最多的前100个IP的话怎么解决呢? 答：使用Top k解决策略，用100个IP直接建一个小堆，然后从每个文件中每个IP出现的次数和堆顶的元素比较，如果比其大的话，那么将其放入堆中，最后将所有文件遍历完，则堆中的元素就是出现次数最多的前100个IP 与上题条件相同，如果找到Tok K的IP？如何直接用Linux系统命令直接实现呢？ 给定100亿个整数，设计算法找到只出现一次的整数？问题分析 首先看到100亿个整数我们第一想法会想到位图吗，没错这个题是用位图解决 可是位图单纯的一位只能表示这个数字在不在，没有办法表示他出现了几次，所以我们在这里使用两位来表示一个数的状态，即有没有出现过、出现了几次、这种状态由你自己规定是01 10 00之类的。 之后遍历位图找到出现一次的数就可以了 解决办法 下面主要给出伪代码的实现1234567891011121314151617181920212223242526272829#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std;class TwoBitSap&#123;public: bool TestBit(size_t index, size_t num) &#123; return _bits[index] &amp; (1 &lt;&lt; num);//判断两个位是0还是1，_bits[index]表示在第几个size_t当中 &#125; void Add(size_t x) &#123; size_t index =x/ 16; size_t num = x% 16 * 2;//找到其两位 bool first=TestBit(index, num); bool second=TestBit(index, num + 1); if (first == false &amp;&amp; second == false)//表示一次都没有出现过 &#123; ; &#125; else if (first==false&amp;&amp;second==true)//出现过1次 &#123; ;//表示出现过一次比如01表示出现了一次了，那么将其改为10， &#125; //后续代码只需要从位图中找到01就表示只出现了一次 &#125;protected: vector&lt;size_t&gt; _bits;&#125;; 问题延伸 如果不允许使用位图的话，我们可以继续使用哈希切割的思想 给两个文件，分别有100亿个整数，我们只有1G内存，如何找到这两个文件的交集？问题分析 又是上百亿整数所以这个题我们还是使用位图 将两个文件的整数全部映射到两个位图当中去 因为我们要求得是交集所有我们将两个位图按位与最后得到的结果就是他们的交集 问题延伸 如果要找他们的并集的话我们只需要按位或就可以了 那么如果要找他们的差集呢？则异或就可以很好的解决问题 1个文件有100亿个int，1G内存，设计算法找到出现次数不超过两次的所有整数集？ 问题分析 这个题和第三题的解题方法思路几乎一样这里就不多阐述了。 给两个文件，分别有100亿个查询，有1G内存，如何找到两个文件的交集？分别给出精确的算法和近似的算法？问题分析 运用哈希切割的思想，将两个文件分别运用同一个散列函数切割成小块文件，然后两个两个文件对应再运用set去找在不在 解决方法 如何扩展布隆过滤器使得它支持删除元素的操作？问题分析 首先我们知道布隆过滤器不支持删除，因为多个key可能映射在同一个位置，如果你根据其中的一个key贸然的删除这个位的话，那么其他的key是不是也就找不到了。 所以如果我们要对布隆过滤器进行删除的话，我们需要对每个位的引用个数进行计数 给你上千个文件，每个文件大小1K-100M。给n个词，设计算法对每个词找到所有包含它的文件，你只有100k的内存问题分析 倒排索引，了解搜索引擎底层，这里就略了！","categories":[],"tags":[]},{"title":"处理机调度","slug":"处理机调度","date":"2018-05-12T00:22:38.000Z","updated":"2018-05-13T03:18:21.445Z","comments":true,"path":"2018/05/12/处理机调度/","link":"","permalink":"http://yoursite.com/2018/05/12/处理机调度/","excerpt":"本篇博客的主要内容是介绍调度算法。 1.关于处理机调度的基础概念","text":"本篇博客的主要内容是介绍调度算法。 1.关于处理机调度的基础概念 处理机调度： 1.从就绪队列中挑选下一个占用CPU运行的进程。 2.从多个可用cpu中挑选就绪进程可使用的CPU资源。 调度程序：挑选就绪进程的内核函数，如果是多处理机，即挑选cpu。 调度算法的核心：依据什么进行调度和调度时机。下面来详细说一下 1.调度时机 对于非抢占的情况来说：进程从运行变为等待可以调度一个就绪进程运行，或者运行进程退出时也可以调度。 对于抢占的情况来说：中断请求被服务例程相应完成的时候，或者进程时间片用完，或者进程从等待切换到就绪状态(此进程优先级高) 2.调度的准则依据是什么 衡量一个调度算法的好坏即cpu的繁忙率、还有就是吞吐量（即cpu单位时间完成的进程数）这是从系统角度，从用户角度的话，即速度快不快。 2.调度算法调度算法有这么几种：先来先服务算法、短进程优先算法、最高响应比优先算法（依据等待时间）、时间片轮转算法（在先来先服务器基础上加上时间片）、多级反馈队列算法、公平共享调度算法 1.先来先服务算法依据进程进入就绪状态的先后顺序排列，正在运行的进程进入等待状态或者结束状态时，就绪队列中的下一个进程去运行。。 这个算法的优点是简单，缺点是会造成平均等待时间较大，这个缺点怎么理解呢？ 比如有三个进程ABC执行时间分别是12 3 3，那么假如在就绪队列中的排序为A B C那么周转时间就是 （12+15+18/3=15，如果是B C A 的话那么（3+3+15）/3=9周转时间就是9了。。所以这就是一个很大的问题。 对于这种算法的改进就是短进程优先算法 2.短进程优先算法（SPN）选择进程占用的时间少的先运行，即就绪队列按预期的执行时间来排序。但是如果就绪队列中来了一个比当前执行了一半剩余时间还要短的进程，那么他可以抢占cpu去执行。这个就是该进程的算法，即短剩余时间优先算法（SRT） 短时间优先的特征： 优点：进程的周转时间最短。缺点：如果短进程较多的话,那么长时间进程会导致饥饿。还有的缺点就是如何知道进程的执行时间长短（1.询问用户，或者用过去预测未来） 3.最高响应比优先根据响应比选择就绪队列中响应比R值最高的进程。 R=(W+S)/S W:等待时间 S：执行时间 这是基于短进程优先的改进，即也没有抢占。 以上根据就绪队列排序的算法就说完了。。 4.时间片轮转算法时间片结束时按照先来先服务下一个进程去执行。 这种算法会有额外的上下文切换的开销 那么时间片大小如何确定呢？ 太大的话就和先来先服务一样了，太短的话 ，上下文切换开销大，影响吞吐量 目前来说只能根据经验来规定：即10ms切换 一次 5.多级反馈调度算法（MQ）就就绪队列被划分为多个独立的子队列，例如：前台（时间片短）、后台（执行时间长），这样的话后台进程可能会导致饥饿，所以可以给不同的队列分配不同的时间片从而防止饥饿产生。。所以就进阶产生了多级反馈队列。即进程可以在不同的队列间移动的多级队列算法。 传统的调度算法到此就说完了。。。 下面说说实时调度的算法。。 静态的速度单调调度算法： 1.根据任务周期安排优先级 2。周期越短先执行 最早截止时间优先算法","categories":[{"name":"系统学习","slug":"系统学习","permalink":"http://yoursite.com/categories/系统学习/"}],"tags":[]},{"title":"HTTP协议","slug":"HTTP协议","date":"2018-05-11T10:42:51.000Z","updated":"2018-05-13T02:59:53.589Z","comments":true,"path":"2018/05/11/HTTP协议/","link":"","permalink":"http://yoursite.com/2018/05/11/HTTP协议/","excerpt":"此篇博客的主要内容来讲解一下HTTP协议。 首先在讲解HTTP协议之前先补充一下万维网WWW（world,wide,web）的相关知识. 万维网组成：主要由网页组成，还有就是网页之间的互相连接。","text":"此篇博客的主要内容来讲解一下HTTP协议。 首先在讲解HTTP协议之前先补充一下万维网WWW（world,wide,web）的相关知识. 万维网组成：主要由网页组成，还有就是网页之间的互相连接。网页的内容又是什么呢？ 网页包含多个对象：HTML文件、图片、视频、动态脚本，每个网页还有一个基本的HTML文件包含对其他对象的引用。 Web对象的寻址（URL）：使用URL统一资源定位器 固定格式:&lt;协议&gt;://&lt;主机&gt;:&lt;端口&gt;/&lt;路径&gt; 协议：就是指用什么协议来获取该万维网文档。现在最常用的就是http协议（超文本传输协议），其次是ftp（文件传输协议）。在协议后面的://是规定的格式 主机：指出万维网文档在哪个主机上，这里可以是主机ip也可以是域名，后面的端口和路径有时候可以省略。 举个例子： www.lishuaii.com/test/pic.gif HTTP(超文本传输协议)下面进入超文本传输协议的介绍，首先介绍一些基础知识，然后在介绍HTTP协议的格式吧。。 http的操作过程：http定义了浏览器（即万维网客户进程）怎么向万维网服务器求情万维网文档，以及服务器怎么样把文档传给浏览器。从层次角度看HTTP是面向事物的（所谓事物就是指一系列信息的交换，而这一系列信息的交换是一个不可分割的整体，也就是说要么所有的信息都交换完，要么一次都不进行）应用层协议。HTTP不仅传输超文本跳转所必须的信息，而且也传送任何从互联网上得到的信息，如文本、超文本、声音、图像等。 版本：http1.0和http1.1 下面讲一下http使用tcp的一次传输过程？： 1.服务器在80端口等待客户端的连接请求 2.浏览器发起到服务器的TCP连接（创建socket套接字，建立三次握手） 3.服务器接收来自浏览器的TCP连接 4.浏览器（HTTP客户端）与Web服务器（HTTP服务器）交换HTTP消息 5.关闭TCP连接。 注意：http应用协议是一个无状态的协议，即服务器不维护任何有关客户端过去所发请求得信息。为什么使用无状态呢？因为成本低，问题少。 http的连接类型？ 1.非持久性性连接：每个TCP连接最多允许传输一个对象。HTTP 1.0版本使用非持久性连接（短连接） 2.持久性连接：每个TCP连接允许传输多个对象。HTTP1.1版本默认使用持久性连接（长连接） 下面详细介绍两个连接方式的工作过程 1.非持久性连接： 2.持久性连接 因为非持久性连接有很大的问题比如： 1.每个对象需要2个RTT 2.操作系统需要为每个TCP连接开销资源（overhead） 所以持久性连接就是在发送相应以后，服务器保持TCP连接的打开而不是直接关闭连接，后续的HTTP消息通过这个连接发送。 但是持久性连接又可以分为1.非流水线方式的持久性连接：即客户端只有收到前一个响应后才能发送新的请求，每个被引用的对象耗时一个RTT。2.流水线机制的持久性连接（HTTP1.1默认选项）：客户端只要遇到一个引用对象就尽快发出请求，理想情况下收到所有的对象只需要耗时约一个RTT。 好了接下来就来看看HTTP消息格式 HTTP消息格式HTTP有两类消息：请求消息（从客户向服务器发送请求报文）和相应消息（从服务器到客户端的回答） 1.请求消息 2.响应消息 致此关于HTTP基本的内容已经讲完了，下面再说两个扩展性的话题Cookie和代理服务器 Cookie技术为什么需要Cookie技术呢？ 因为HTTP协议是一种无状态的，即服务器不记录客户的历史行为，那么就会带来一些问题，很多服务器需要记录客户的状态，购物车之类的。。 Cookie工作原理:当用户A浏览某个使用Cookie的网站的时候，该网站的服务器就会为A产生一个唯一的标识码，并以此作为索引在服务器的后端数据库中产生一个项目。接着在给A的响应报文的首部行中添加一个叫做Set-cookie的首部行，形如Set-cookie：识别码（123456或者fgdsgdfgsd）总之识别码是唯一的，那么这个网站就能跟踪客户A在该网站的活动，需要注意的是服务器并不知道这个用户的真实姓名以及其他的信息，但是服务器能够知道用户A在什么时候访问了哪些页面，以及页面的访问顺序。如果A是在网上购物，那么服务器就可以为A维护一个所购物品的列表，方便A一起付费。假如A过几天再次访问这个网站的话，那么他的请求报文中继续使用Set-cookie：识别码，这个时候网站可以根据其过去的访问记录给A提供相应的商品推荐。。如果A在该网站输入过个人信息的话，那么该网站也保存了用户的信息。。 Web代理服务器技术（Web缓存技术）功能：在用户浏览器不需要访问源服务器就能满足HTTP请求。 好处：缩小响应的时间、减少机构和组织的流量、在大范围内实现有效内容的分发。 技术的实现过程假如不使用代理服务器的时候，局域网中的所有计算机都通过1.5Mbit/s的线路与互联网上的源点服务器建立TCP连接。所以会造成链路过载，延时大大增加。 如果使用代理服务器的话 下面详细叙述一下整个访问的过程 1.局域网中的计算机的浏览器向互联网服务器请求服务时，就先和代理服务器建立TCP连接，并向代理服务器发出HTTP请求报文。 2.如果代理服务器已经存放了所请求得对象，代理服务器就把这个对象放入HTTP响应报文中返回给计算机的浏览器。 3.否则，代理服务器就代表发出请求得用户浏览器，与互联网上的源点服务器建立TCP连接，并发送HTTP请求报文。 4.源点服务器把所有的请求对象放在HTTP响应报文中返回给代理服务器。 5.代理服务器收到这个对象以后，先复制在自己本地的存储器中（留待以后使用），然后在吧这个对象放在HTTP响应报文中，通过已经建立的TCP连接，返回给请求该对象的浏览器。。 那么我们如何保证代理服务器上的页面就一定是最新的页面的呢？","categories":[{"name":"网络学习","slug":"网络学习","permalink":"http://yoursite.com/categories/网络学习/"},{"name":"应用层","slug":"网络学习/应用层","permalink":"http://yoursite.com/categories/网络学习/应用层/"}],"tags":[]},{"title":"进程和线程","slug":"进程和线程","date":"2018-05-10T06:28:44.000Z","updated":"2018-05-13T03:18:35.637Z","comments":true,"path":"2018/05/10/进程和线程/","link":"","permalink":"http://yoursite.com/2018/05/10/进程和线程/","excerpt":"首先给出本节的主要内容！ 1.进程：进程的概念、进程控制块、进程状态、三状态进程模型、挂起进程模型 2.线程：为什么引入线程、线程的概念、用户线程、内核线程","text":"首先给出本节的主要内容！ 1.进程：进程的概念、进程控制块、进程状态、三状态进程模型、挂起进程模型 2.线程：为什么引入线程、线程的概念、用户线程、内核线程 1.进程的概念1.进程的概念 2.进程的特点 动态性：可动态的创建、结束进程 并发性：进程可以被独立调度并占用处理机（交替执行） 独立性：不同的进程工作互不影响 制约性：因访问共享数据或者资源或者进程间同步而产生制约 3.进程与程序的联系 4.进程和程序的区别 2.进程控制块在这里我指向强调两点 1.进程控制块中的内容 2.进程控制块的组织形式 3.进程的状态 下面我针对每个状态详细阐述一下 1.创建：引起进程创建的情况： 系统初始化的时候；用户请求创建一个新进程；正在运行的进程执行了创建进程的系统调用（fork和do_fork） 2.当一个进程创建好以后就进入了就绪队列，这个时候内核根据系统调用算法，选择合适的进程进入运行状态。 3.等待：进程进入等待（阻塞）的情况： 请求并等待系统服务，无法马上完成；启动某种操作的，无法马上完成（读写磁盘的速度）；需要的数据没有到达 注意：只有进程自身才会导致进程进入等待状态，不会被外部改变 4.运行–&gt;就绪： 高优先级进程就绪； 进程当前的时间片用完； 5.等待–&gt;就绪:（唤醒） 唤醒进程的情况，被阻塞的进程需要的资源可被满足；被阻塞的进程等待的时间的到达； 注意：唤醒只能被其他进程或者操作系统唤醒 6.运行–&gt;退出 进程结束的情况： 正常退出（自愿的）、错误退出（自愿的）、致命错误（强制性的）、被其他进程所杀死（强制性的） 下面阐述一下sleep()系统调用对应的进程状态变化 创建–&gt;就绪–&gt;运行–&gt;等待–&gt;就绪–&gt;运行–&gt;结束。 4.三状态进程模型（就绪，运行，等待）运行：进程正在CPU上运行 就绪：进程获得了除处理机以外的所需资源，只需要得到处理机就可以运行 等待(阻塞)：进程等待某事件的出现而暂停的状态 除了这三个状态以外还有两个辅助状态 1.创建状态：一个进程正在被创建，还没被转到就绪状态之前的状态，正在分配资源 2.退出状态：进程正在从操作系统中退出，清理所占资源 5.挂起进程模型之前讨论的状态都是和CPU有关系的状态。但实际上进程的状态中还有一类和存储相关，一部分存储在外存和虚拟存储关联，这就是牵扯到挂起状态。 这是进程挂起的一个状态模型图，可以看出里面和之前相比，多了等待挂起、就绪挂起这两种状态，新加的这两种状态是为了描述进程在外存中的状态。 1.等待挂起：进程在外存并等待某事件的出现（相当于在等待的基础上加了进程的位置的信息） 2.就绪挂起：进程在外存，但是只要进入内存，即可运行。 挂起：把一个进程从内存转到外存。 下面我来阐述一下内存到外存的转变(挂起)： 1.等待–&gt;等待挂起: 没有进程处于就绪状态或者就绪进程要求更多内存资源。 2.就绪–&gt;就绪挂起 当有高优先级等待（系统认为很快就会就绪的）进程和低优先级就绪进程，为了让高优先级有足够的就绪空间，低优先级就绪进程就变成挂起就绪 3.运行–&gt;就绪挂起 对抢占时分时系统，当有高等优先级进程进入就绪要运行，但是没有足够的内存空间，那么正在运行的低优先级变成挂起就绪状态 上面是内存–&gt;外存状态的切换 下面介绍一下在外存中的状态转换 1.等待挂起–&gt;就绪挂起 当有等待挂起进程因相关事件出现 下面在说一下从外存到内存的状态转换（激活：把一个进程从外存转到内存） 1.就绪挂起–&gt;就绪 没有就绪进程或挂起就绪进程优先级高于就绪进程 2.等待挂起–&gt;等待 当一个进程释放足够的内存，并且有高优先级等带挂起进程。 到这里关于状态装换就说完了。。。 下面来讨论线程部分 线程线程的提出原因：多个进程之间切换调度耗费资源，进程间通信困难，效率低下，所以需要多线程。可以在 进程内实现并发执行，并且共享实体之间的地址空间。 线程的概念 ：线程是进程的一部分，描述指令执行流的状态，他是进程中指令执行的最小单元，是CPU调度的基本单位。将进程的执行流分离出来，为并发提供更好的可能 ‘","categories":[{"name":"系统学习","slug":"系统学习","permalink":"http://yoursite.com/categories/系统学习/"}],"tags":[]},{"title":"布隆过滤器（哈希应用）","slug":"布隆过滤器","date":"2018-05-09T23:28:24.000Z","updated":"2018-05-15T15:13:41.981Z","comments":true,"path":"2018/05/10/布隆过滤器/","link":"","permalink":"http://yoursite.com/2018/05/10/布隆过滤器/","excerpt":"","text":"布隆过滤器的简单介绍 因为位图虽然可以节省空间，但是只能给整形使用。所以还不能满足我们的需求。 所以就有了我们今天的核心，布隆过滤器。比起位图的优势，布隆过滤器可以针对各种类型来处理 但是不布隆过滤器会有一个致命的缺点—&gt;误判，即判断存在的情况可能不准确（产生哈希冲突），判断不存在是准确的，不存在有误判因为可能多个元素映射到同一个位置。那么误判可以解决吗？不能！但是可以去缓解误判。缓解的方法就是把一个值可以映射到多个位置，即多次映射，从而减少产生哈希冲突（记住这里只是减少，但是不能绝对的避免）。规定：如果空间有限，你映射的位置越多，误判率越低，但是空间占有率就变多了。所以这里就需要取一个适中的映射尺度。 原理 在哈希算法的思想上加上位图从而可以实现高效的查找，具体做法是将一个key，通过k各哈希函数产生K个表示码，然后将这些标识码对应位图中的位置置为1，那么再查找的时候就根据刚才的算法分别判断对应的位置是否都是1，如果全部满足，则元素存在，否则不存在 实现代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108#pragma once#include\"BitSet.h\"template&lt;class K&gt;struct HashFunc1&#123; size_t BKDRHash(const char *str) &#123; register size_t hash = 0; while (size_t ch = (size_t)*str++) &#123; hash = hash * 131 + ch; &#125; return hash; &#125; size_t operator()(const string&amp; key) &#123; return BKDRHash(key.c_str()); &#125;&#125;;template&lt;class K&gt;struct HashFunc2&#123; size_t SDBMHash(const char *str) &#123; register size_t hash = 0; while (size_t ch = (size_t)*str++) &#123; hash = hash * 65599 + ch; &#125; return hash; &#125; size_t operator()(const string&amp; key) &#123; return SDBMHash(key.c_str()); &#125;&#125;;template&lt;class K&gt;struct HashFunc3&#123; size_t RSHash(const char *str) &#123; register size_t hash = 0; size_t magic = 63689; while (size_t ch = (size_t)*str++) &#123; hash = hash * magic + ch; magic *= 378551; &#125; return hash; &#125; size_t operator()(const string&amp; key) &#123; return RSHash(key.c_str()); &#125;&#125;;//哈希映射次数K=位数/数据个数*0.7（ln2）----&gt;总位数=K/数据个数template&lt;class K=string, class HashFunc1=HashFunc1&lt;K&gt;, class HashFunc2=HashFunc2&lt;K&gt;, class HashFunc3=HashFunc3&lt;K&gt;&gt;class BloomFilter&#123;protected: BitSet _bs; size_t _rang;//范围public: BloomFilter(size_t num)//数据个数 :_bs(num * 5) , _rang(num * 5)&#123;&#125; void Set(const K&amp; key) &#123; size_t hash1 = HashFunc1()(key);//转换为整形的方式 size_t hash2 = HashFunc2()(key); size_t hash3 = HashFunc3()(key); _bs.Set(hash1%_rang); _bs.Set(hash2%_rang); _bs.Set(hash3%_rang); &#125; //void Reset(const K&amp; key) bool Test(const K&amp; key) &#123; size_t hash1 = HashFunc1()(key);//转换为整形的方式.哈希函数 if (_bs.Test(hash1%_rang) == false) return false; size_t hash2 = HashFunc2()(key); if (_bs.Test(hash2%_rang) == false) return false; size_t hash3 = HashFunc3()(key); if (_bs.Test(hash3%_rang) == false) return false; return true;//不准确的，存在误判 &#125;&#125;;void TestBloomFilter()&#123; BloomFilter&lt;&gt; bf(10); bf.Set(\"sort\"); bf.Set(\"bloom\"); bf.Set(\"filter\"); bf.Set(\"bloomfilter\"); cout &lt;&lt; bf.Test(\"sort\"); cout &lt;&lt; bf.Test(\"bloom\"); cout &lt;&lt; bf.Test(\"sort1\");&#125; 下面给出关于布隆过滤器博客https://segmentfault.com/a/1190000002729689http://www.cnblogs.com/haippy/archive/2012/07/13/2590351.html","categories":[{"name":"数据结构随笔","slug":"数据结构随笔","permalink":"http://yoursite.com/categories/数据结构随笔/"}],"tags":[{"name":"布隆过滤器","slug":"布隆过滤器","permalink":"http://yoursite.com/tags/布隆过滤器/"}]},{"title":"页面置换算法","slug":"页面置换算法","date":"2018-05-08T11:22:49.000Z","updated":"2018-05-13T03:19:17.210Z","comments":true,"path":"2018/05/08/页面置换算法/","link":"","permalink":"http://yoursite.com/2018/05/08/页面置换算法/","excerpt":"1.页面置换算法的概念功能：当出现缺页异常，需要调入新的页面内存已经满时，置换算法选择被置换的物理页面","text":"1.页面置换算法的概念功能：当出现缺页异常，需要调入新的页面内存已经满时，置换算法选择被置换的物理页面设计目标： 1.尽可能的减少页面的调入调出次数 2.把未来的不在访问的或者短期内部访问的页面调出（这里的核心难点就在于如何知道未来不经常访问的页面呢） 注意：在说置换算法算法之前强调一点，就是页面锁定，即一些页面被锁定以后不能被置换到外存里面去，这些页面一般是描述常驻内存的逻辑页面，或者操作系统关键部分，或者是要求相应速度的代码和数据，只需要在对应的页表中将其锁定标志位置为1就可以了 2.局部页面置换算法1.最优页面置换算法（OPT）基本思路：置换在未来最长时间不访问的页面。 算法实现：缺页的时候，计算内存中每个逻辑页面的下一次访问的时间，然后选择未来最长时间不访问的页面置换出去 算法的特征： 1.缺页最少 2.实际系统中无法实现 3.无法预知每个页面在下一次访问前的等待时间。 既然这个算法在实际系统中无法实现为什么我们还要说这个算法呢？ 因为我们可以根据这个算法来衡量其他设计的算法的性能，比如我们模拟某个程序运行，第一次记录每个页面的访问时间，第二次不就可以使用最优算法了。 下面给出算法的模拟实现图： 2.先进先出算法（FIFO）思路： 选择在内存中驻留时间最长的页面进行置换（驻留的时间越长不就是最先进来的嘛） 实现： 维护一个记录所有位于内存中的逻辑页面的链表，链表中的结点按驻留在内存中时间排序（时间最长的在链表头部，时间最短的在链表尾部），当出现缺页的时候，选择链表头部页面进行置换，新的页面添加到链尾。 特征： 实现简单；性能较差，调出的页面可能是经常访问的页面；进程分配物理页面数增加的时候，缺页不一定会减少（Belady现象）；很少单独使用，一般和其他算法一起使用。 3.最近最久未使用算法（LRU）思路：选择最长时间没有被引用的页面进行置换，如果某些页面长时间未被访问，则他们在将来可能还会长时间不会被访问。 实现：缺页时候，计算内存中每个逻辑页面的上一次访问时间，选择上一次使用到当前时间最长的页面 特征：最优置换算法的一种近似。 实现LRU的可能的手段 1.页面链表 系统维护一个按最近一次访问时间排序的链表，链表的首结点是最近刚刚使用的页面，链表尾结点是最久未使用的页面。 当访问内存的时候，找到相应的页面，并把他头插入结点，缺页时直接置换尾结点。 2.活动栈页面 访问页面的时候，将此页号压入栈顶，并将栈内相同页号抽出，缺页时，置换栈低的页面。 4.时钟页面置换算法（Clock）这个算法是FIFO和LRU算法的结合。 思路：仅对页面的访问情况进行大致统计。 数据结构： 在页表的表项中增加访问位，描述页面在过去的一段时间内的访问情况。 各页面组成形成环形链表，指针指向最先调入的页面 算法： 访问页面的时候，在页表项纪录页面访问情况，缺页的时候，从指针处开始顺序查找未被访问的页面进行替换。 算法的实现： 页面装入内存的时候，访问位初始化为0，访问页面（读/写）时，访问位置1，缺页的时候。从指针当前位置顺序检查环形链表。当访问位位0，则置换该页面，访问位为1.则访问位置0，并指针移动到下一个页面，直到找到可置换的页面。 下面给出时钟置换算法图示的演示图 特征：时钟算法是LRU和FIFO的折中 这个算法的缺点是，如果置换的页被修改过的话，那么还需要将修改过的页面保存，在进行替换，会比较低效，所以我们对这个算法进行改进 5.最不常用算法（LFU）也是对LRU的一种简化的算法 思路：缺页的时候置换过去时间内访问次数最少的页面 实现：每个页面加一个访问计数，访问页面的时候访问计数+1，缺页时，置换计数最小的页面 不过这个算法有个问题，就是一个页面可能被置换进来还没访问几次就又被置换出去了。但是有一个解决办法就是：对已经计数的计数值较大的呢，定期右移，即将计数较大的页面会计数减小增加置换出去的概率 LRU和LFU的区别 LRU关注多久未访问，时间越短越好LFU关注次数，这个更好的维护实现 致此局部置换算法就算描述完了，那么下面来讨论一下局部置换算法的一些相关问题 6.Belady现象现象：采用FIFO等算法时，当进程缺页次数比较大时，就要给其增加物理页面，但是可能出现分配给进程的物理页面增加，那么他的缺页率反而会增加的现象。 原因：FIFO算法法的置换特征与进程访问内存的动态特征所矛盾，即依照置换特征被置换出去的页面，近期可能又会被访问。但是LRU就没有Belady现象。 7.LRU、FIFO和CLock的比较 1.LRU和FIFO本质都是先进先出思路 LRU依据页面最近访问时间排序，LRU需要动态的调整顺序，FIFO依据页面进入内存的时间排序，FIFO页面进入时间是固定不变得。 LRU可退化成FIFO：比如页面进入内存后没有被访问，最近访问时间与进入内存的时间相同。","categories":[{"name":"系统学习","slug":"系统学习","permalink":"http://yoursite.com/categories/系统学习/"}],"tags":[{"name":"存储","slug":"存储","permalink":"http://yoursite.com/tags/存储/"}]},{"title":"虚拟存储","slug":"虚拟存储","date":"2018-05-06T01:12:42.000Z","updated":"2018-05-13T03:19:00.600Z","comments":true,"path":"2018/05/06/虚拟存储/","link":"","permalink":"http://yoursite.com/2018/05/06/虚拟存储/","excerpt":"首先介绍一下本节的核心知识点： 虚拟存储的需求背景 覆盖技术 交换技术 局部性原理 虚拟存储概念 虚拟页式存储 缺页异常","text":"首先介绍一下本节的核心知识点： 虚拟存储的需求背景 覆盖技术 交换技术 局部性原理 虚拟存储概念 虚拟页式存储 缺页异常 1.虚拟存储的需求背景 需求的原因：因为一些大量的并发线程或者进程的运行,计算机系统时常出现内存空间不够用，所以最终诞生了虚拟存储的这中技术需求 内存不够用的一些解决办法： 1.覆盖：应用程序手动的把需要的指令和数据保存在内存中 2.交换：操作系统自动把暂时不能执行的程序保存到外存中 3.虚拟内存：在有限的容量内存中，以页为单位自动装入更多更大的程序。 2.覆盖和交换技术覆盖技术目标：在较小的可用内存中运行较大的程序 实现方法：依据程序的逻辑结构（这里我的理解就是各个函数直接的结构钢关系），将程序划分为若干功能相对独立的模块，将不会同时执行的模块共享一块存储区域（这里的意思就是没有调用关系的函数模块可以共享一块存储区域） 在这里要注意这么几点： 1.必要部分（常用功能）的代码和数据常驻内存中 2.可选部分（不常用的功能）放在其它程序的模块中，只在需要的时候装入到内存中 3.不存在 相互调用关系的模块可以相互覆盖，共同用一块内存区域，只不过他们之间需要换来换去。 下面用图示说明问题： 将不存在调用关系的模块分成一组，选取每组中占用内存最大的分配内存，然后根据调用关系去换出换入就可以了！ 覆盖技术的缺点： 1增加了编程的难度 程序员需要自己去合理设计每个函数之间的调用关系 2.增加了执行的时间 频繁从外存装入内存的覆盖区域中。 这是一种时间换去空间的做法。 交换技术 目标：是针对有很多应用程序运行的时候，内存空间不够用了，而不是像覆盖技术那样，一个应用程序运行内存空间都不够用。 实现：将当前暂时不能运行的程序放到外存，这里要注意的是，换入换出的基本单位是整个进程的地址空间放入外存或者放回内存 交换技术面临的问题： 1.交换时机：只有当内存空间不够或者可能不够的时候换出 2.交换区的大小：存放用户空间所有内存映像的拷贝 3.程序换入时的重定向：采用动态地址映射 下面对于交换和覆盖进行比较： 覆盖： 1.只能发生在 没有调用的模块关系间 2.程序员要给出模块的覆盖关系 3.发生在运行的程序的内部模块之间 交换： 1.以进程为单位 2.不需要模块之间的逻辑覆盖结构 3.发生在内存进程间 3.局部性原理 概念：程序在执行过程中的一个较短的时间，所执行的指令地址和指令操作数地址，分别局限于一定的区域。 时间局部性：一条指令的一次执行和下次执行，一个数据的一次访问和下次访问都是集中在一个较短的时期内 空间局部性：当前指令和邻近的几条指令，当前访问的数据和邻近的几个数据都集中在一个较小的区域内 分支局部性：一条跳转指令的两次执行，很可能跳到相同的内存位置 4.虚拟存储的概念思路：将不常用的部分内存块暂时放到外存中 原理：装在程序的时候只是将当前执行需要的部分页面或者段装入内存，在执行执行的过程中需要的指令或者数据不在内存的时候（成为缺页），处理器通知操作系统将相应的页面或者段调入内存中去，当然还需要操作系统维护内存将暂时不用的页面或者段保存到外存中去。 实现方式：基于之前的非连续存储方式中的段式存储和页式存储，所以这里也分为虚拟段式和虚拟页式存储。 虚拟存储的特点 ： 1.物理内存和虚拟内存都可以不连续 2.大用户空间，提供给用户的虚拟内存大于实际内存。 3.部分交换技术，虚拟存储只对部分虚拟地址空间进行调入和调出 虚拟存储的技术支持： 1.硬件：页式或短时存储中的地址映射转换机制（MMU） 2.操作系统：管理内存和外存间的页面或者段的换出换入 5.虚拟页式存储管理概念：就是在非连续存储页式存储的 基础上，加上请求调页和页面置换 思路： 1.当用户程序要装在到内存运行时候，只装入部分页面，就启动运行程序 2.进程在运行中发现有需要的代码或者数据不在内存中时，则向系统发出缺页异常请求 3.操作系统在处理缺页异常的时候，将外存的相应页面调入内存，使得程序能继续执行 6.缺页异常","categories":[{"name":"系统学习","slug":"系统学习","permalink":"http://yoursite.com/categories/系统学习/"}],"tags":[{"name":"存储","slug":"存储","permalink":"http://yoursite.com/tags/存储/"}]},{"title":"哈希表","slug":"哈希表","date":"2018-05-05T02:45:39.000Z","updated":"2018-05-15T10:57:41.134Z","comments":true,"path":"2018/05/05/哈希表/","link":"","permalink":"http://yoursite.com/2018/05/05/哈希表/","excerpt":"","text":"哈希表的基本相关的概念 简单说一下哈希算法的核心思想吧：即给定一个值，通过一个转换的方式给出一个特定的结果（这个结果是这个值得存储位置），然后将这个结果存储起来。这样的话我们查找的时候就可以根据这个转换的方式得到的结果去找我们要的元素。就可以0（1）的时间复杂度中找到我们要的元素，所以哈希的查找是相当的厉害的。应用也很广泛。哈希表就是构建一个这种对应关系的表（也叫散列表）。转换的方式就是散列函数。 哈希表的构建的方法有如下几种： 直接定址法：hash(key)=key*i+j; 除留余数法 折叠法 随机数法 数学分析法 上面的方法我重点说第二种，因为后三种不常用，第一种太简单，适用于局部性的常见。 除留余数法即除以小于表长的最大质数时比较好。但是这种方法会产生哈希冲突(哈希碰撞)：即不同的数字，模出来的结果是一样的，那么怎么解决呢？ 解决哈希冲突的方法： 闭散列法（又叫开放定址法），线性探测和二次探测（自己去了解很简单的概念） 开散列法（又叫链地址法，哈希桶） 闭散列法 首先给出哈希表的框架 哈希表的框架12345678910111213141516171819202122232425262728enum State//描述哈希表的状态，方便我们添加和删除&#123; EXIST, EMPTY, DELETE,&#125;;template&lt;class K,class V&gt;//哈希结点的内容我们使用的是key和value键值对的方式struct HashTableNode&#123; K _key; V _value; State state; HashTableNode(const K&amp; key = K(), const V&amp; value = V()) :_key(key) , _value(value) , state(EMPTY)&#123;&#125;&#125;;template&lt;class K,class V&gt;class HashTable&#123;public: typedef HashTableNode&lt;K, V&gt; Node; HashTable() :_size(0)&#123;&#125;private: vector&lt;Node&gt; _tables; size_t _size;//统计哈希表中扔进去了多少个，因为我们删除并不是删除而只是改了其state状态,所以不能用vector的size功能&#125;; 这是哈希表最基础的框架，后面我们会在次框架基础上引用仿函数，主要用来处理字符串类型的关键码取值、和加入迭代器 哈希表要实现的功能 Insert(插入)，这里要注意的问题是如果哈希表满了的话就会陷入死循环的寻找位置，所以在插入之前我们要进行扩容 CheckCapacity（扩容）,扩容牵扯到的问题就是什么时候进行扩容，还有扩多大 比较合适呢？ 扩容时机：一般来说扩容时机取决于哈希表的负载因子，负载因子=表中元素个数/散列表的长度，负载因子一般取0.7，这样就时刻保证了哈希表都有空位置，而不至于出现高负载的情况 扩容后的大小一般来说是小于容量的最大素数，这里有现成的素数表给我们使用，扩容以后要将原表中的元素再次进行映射到增容的表中 Erase（删除） ，由于随便删除会影响哈比表的删除，所以我们只是将其对应的状态置为删除，方便辨认就可以了，不然会印象后面的查找 Find(查找),使用散列函数Hashfunc，直接去找对应的元素 HashFunc(散列函数)，这里要注意的是这个散列函数可以处理字符串数据并且能给你一个特殊的key，因为字符串很容易产生错误，多个字符串对应相同的key,所以有专门的字符串处理函数(这里就要用到仿函数或者函数特化) 代码实现 首先给出处理字符串和整形key值的解决方案，这里分别使用了两种方法 模板特化 1234567891011121314151617181920212223242526template&lt;class K&gt;struct Hashkey&#123; size_t operator()(const K&amp; key) &#123; return key; &#125;&#125;;template&lt;&gt;struct Hashkey&lt;string&gt;&#123; static size_t BKDRHash(const char*str) &#123; unsigned int seed = 131;// 31 131 1313 13131 131313 unsigned int hash = 0; while (*str) &#123; hash = hash*seed + (*str++); &#125; return(hash &amp; 0x7FFFFFFF); &#125; size_t operator()(const string &amp;key) &#123; return BKDRHash(key.c_str()); &#125;&#125;; 仿函数 1234567891011121314151617181920212223242526template&lt;class K&gt;struct Hashkey&#123; size_t operator()(const K&amp; key) &#123; return key; &#125;&#125;;template&lt;class K&gt;struct Hashstring&#123; static size_t BKDRHash(const char*str) &#123; unsigned int seed = 131;// 31 131 1313 13131 131313 unsigned int hash = 0; while (*str) &#123; hash = hash*seed + (*str++); &#125; return(hash &amp; 0x7FFFFFFF); &#125; size_t operator()(const K&amp;key) &#123; return BKDRHash(key.c_str()); &#125;&#125;; 整体代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std;enum State//描述哈希表的状态，方便我们添加和删除&#123; EXIST, EMPTY, DELETE,&#125;;template&lt;class K&gt;struct Hashkey&#123; size_t operator()(const K&amp; key) &#123; return key; &#125;&#125;;template&lt;class K&gt;struct Hashstring&#123; static size_t BKDRHash(const char*str) &#123; unsigned int seed = 131;// 31 131 1313 13131 131313 unsigned int hash = 0; while (*str) &#123; hash = hash*seed + (*str++); &#125; return(hash &amp; 0x7FFFFFFF); &#125; size_t operator()(const K&amp;key) &#123; return BKDRHash(key.c_str()); &#125;&#125;;//template&lt;&gt;//struct Hashkey&lt;string&gt;//&#123;// static size_t BKDRHash(const char*str)// &#123;// unsigned int seed = 131;// 31 131 1313 13131 131313// unsigned int hash = 0;// while (*str)// &#123;// hash = hash*seed + (*str++);// &#125;// return(hash &amp; 0x7FFFFFFF);// &#125;// size_t operator()(const string &amp;key)// &#123;// return BKDRHash(key.c_str());// &#125;//&#125;;template&lt;class K,class V&gt;//哈希结点的内容我们使用的是key和value键值对的方式struct HashTableNode&#123; K _key; V _value; State _state; HashTableNode(const K&amp; key = K(), const V&amp; value = V()) :_key(key) , _value(value) , _state(EMPTY)&#123;&#125;&#125;;template&lt;class K, class V, class SetHashKey = Hashkey&lt;int&gt;&gt;class HashTable&#123;public: typedef HashTableNode&lt;K, V&gt; Node; HashTable() :_size(0)&#123;&#125;private: vector&lt;Node&gt; _tables; size_t _size;//统计哈希表中扔进去了多少个，因为我们删除并不是删除而只是改了其state状态,所以不能用vector的size功能public: bool Insert(const K&amp; key, const V&amp; value)//查找 &#123; CheckCapacity(); if(Find(key)) return false; size_t index = HashFunc(key); while (_tables[index]._state== EXIST) &#123; ++index; if (index == _tables.size()) &#123; index = 0; &#125; &#125; _tables[index]._state = EXIST; _tables[index]._key = key; _tables[index]._value = value; ++_size; return true; &#125; Node* Find(const K&amp; key) &#123; size_t index = HashFunc(key); while (_tables[index]._state != EMPTY) &#123; if (_tables[index]._key == key)//找到了这个元素 &#123; if (_tables[index]._state == EXIST)//找到了并且标记没有删除是存在 &#123; return &amp;_tables[index]; &#125; else &#123; return NULL; &#125; &#125; ++index; if (index == _tables.size()) index = 0; &#125; return NULL; &#125; size_t GetNextPreimeNum(size_t num)//素数表 &#123; const int _PrimeSize = 28; static const unsigned long _PrimeList[_PrimeSize] = &#123; 53ul, 97ul, 193ul, 389ul, 769ul, 1543ul, 3079ul, 6151ul, 12289ul, 24593ul, 49157ul, 98317ul, 196613ul, 393241ul, 786433ul, 1572869ul, 3145739ul, 6291469ul, 12582917ul, 25165843ul, 50331653ul, 100663319ul, 201326611ul, 402653189ul, 805306457ul, 1610612741ul, 3221225473ul, 4294967291ul &#125;; for (size_t i = 0; i &lt; _PrimeSize; ++i) &#123; if (_PrimeList[i]&gt;num) &#123; return _PrimeList[i]; &#125; &#125; return _PrimeList[_PrimeSize - 1]; &#125; void CheckCapacity() &#123; if(_tables.size()==0||_size * 10 / _tables.size() * 10 &gt;= 7)//满足这个条件才开始扩容 &#123; if (_tables.size() == 0) &#123; _tables.resize(GetNextPreimeNum(3), NULL);//除了给空间还可以给值 return; &#125; size_t newsize = GetNextPreimeNum(_tables.size()); if (newsize == _tables.size()) return; HashTable&lt;K, V&gt; newtable; newtable._tables.resize(newsize); for (size_t i = 0; i &lt; _tables.size(); i++) &#123; if (_tables[i]._state == EMPTY) &#123; newtable.Insert(_tables[i]._key, _tables[i]._value); &#125; &#125; _tables.swap(newtable._tables); &#125; &#125; bool Erase(const K&amp; key) &#123; Node* node = Find(key); if (node) &#123; node-&gt;_state = DELETE; --_size; &#125; else &#123; return false; &#125; &#125; size_t HashFunc(const K&amp; key)//专门生成唯一标识码的主题 &#123; SetHashKey hf; return hf(key) % _tables.size(); &#125;&#125;;int main()&#123; int a[] = &#123; 89, 18, 49, 58, 9 &#125;; HashTable&lt;int, int&gt; ht; for (size_t i = 0; i &lt; sizeof(a) / sizeof(*a); i++) &#123; ht.Insert(i, a[i]); &#125; cout &lt;&lt; ht.Find(6)-&gt;_value&lt;&lt; endl; system(\"pause\"); return 0;&#125; 上面我们在插入的时候用的是线性探测，这个时候容易产生哈希碰撞，所以我们就使用二次探测，即当前位置如果冲突以后就不是index++了，而是index+1^2,如果还冲突则就是index+2^2，以此类推。 闭散列的缺点：运用顺序表存储，存储效率较高，但容易产生堆积，查找不易实现，需要用到二次再查找。 开散列法（链地址法）算法介绍 开散列法首先对关键码集合用散列函数计算散列地址，具有相同地址的关键码归于同一子集合，每一个子集合称为一个桶，各个桶中的元素通过一个单链表链接起来，各链表的头结点组成一个向量，因此，向量的元素个数与可能的桶数一致 通常，每个桶中的同义词子表都很短，设有n个关键码通过某一个散列函数，存放到散列表中的m个桶中，那么每一个桶中的同义词子表的平均长度为n/m。这样以搜索平均长度为n/m的同义词子表代替了搜索长度为n的顺序表，搜索效率快的多。应用链地址法处理溢出，需要增设链接指针，似乎增加了存储开销。事实上，由于开地址法必须保持大量的空闲空间以确保搜索效率，如二次探查法要求装载因子a &lt;= 0.7 而表项所占空间又比指针大的多，所以使用链地址法反而比开地址法节省存储空间。 代码实现-由于有了全面的代码铺垫这里我就直接给出全部代码+迭代器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261#pragma once#include&lt;iostream&gt;#include&lt;vector&gt;#include&lt;string&gt;using namespace std;template&lt;class V&gt;struct HashNode&#123; V _v;//set-&gt; map-&gt;kv HashNode&lt;V&gt;* _next; HashNode(const V&amp; v) :_v(v) , _next(NULL)&#123;&#125;&#125;;template&lt;class K&gt;struct Hash&#123; size_t operator()(const K&amp; key) &#123; return key; &#125;&#125;;template&lt;&gt;struct Hash&lt;string&gt;&#123; size_t operator()(const string&amp; s) &#123; return s[0]; &#125;&#125;;template&lt;class K, class V, class KeyofValue, class _HashFunc&gt;class HashTable;//迭代器template&lt;class K, class V, class KeyOfvalue,class _HashFunc&gt;struct _HashTableIterator&#123;private: typedef _HashTableIterator&lt;K, V, KeyOfvalue,_HashFunc&gt; Self; typedef HashNode&lt;V&gt; Node; typedef HashTable&lt;K, V, KeyOfvalue,_HashFunc&gt; HT; Node* _node; HT* _ht;public: //在这里不需要--，即可以是单向迭代器 _HashTableIterator(Node* node, HT* ht) :_node(node) , _ht(ht)&#123;&#125; V&amp; operator*() &#123; return _node-&gt;_v;//如果是map的话,那么返回的是pair &#125; V* operator-&gt;() &#123; return &amp;(operator*()); &#125; Self operator++() &#123; if (_node-&gt;_next) &#123; _node = _node-&gt;_next; &#125; else &#123; KeyOfvalue kov; size_t index = _ht-&gt;HashFunc(kov(_node-&gt;_v),_ht-&gt;_tables.size()); ++index; while (index &lt; _ht-&gt;_tables.size()) &#123; if (_ht-&gt;_tables[index] != NULL) &#123; _node = _ht-&gt;_tables[index]; break; &#125; else &#123; ++index; &#125; &#125; if (index == _ht-&gt;_tables.size()) &#123; _node = NULL; &#125; &#125; return *this; &#125; Self operator++(int)//后置++ &#123; Self tmp(*this); ++*this; return tmp; &#125; bool operator==(const Self&amp; s) const &#123; return _node == s._node; &#125; bool operator!=(const Self&amp; s) const &#123; return _node != s._node; &#125;&#125;;template&lt;class K,class V,class KeyofValue,class _HashFunc=Hash&lt;K&gt;&gt;class HashTable&#123;public: typedef HashNode&lt;V&gt; Node; friend struct _HashTableIterator&lt;K, V, KeyofValue,_HashFunc&gt;;public: typedef _HashTableIterator&lt;K, V, KeyofValue,_HashFunc&gt; Iterator; Iterator Begin() &#123; for (size_t i = 0; i &lt; _tables.size(); ++i) &#123; if (_tables[i]) &#123; return Iterator(_tables[i],this); &#125; &#125; return End(); &#125; Iterator End() &#123; return Iterator(NULL,this); &#125; HashTable() :_size(0)&#123;&#125; pair&lt;Iterator,bool&gt; Insert(const V&amp; v) &#123; CheckCapacity(); KeyofValue kov; size_t index = HashFunc(kov(v),_tables.size());//用来防止是pair Node* cur = _tables[index]; while (cur) &#123; if (kov(cur-&gt;_v) == kov(v))//不能插入重复的元素 &#123; return make_pair(Iterator(cur,this),false); &#125; cur = cur-&gt;_next; &#125; Node* node = new Node(v); //头插 node-&gt;_next = _tables[index]; _tables[index] = node; ++_size; return make_pair(Iterator(node,this),true); &#125; size_t HashFunc(const K&amp; key,size_t size) &#123; _HashFunc kov; return kov(key)%size; &#125; size_t GetNextPreimeNum(size_t num)//素数表 &#123; const int _PrimeSize = 28; static const unsigned long _PrimeList[_PrimeSize] = &#123; 53ul, 97ul, 193ul, 389ul, 769ul, 1543ul, 3079ul, 6151ul, 12289ul, 24593ul, 49157ul, 98317ul, 196613ul, 393241ul, 786433ul, 1572869ul, 3145739ul, 6291469ul, 12582917ul, 25165843ul, 50331653ul, 100663319ul, 201326611ul, 402653189ul, 805306457ul, 1610612741ul, 3221225473ul, 4294967291ul &#125;; for (size_t i = 0; i &lt; _PrimeSize; ++i) &#123; if (_PrimeList[i]&gt;num) &#123; return _PrimeList[i]; &#125; &#125; return _PrimeList[_PrimeSize - 1]; &#125; void CheckCapacity()//扩容 &#123; if (_tables.size() == 0) &#123; _tables.resize(GetNextPreimeNum(1), NULL);//除了给空间还可以给值 &#125; else if (_size == _tables.size())//负载因子到了要进行增容 &#123; size_t newsize = GetNextPreimeNum(_tables.size()); if (newsize == _tables.size()) return; vector&lt;Node*&gt; newtables; newtables.resize(newsize,NULL); KeyofValue kov; for (size_t i = 0; i &lt; _tables.size(); ++i) &#123; Node* cur = _tables[i]; while (cur) &#123; size_t index = HashFunc(kov(cur-&gt;_v),newsize);//计算新位置 Node* next = cur-&gt;_next; //头插到桶中去 cur-&gt;_next = newtables[index]; newtables[index] = cur; cur = next; &#125; _tables[i] = NULL; &#125; swap(_tables, newtables); //为什么开放地址法不能这么做呢? //可以这么做，但是太过于复杂 &#125; &#125; Node* Find(const K&amp; key) &#123; size_t index = HashFunc(key,_tables.size()); Node* cur = _tables[index]; KeyofValue kov; while (cur) &#123; if (keykov(cur-&gt;_v) == key) &#123; //return cur; return Iterator(cur,this) &#125; cur = cur-&gt;_next; &#125; //return NULL; return Iterator(NULL, this); &#125; bool Remove(const K&amp; key)//删除元素 &#123; KeyofValue kov; size_t index = HashFunc(key); Node* cur = _tables[index]; if (cur == NULL) return false; if (kov(cur-&gt;_v) == key) &#123; _tables[index] = cur-&gt;_next; delete cur; return true; &#125; else &#123; Node* prev = cur; cur = cur-&gt;_next; while (cur) &#123; if (kov(cur-&gt;_v) == key) &#123; prev-&gt;_next = cur-&gt;_next; delete cur; return true; &#125; prev = cur; cur = cur-&gt;_next; &#125; return false; &#125; &#125;private: vector&lt;Node*&gt; _tables; size_t _size; &#125;; 上面的给出的哈希桶是我们已经给封装Hash_map和Hash_set做好了准备之后的代码，如果需要封装map的话我们使用pair&lt;K,V&gt;,否则我们使用k就可以了. 一致性哈希未完待续….","categories":[{"name":"数据结构随笔","slug":"数据结构随笔","permalink":"http://yoursite.com/categories/数据结构随笔/"}],"tags":[{"name":"哈希表","slug":"哈希表","permalink":"http://yoursite.com/tags/哈希表/"}]},{"title":"操作系统01","slug":"操作系统01","date":"2018-05-05T02:45:39.000Z","updated":"2018-05-11T10:01:30.453Z","comments":true,"path":"2018/05/05/操作系统01/","link":"","permalink":"http://yoursite.com/2018/05/05/操作系统01/","excerpt":"问题1：分段和分页有什么区别？答：分页和分段有着许多相同之处比如两者都是采用离散分配方式，并且都是需要采取地址映射实现虚拟地址的变换。但是两个又有着许多不不同之处，下面主要强调一下二者的区别。","text":"问题1：分段和分页有什么区别？答：分页和分段有着许多相同之处比如两者都是采用离散分配方式，并且都是需要采取地址映射实现虚拟地址的变换。但是两个又有着许多不不同之处，下面主要强调一下二者的区别。1.页信息是物理单位，采取分页的方式能够更好的消除内存碎片，提高内存的利用率，分页仅仅只是系统的需要，完全是系统的行为，对于用户是不可见的。分段的话则是一种逻辑上的范围，分段更好的是处于用户的需要，一个程序的指令可能会跨越两个页的分介处，但是不会跨越一个段的。 2.页的大小通常是固定的，而段不固定，取决于程序的需求。 3.分页的用户的逻辑地址空间是一维的，分段是二维的，程序员在表示一个地址的时候既要给出段名字，又要给出段内地址 4通常页比段小，因而段表比页表小，所以可以提高查找的效率。 问题2：请简单说一说进程和线程，以及他们的区别？答：首先分别从进程和线程的概念入手说一说： 进程：在一定的环境下，把静态的程序代码运行起来，通过使用不同的资源，来完成一定的任务。比如说，进程的环境包括环境变量，进程所掌控的资源，有中央处理器，有内存，打开的文件，映射的网络端口等等。系统会为其创建进程控制块，为其分配资源，进程有自己独立的地址空间，页表等。进程在一定的意义上来说是CPU最小的的资源分配单位 这里给出一个我觉得解释比较好的陈述：进程是资源（CPU、内存等）分配的基本单位，它是程序执行时的一个实例。程序运行时系统就会创建一个进程，并为它分配资源，然后把该进程放入进程就绪队列，进程调度器选中它的时候就会为它分配CPU时间，程序开始真正运行。 线程：轻量级进程，属于进程的一部分，扮演的角色主要就是利用中央处理器执行代码。更多的线程是进程的执行路径。想线程共享进程的数据，但是也有自己独立的一部分数据，栈空间，寄存器，errno,信号,屏蔽字，调度优先级。 其实两者都是CPU工作时间段的描述，只不过两个的大小不一样，进程的切换需要分配一系列资源，保存上下文，而然线程不要，只需要保存其上下文，所以某种意义上来说，进程主要用来分配资源，线程用来执行任务的。 下面官方式的说一说二者的区别，上面主要从理解的角度来说得。面试的话总的说得比较官方吧 https://blog.csdn.net/laviolette/article/details/51506953 3.什么是死锁，死锁产生的条件？答：死锁的概念：进程竞争资源而造成的一种僵局。比如一个进程持有某个资源A，这个时候有它又去获取资源A这个时候就会陷入死锁状态。多个进程下，比如进程A持有资源B，进程B持有资源A，这个时候A去获取进程B持有的A资源，B进程去获取A进程持有的B资源，那么这个时候就会造成死锁的僵局。即A在等待B进程释放资源，B进程在等待A进程释放资源。如果没有外力的作用下，这种僵局将会一直持续下去。 产生死锁的条件： 1.互斥条件：即某个资源一段时间内只能被一个进程所占有。不能同时被两个或两个以上的进程占有。必须在该进程主动释放该资源以后其他进程才能占有该资源。此时如果有其他进程求情该资源，此请求进程只能等待，等到拥有该资源的进程释放该资源以后，自己方可获得该资源 2.求情与保持条件：即进程已经占有了一个资源，但是又去申请被其他进程正在占用的资源，此时请求进程被阻塞，对自己已获得的资源自己又不释放 3.不可剥夺条件：进程所占有的资源只能被自己释放，不能被其他进程强行夺走 4.循环等待条件：形成进程的循环等待链，即比如上面的例子中进程A和进程B就形成了一个循环等待的条件。 5.线程同步的方式有哪些？互斥锁信号量： 因为互斥锁只能讲资源锁住，这样虽然实现了多线程访问共享资源的同步问题，但是降低了多线程之间的并发性。使用信号量可以提高高并发性。用循环队列。定义两个信号量一个给生产者一个给消费者，当wait等于0，则造成调用该wait函数线程阻塞，当消费者有东西时唤醒 条件变量： 当我访问的资源需要满足一定的条件的时候我再去加锁，进行我的操作，否则不就不取和其他线程证，这样能够提高cpu的效率，避免不必要的争论。 读写锁：读共享，写独享，读优先级大于读优先级。悲观锁乐观锁","categories":[{"name":"面试题","slug":"面试题","permalink":"http://yoursite.com/categories/面试题/"},{"name":"操作系统","slug":"面试题/操作系统","permalink":"http://yoursite.com/categories/面试题/操作系统/"}],"tags":[{"name":"系统","slug":"系统","permalink":"http://yoursite.com/tags/系统/"}]},{"title":"网络01","slug":"网络01","date":"2018-04-28T08:55:17.000Z","updated":"2018-05-02T12:47:03.203Z","comments":true,"path":"2018/04/28/网络01/","link":"","permalink":"http://yoursite.com/2018/04/28/网络01/","excerpt":"问题1：TCP为什么需要三次握手四次断开？答：1.需要三次握手是为了：防止已经失效连接请求得报文段突然又传送到了服务器端，因为产生错误。这里所产生的的错误会导致服务器端陷入等待，虽然有保活计时器，但是也会浪费资源呀（这种错误是两次握手导致的结果）。","text":"问题1：TCP为什么需要三次握手四次断开？答：1.需要三次握手是为了：防止已经失效连接请求得报文段突然又传送到了服务器端，因为产生错误。这里所产生的的错误会导致服务器端陷入等待，虽然有保活计时器，但是也会浪费资源呀（这种错误是两次握手导致的结果）。下面详细解释一下为什么会产生这种错误：如果是两次握手的话那么相当于客户端发送SYN给服务器，然后服务器回送SYN+ACK以后服务器就会以为自己和客户端建立了连接，所以问题就来了，如果客户端第一次的SYN请求报文阻塞了，那么根据超时重传机制，那么会发送第二个SYN，第二次成功建立并且顺利完成数据交付并结束连接，这个时候第一个阻塞的报文到达了服务器端、那么服务器端就认为客户端又要和自己建立连接，这个时候发送SYN+ACK以后，服务器端就认为已经建立了连接，但是客户端并没有发送SYN，所以不会理会服务器端的 ，那么服务器就傻傻的等待客户端发送数据，是不是造成了一种资源的浪费。 还有比如采用两次连接的话，只要服务器端发送SYN+ACK，服务器端就建立了连接，那么如果服务器的SYN+ACK丢失了，服务器还是建立连接，客户端重发SYN，服务器又建立连接，这样会很浪费资源的。 如果建立连接换为4次的话，其实是可以的，即将服务器端收到客户端的SYN以后发送SYN+ACK拆成两步，只不过这么做有点多余。。。 2.需要四次挥手是因为：TCP是一个全双工的通信协议，即允许允许同时通信的双方同时进行数据的收发，同样也允许收发两个方向的连接被独立关闭，以避免client数据发送完毕，向server发送FIN关闭连接，而server还有发送到client的数据没有发送完毕的情况。也就是因为其有个半关闭的状态！ 问题2：TCP和UDP有什么区别？答：对于这个问题可以从三个方面来回答，1.最基本的一些区别，2.应用场景的区别，3.socket编程上面的区别。下面我来一个一个阐述 1.基本的区别：TCP是传输控制协议，提供的是面向连接、可靠的字节流服务。通信双方彼此交换数据前，必须先通过三次握手协议建立连接，之后才能传输数据。TCP提供超时重传，丢弃重复数据，检验数据，流量控制等功能，保证数据能从一端传到另一端。UDP是用户数据报协议，是一个简单的面向无连接的协议。UDP不提供复杂的控制机制，利用IP提供面向无连接的通信服务。并且它是将应用程序发来的数据在收到的那一刻，立刻按照原样发送到网络上的一种机制。即使是出现网络拥堵的情况下，UDP也无法进行流量控制等避免网络拥塞的行为。此外，传输途中如果出现了丢包，UDP也不负责重发。甚至当出现包的到达顺序乱掉时也没有纠正的功能。如果需要这些细节控制，那么不得不交给由采用UDP的应用程序去处理。换句话说，UDP将部分控制转移到应用程序去处理，自己却只提供作为传输层协议的最基本功能。UDP有点类似于用户说什么听什么的机制，但是需要用户充分考虑好上层协议类型并制作相应的应用程序UDP不提供可靠的服务。在数据数据前不用建立连接故而传输速度很快。所以TCP报文设计要比UDP复杂的多。http://lishuaii.top/2018/03/29/UDP%E6%A6%82%E8%BF%B0/ 这里给出UDP的介绍2.应用场景：1.面向数据报方式，网络数据大多为短消息，拥有大量Client，对数据安全性无特殊要求 ，网络负担非常重，但对响应速度要求高。比如即时通讯，视频通讯，这种情况使用UDP。反之使用TCP 下面给出常见应用使用的协议和端口号 http:TCP,80; https:TCP:443; ftp:TCP:21; smtp:TCP:25 sql:TCP:1433 dns:TCP:53 3.编程方面的区别： UDP在创建套接字使用的是SOCK_DGRAM而TCP使用的是SOCK_STREAM，UDP不使用Listen和accept、connect这三个函数，而TCP必须使用，UDP发送和接收消息需要sendto/recvfrom，而TCP可以使用send()和recv()，或者read()和write()，正是因为DUP没有三次握手的这个过程，所以看起来会比TCP编程简单很多。 问题3：交换机和路由器的区别1.工作的层次不同 最初的交换机是工作在链路层的（第二层），而路由器的在网络层。 2.数据转发依据的对象不同 交换机是利用物理地址或者可以说是MAC地址来确定转发的数据的目的地址。而路由器是根据不同的网络号即IP地址来确定数据转发的地址。IP是在软件中实现的，描述的是设备所在的网络，而MAC地址是硬件自带的，由网卡生产商类分配，而且已经固化到了网卡中去，一般来说是不可更改的，而IP地址通常由网络管理员或者系统系统分配。 3.交换机只能分割冲突不能分割广播，因为交换机所连的还是同一个局域网，即同一个广播域，而路由器可以分割广播，因为其可以连接不同的网段，即广播可以穿透路由器不能穿透广播。 问题4：TCP的流量控制所谓流量控制就是让发送方的发送速率不要太快，要让接收方来得及接收。利用滑动窗口实现流量控制，如果发送方把数据发送得过快，接收方可能会来不及接收，这就会造成数据的丢失。 在这里要强调一点：坚持计时器 目的：主要解决零窗口大小通知可能导致的死锁问题 死锁问题的产生：当接收端的窗口大小为0时，接收端向发送端发送一个零窗口报文段，发送端即停止向对端发送数据。此后，如果接收端缓存区有空间则会重新给发送端发送一个窗口大小，即窗口更新。但接收端发送的这个确认报文段有可能会丢失，而此时接收端不知道已经丢失并认为自己已经发送成功，则一直处于等待数据的状态；而发送端由于没有收到该确认报文段，就会一直等待对方发来新的窗口大小，这样一来，双方都处在等待对方的状态，这样就形成了一种死锁问题。如果没有应对措施，这种局面是不会被打破的。为了解决这种问题，TCP为每一个连接设置了坚持计时器。 工作原理：当发送端TCP收到接收端发来的零窗口通知时，就会启动坚持计时器。当计时器的期限到达时，发送端就会主动发送一个特殊的报文段告诉对方确认已经丢失，必须重新发送。【这个特殊的报文段就称为探测报文段，探测报文段只有1个字节的大小，里边只有一个序号，该序号不需要被确认，甚至在计算其他部分数据的确认时该序号会被忽略。 截止期的设置：设置为重传时间的值。但如果没有收到接收端的响应，则会发送另一个探测报文段，并将计时器的值加倍并复位，直到大于门限值（一般为60秒）。在此之后，发送端会每隔60秒发送一个探测报文段，直到窗口重新打开。（注意TCP的四个计时器） 问题5：TCP的拥塞控制http://lishuaii.top/2018/04/02/TCP%E5%8F%AF%E9%9D%A0%E4%BC%A0%E8%BE%93%E7%9A%84%E5%AE%9E%E7%8E%B0/链接中有详解！","categories":[{"name":"面试题","slug":"面试题","permalink":"http://yoursite.com/categories/面试题/"},{"name":"网络","slug":"面试题/网络","permalink":"http://yoursite.com/categories/面试题/网络/"}],"tags":[{"name":"网络","slug":"网络","permalink":"http://yoursite.com/tags/网络/"}]},{"title":"TCP可靠传输的实现","slug":"TCP可靠传输的实现","date":"2018-04-02T09:02:57.000Z","updated":"2018-04-02T14:02:15.737Z","comments":true,"path":"2018/04/02/TCP可靠传输的实现/","link":"","permalink":"http://yoursite.com/2018/04/02/TCP可靠传输的实现/","excerpt":"此篇博客的主要内容 1.TCP的拥塞控制 2.TCP的滑动窗口（实现流量控制）","text":"此篇博客的主要内容 1.TCP的拥塞控制 2.TCP的滑动窗口（实现流量控制） 1.拥塞控制首先你需要对于拥塞的概念有个了解，接下来才能去探究TCP是如何实现拥塞控制的。 拥塞：简单的说就是网络中对某一资源的需要量大于该资源所能提供的可用部分，那么就会造成网络的性能变差，这就叫做拥塞。因为产生网络拥塞的原因有很多，而且情况复杂所以处理起来就很麻烦。 TCP处理拥塞的机制：它使用了四种算法结合起来来合理的控制网络拥塞，即慢开始、拥塞避免、快重传、和快恢复。下面我就来详解介绍一下这种拥塞处理的机制 1.慢开始和拥塞避免 为了防止网络拥塞的问题产生，那么发送维持一个叫做拥塞窗口的状态变量，拥塞窗口的大小取决于网络的拥塞程度（即拥塞窗口是会变化的）。发送方让自己的发送窗口等于其拥塞窗口的大小。发送方对于这个定义的拥塞窗口的控制原则是只要网络没有出现拥塞的现象，则将拥塞窗口增大，只要发现或者察觉可能会出现拥塞则将窗口的值减小，通过这样来防止网络拥塞。那么发送端如何察觉即将或者可能发生了拥塞现象呢？ 他是这样做的，当网络发生拥塞的时候，路由器就会丢弃一些分组，所以当发送方没有在计数器范围内收到确认消息的话，就可以猜测是不是出现了网络拥塞。即判断条件就是是否出现了超时。 这是前面为讲解后续的算法做的一些铺垫你大概对于发送端如何判断及操作拥塞窗口有了一些了解以后，下面我们来讲具体的做法。 慢开始：最开始的时候对于网络的情况是未知的，所以将拥塞窗口cwnd=1,发送第一个报文，收到确认以后，cwnd=2,则发送两个报文，再两个都收到确认以后，cwnd=4,发送四个报文。。。以此类推。。这就是满开始，这里的慢并不是说cwnd的增长速度慢，而是说一开始将cwnd设置为1，这比起来一次性发送很多的报文，要慢的多。。当然如果仅仅是满开始肯定不行因为，随着cwnd的增多，发送的数据报越来越多，造成拥塞是肯定的，，所以就需要设置一个慢开始门限（ssthresh）,则当 cwnd&lt;ssrhresh时，继续保持慢开始 cwnd&gt;ssthresh时，停止使用慢开始算法而变成使用拥塞避免算法 cwnd=ssthresh时，即可以使用慢开始算法也可以使用拥塞避免算法 拥塞避免：不是像慢开始阶段那样成2 4 8 16 这样的增长，而是每经过一个往返时间RTT就把拥塞窗口加1,即一个轮询+1，好比 1 2 3 4 5这样的增长方式，比之前的慢增长方式慢。这里要理解这个拥塞避免就是防止产生拥塞。。下面来看一幅图 最开始到①之前都是慢启动，达到ssthresh以后开始实现拥塞避免，当拥塞窗口值达到24的时候，出现了超时，这个时候认为发生了网络阻塞。所以讲ssthresh的值调整为ssthresh=cwnd/2=12,然后继续开始慢启动，当拥塞窗口的值达到12时，继续使用拥塞避免，这个时候当拥塞窗口的值等于16的时候（④），发送方连续收到了三个ACK重复确认消息。那么这个时候发送方如何判断呢？？对于这个问题需要解释一下： 有时候个别报文会在网络中丢失但是并没有发生网络阻塞的现象。如果发送方迟迟收不到确认消息就会认为发生了网络拥塞，那么就会再次启动慢启动重设ssthresh的值，这样的话会降低传输的速率。。这就引出来了快重传算法和快恢复。。 快重传和快恢复：只要发送方收到了连续的三个ACK重复确认报文，就说明接收方确实没有收到相应的报文，所以立即重传对于的报文，这样就不会出现超时，发送方也不会认为出现了网络延迟，从而避免可不必要的慢开始的启动。使用快重传机制大概可以使网络吞吐量提高0.2..所以④处收到三个重复的确认消息以后，立即快重传，然后没有实行慢启动而是实行了快恢复，然后将ssthresh设置俄日ssthresh=cwnd/2=8,然后继续执行拥塞避免。。 可以看出来在拥塞避免阶段，拥塞窗口是线性增长的，这个通常称为加法增大。一旦出现超时或者三个重复的确认，就把门限减为cwnd的1/2,这个称为乘法减小，这两种方法结合在 一起称为AIMD算法. 下面给出流程处理图： 实际情况下，发送方的窗口值应该等于接收方和拥塞窗口值中比较小的那个。 所以当rwnd&lt;cwnd的时候：接收方窗口限制了发送方窗口的最大值 rwnd&gt;cwnd：网络拥塞程度限制了发送方窗口的最大值 也就是说rwnd和cwnd中较小的一个控制了发送数据的速率。 主动管理队列（AQM）因为上面提到的拥塞控制只是TCP层面的没有牵扯网络层。可是他们之间有着密切的联络。那么有这么情况，一个路由器可能链接了多个主机服务器即会有多个链接，所以当路由器队列满的时候，采取了尾部丢弃策略以后，可能会导致一连串分组的丢失，那么就会对发送方产生延迟，这里可能有很多个发送方，所以多个发送方都认为产生了网络延迟则将ssthresh=cwnd/2;然后重新开始慢启动，那么同一时间很多发送方式慢启动，那么意味着他们同时达到发送高峰，这也 很容易再次引起拥塞。这就叫做全局同步。所以为了避免发生这种情况。。就提出了主动管理队列，即路由器不要等到满了才丢弃，而是当队列长度达到某个值，可能将要发生拥塞的时候，就丢弃一些分组，这样就提醒了个别发送方放慢了传送速率。。所以有可能减轻网络的拥塞，甚至不出现拥塞。这里的丢弃就是随机丢弃，不然全部丢弃的话和队列满了的效果是一样的。。所以ARQ的实现方法就是随机早期检测（RED），实现RED需要路由器维护两个参数，即队列长度的最大限度和最小限度 1.若平均队列长度小于最小限制，则把新收到的假如队列 2.若平均队列长度大于最大限制，则把新到达的丢弃 3.介于最大和最小之间，则按照某个丢弃概率把新到达的分组丢弃（这就体现了随机丢弃）。 这里的这个概率是最难的。。有兴趣的可以了解一下。。通过这种方法就避免了上面描述的那种情况产生的拥塞。。 好了致此TCP的拥塞控制就全部讲完了。。 2.滑动窗口TCP滑动窗口是以字节为单位的。","categories":[{"name":"网络学习","slug":"网络学习","permalink":"http://yoursite.com/categories/网络学习/"},{"name":"传输层","slug":"网络学习/传输层","permalink":"http://yoursite.com/categories/网络学习/传输层/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"http://yoursite.com/tags/TCP/"}]},{"title":"套接字编程函数","slug":"套接字编程函数","date":"2018-04-01T02:45:27.000Z","updated":"2018-04-07T09:05:29.236Z","comments":true,"path":"2018/04/01/套接字编程函数/","link":"","permalink":"http://yoursite.com/2018/04/01/套接字编程函数/","excerpt":"此篇博客的主要内容对如下函数进行详细的介绍 1.int socket(int domain, int type, int protocol); 2.int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen); 3.int listen(int sockfd, int backlog); 4.int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen); 5.int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen);","text":"此篇博客的主要内容对如下函数进行详细的介绍 1.int socket(int domain, int type, int protocol); 2.int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen); 3.int listen(int sockfd, int backlog); 4.int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen); 5.int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen); 下面我来一个一个介绍： 1.socket() #include &lt;sys/types.h&gt; /* See NOTES */ #include &lt;sys/socket.h&gt; int socket(int domain, int type, int protocol); 如果要进行网络I/O，进程需要的做的第一件事就是使用socket函数来创建一个套接字（好比一个网络端口），如果成功的话，就像open()一样返回一个文件描述符，应用程序可以像读写文件一样用read/write在网络上收发数据，如果socket()调用出错则返回-1。这个socket（）可以用来指定通过信的类型。 参数： 1.domain: 当domain==AF_INET:这是大多数用来产生socket的协议，使用TCP或UDP来传输，用IPv4的地址 当domain==AF_INET6:与上面类似，不过是来用IPv6的地址 当domain==AF_UNIX:本地协议，使用在Unix和Linux系统上，一般都是当客户端和服务器在同一台及其上的时候使用。 2.type:（这里只给出最常用的两种） SOCK_STREAM: 这个协议是按照顺序的、可靠的、数据完整的基于字节流的连接。这是一个使用最多socket类型，这个socket是使用TCP来进行传输。 SOCK_DGRAM: 这个协议是无连接的、固定长度的传输调用。该协议是不可靠的，使用UDP来进行它的连接。 3.传0 表示使用默认协议。 2.connect() #include &lt;sys/types.h&gt; /* See NOTES */ #include &lt;sys/socket.h&gt; int connect(int sockfd, const struct sockaddr *addr,socklen_t addrlen); TCP客户端用来建立和TCP服务器的连接 参数： 1.sockfd:客户端所建立的套接字所返回的文件描述符,第二个参数里面的内容是服务器的IP地址和端口号，第三个是这个地址的长度 注意： 1.客户端在调用connect的时候不一定要调用bind函数绑定，因为不绑定内核会帮我们来确定源IP并且会替我们找一个临时的端口号。 2.如果是TCP的套接字，connect函数将激发三次连接，当且仅当三次连接建立成功或者出错时才返回。其中的错误返回可能有下面的几种情况 ①TCP客户端没有收到SYN的确认，则返回ETIMEDOUT错误。举个例子说明：当客户端发送一个SYN给服务器发起三次握手的时候，客户端没有回复ACK，则过6s客户端在发送一个SYN，还没有收到ACK，则等24秒后在发一个SYN，如果一共等了75S后还没有收到ACK，则返回ETIMEDOUT错误 ②如果对于客户端的SYN的响应是RST（表示复位），表示在服务器的主机上没有与我们发送建立连接的端口所对应的进程在等待和客户端连接（可能是服务器进程没有运行），这是一种硬错误，客户端一接收到RST就立马返回ECONNREFUSED错误。（RST产生的原因：1.服务器对应进程不存在，2.非法连接） ③ 客户端发送的SYN引发了一个（目的不可达的错误）ICMP错误，则认为是一种软错误，客户端主机保存该消息，并且按照第一种情况继续发送直到超时，则把报错下来的ICMP错误作为EHOSTUNREACH或者ENETUNREACH错误返回给进程。 3.按照TCP状态转换图来讲，connect函数导致当前套接字从CLOSED状态（该套接字自从socket创建以来一直处于的状态）转移到SYN_SENT状态。如果连接建立成功则转到ESTABLISHED状态。如果connect失败的话,那么之前socket的套接字也不能再使用了，必须关闭，不能再次对这样的套接字使用conenct，需要重新创建。 3.bind() #include &lt;sys/types.h&gt; /* See NOTES */ #include &lt;sys/socket.h&gt; int bind(int sockfd, const struct sockaddr *addr,socklen_t addrlen); bind函数将一个本地协议地址赋予一个套接字，即给这个进程的套接字绑定上端口号和Ip. 参数： 1.sockfd:要绑定的套接字，之前使用socket创建的 2.addr:指向特定的协议的地址结构的指针. 3.addrlen:是这个结构体的长度 重点强调： 1.服务器在一般使用bind比较多，服务器会绑定一个众所周知的的端口号。如果TCP客户端，那么当调用connect的时候，内核就会为相应的套接字选择一个临时的端口。但是服务器一定要使用bind. 2.进程也可以通过Bind将特定的IP捆绑到创建的套接字上面去。不过这个IP地址必须属于其注意所在的网络接口之一。对于客户端来讲，绑定的这个IP就意味着为发送的IP数据报指定了源IP地址，对于服务器来说，相当于只接受目的IP为绑定的IP的数据。如果TCP的客户没有绑定IP地址的话那么，那么当发起连接的时候，内核会根据外出网络的接口来选择合适的源IP地址，而这个外出网络的接口取决于所到达的服务器的路径。如果TCP的服务器端没有绑定IP地址的话，内核就把客户端发送的SYN的目的IP地址作为服务器的 源IP地址。（个人觉得服务器不指定IP地址并且客户端能够把自己发送SYN的目的地址作为服务器的IP地址的情况是客户端和服务器端都使用系统指定的默认IP，不然的话指定无法通信的.） 3.如果指定端口号为0，那么内核就会在bind被调用的时候选择一个临时的端口，如果指定IP地址为通配地址（由INADDR_ANY来指定，一般其值为0），那么等到内核的套接字已经连接或者已经在套接字上发送一个数据的时候才选择一个本地的IP. 从bind函数返回的一个常见的错误是EADDRINUSE（地址已使用） 4.listen() #include &lt;sys/types.h&gt; /* See NOTES */ #include &lt;sys/socket.h&gt; int listen(int sockfd, int backlog); listen函数仅由服务器调用，它做了两件事 1.因为当应用进程调用socket()函数以后，这个套接字默认是主动连接的套接字，也就是说内核认为这是一个要发起connect连接的套接字.所以当服务器调用listen后就把服务器创建的未连接的套接字转换成一个被动的套接字，即指示内核应该接受指向该套接字的连接请求，根据TCP的状态装换图，调用listen以后导致套接字从CLOSED转到LISTEN状态 2.函数的第二个参数规定了内核应该为相应的套接字排队的最大连接个数。这个排队的最大连接数怎么理解呢？ 这里就需要补充一点小知识了：那就是我们必须认识到内核为任何一个给定的监听套接字维护两个队列： 一个是未完成连接的队列：每个这样的SYN分节对应其中一项：已由某个客户端发送并到达服务器，而服务器正在等待完成相应的TCP三次握手过程。这些套接字处于SYN_RCVD状态。（简单说就是SYN收到一个SYN以后就对应一个模块） 一个是完成连接队列：每个已经完成TCP三次握手过程的客户端对应其中一项，这些套接字处于ESTABLISHED 当一个客户端发送SYN达到服务器端的时候，TCP就在未完成对流中创建一个新项，然后响应三路握手的第二部即向客户端发送SYN即ACK。创建的这个项一直保留在未完成队列中，直到三路握手的第三步即客户端回应服务器ACK以后到达服务器或者该项超时即超过75s。如果三路握手正常完成连接，那么这项就会被移动到已完成连接队列的队尾。当进程调用accept时，已完成的连接的队列头项将返回给进程取使用，即返回通信的那个套接字。如果已完成队列为空，那么进程将被投入睡眠，直到已完成队列中放入一项才唤醒它。 现在你直到backlog表示什么了吧，就是未完成队列的最大的个数。 如果一个SYN发送过来了，但是未完成队列是满的，那么就忽略该SYN，也就是说不发送RST，这么做是因为满是暂时的，客户TCP等待时间后将重发SYN，期望不久就可以在这些队列中找到可用空间。如果TCP服务器立马回复一个RST的话，那么客户端的connect的调用就会立即返回一个错误，强制应用进程处理这种情况，而不是使用重传机制来处理。单凭一个RST客户端无法知道是服务器没有对应进程还是未完成队列满了。 在三次握手完成以后，但是在服务器调用accept函数之前到达的数据应由服务器TCP排队，最大的数据量为相应的套接字的接收缓冲区的的大小（这个套接字是完成连接队列中的套接字只不过未调用accept意味着还没有从队列中将这个套接字取出） 5.accept()函数 #include &lt;sys/types.h&gt; /* See NOTES */ #include &lt;sys/socket.h&gt; int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen); 由TCP服务器调用，作用是从已完成连接的对列头部返回下一个已完成连接，如果完成队列为空那么进程就进入睡眠状态（假定套接字的默认阻塞） 参数： 1.sockfd:监听的套接字的描述符 2.addr:返回已连接的对端进程的协议地址。 3.addrlen是个值–结果的参数，调用之前，我们由*addrlen所引用的整型数值置为由addr指向的结构体的长度,返回，该数值，即为由内核存放在该套接字地址结构中的确切字节数。 注意： 如果accept返回成功则，其返回值是由内核自动生成的一个全新的描述符，代表与所返回的客户的TCP连接。注意和监听套接字区分，内核为每个服务器通过只创建一个监听服务器，其声明周期随整个进程，但是每当accept成功返回时，即TCP三次握手完成的时候,都会创建一个新的套接字，在数据传送完毕以后这个套接字就被关闭。 这些应该是网络编程最重要的几个函数了。这里做了详细的介绍。。还有一些函数比如字节序转换，端口复用等，，后面 再更新。。。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"},{"name":"网络编程","slug":"Linux/网络编程","permalink":"http://yoursite.com/categories/Linux/网络编程/"}],"tags":[{"name":"套接字","slug":"套接字","permalink":"http://yoursite.com/tags/套接字/"}]},{"title":"TCP协议基本概述","slug":"TCP协议基本概述","date":"2018-03-30T15:14:58.000Z","updated":"2018-04-02T08:50:22.320Z","comments":true,"path":"2018/03/30/TCP协议基本概述/","link":"","permalink":"http://yoursite.com/2018/03/30/TCP协议基本概述/","excerpt":"此篇博客的主要内容： 1.TCP协议的主要特点 2.实现可靠网络传输的基本理论基础 3.TCP报文的首部格式","text":"此篇博客的主要内容： 1.TCP协议的主要特点 2.实现可靠网络传输的基本理论基础 3.TCP报文的首部格式 下面来一个一个介绍 1.TCP协议的特点1.TCP是面向连接的传输层协议：这就意味着应用程序在使用TCP协议进行通信前，必须建立TCP连接。在数据传送完毕以后，必须释放已经建立的连接。 2.每一条TCP只能有两个端点：即每一条TCP连接只能是端到端的1对1形式 3.TCP提供可交付的服务：通过TCP连接传送数据 ，可以 实现无差错，不丢失，不重复，并且按序到达。 4.TCP提供双工通信：TCP允许双方通信的进程在任何时候都能发送数据。TCP连接的两端都设有发送缓存区和接收缓存区，用来临时存放双方通信的数据。发送方应用将数据交给缓存区然后就可以做自己的事情，接收方缓存区保存接收到的数据，在合适的时候读取就可以了。 5.面向字节流：UDP之所以是面向数据报是因为应用层给他多长的报文他就发送多长的报文，其余的不管。在他的眼里只有报文。而说TCP是面向字节流即即时应用层给他的是报文，在他的眼里也就是连续的 字节流组成的而已。如果报文的长度超过了TCP的MSS则会被TCP分段，然后发送出去。所以说UDP容易发生IP分片，TCP不会，但是TCP会发生分段。 2.TCP的可靠传输工作原理的基础首先如果理想的传输特点是这样的 1.传输信道不产生错误 2.不管发送方以多快的速度发送，接收方总是来得及接收和处理数据。 可惜理想就是理解，在现实的网络数据传输中避不了出差错，所以我们需要使用一些比较可靠的协议来为我们可靠传输奠定基础。这就是我们的停止等待协议。其核心思想就是发送一个数据分组然后停下来等待一个确认消息，再继续发送下一个分组。 下面阐述可能出现的问题和相应的解决办法（这里主要是思想，TCP里面的方法就是基于这个思想改变而来的） 为了方便描述问题这里假设A为客户端 B为服务器端 问题1（出现差错）.A给B发送的消息M1丢失了，或者M1出错了，B收到以后将其丢弃，这都会造成A端什么消息也收不到，无法知道消息是出错了还是丢失了。 方法：超时重传，即A每发送完一个数据立即设置一个定时器，在定时器超时的时候还没有收到来自B的确认消息，则认为发送的消息丢失，然后重新发送这个消息，如果在定时器内收到了确认消息则取消定时器。这种方法需要强调三点： 1.发送完一个分组后需要保存已发送分组的备份，用来超时重传，只有在收到这个数据的确认消息后才将保留的分组副本删除。 2.分组和确认组都必须编号，这样才能明确哪个确认是哪个分组的确认 3.超时计时器的时间应该比数据传输的平均往返时间大一点，因为设置时间较长则效率低，设置时间较短则产生不必要的重传，浪费网络资源。 问题2（确认丢失和确认迟到）：B给A的M1消息的确认丢失了。即A无法收到B的确认消息，A也不知道是自己的传送的数据丢失了，出错了，还是B的确认消息丢失了。一旦定时器到时，A就要重新发送。假设B又收到了A重发的M1，这个时候B可以这么处理 ：：丢弃重复的分组M1，不向上层交付，向A再次发送确认，不能因为发送过确认就不发送了，既然你又收到了M1，则证明A没有收到M1的确认。如果B的确认延时了，那么A重发了M1以后，A收到了重发后的确认，然后又立马收到第一次的m1确认则丢弃这个确认。 使用这种重传确认机制就可以实现可靠的网络传输，像这种可靠的协议就是自动重传请求ARQ，意思是重传的请求是根据定时器自动的，接收方不需要请求发送发重发某个出错的分组。 还有两种机制这里就直接说了 1.流水线传送，提高信道的利用率 2.连续ARQ协议，即滑动窗口。保证流水传送的正确机制。 这里要强调的滑动窗口是累计确认机制，即对按序到达的最后一个分组发送确认，表示这个分组及以前分组都收到了。那么假如传送了5个分组，第三个丢失，那么久确认对前两个分组的确认，发送发无法知道后三个分组的情况，则又把后三个重新传一遍，这就是回退。 3.TCP报文内容的介绍 1.源端口和目的端口：各占2个字节，分别是客户端和服务器端的端口号 2.序号：占四个字节，范围[0,2^32-1]即4294967296个序号，并且序号超出最大值以后继续从0开始。TCP是面向字节流的，所以发送的数据每一个字节都要编号，首部中的序号的值就表示本本报文段发送的数据的第一个字节的序号。举例，假如一个报文段字段值是301，而携带数据共有100字节，这就说明这个数据段的第一个字节序号是301，最后一个字节序号是400，所以 下一个数据段的第一个字节序号应该是401. 3.确认号：占四字节，是接收方希望下次收到的报文段的第一个字节的序号，也表示当前序号之前的所有字节都收到了。 4.数据偏移：占四位，表示要传输的数据的起始位置到TCP报文段的起始处有多远，其实也就是指的是TCP的首部，因为首部中还有长度不确定的选选项字段，所以这个偏移地址是有必要计算的，另外偏移地址的以字为单元，因为是4位所有二进制4位最大表示15，即最多偏移40个字节，也就意味着头部最大是40个字节。（即选项长度不能超过40字节） 5.保留：保留为今后使用但是目前值为0 接下来保留旁边的6个控制位，用来说明报文段的性质： 1.紧急URG:将紧急的 数据插入到发送的缓存区的最前面，结合紧急指针使用 2.确认ACK 3.推送PSH：很少使用，，即用户希望很快将自己的数据给对方使用，使用PSH则传送的数据直接给对方的应用进程而不是等接受缓存区满了才上交。 4.复位RST：当TCP连接中出现严重错误，则需要断开连接，然后在重新建立连接，就将RST置1，它还可以用来拒绝非法的报文段或者拒绝打开一个非法连接 5.SYN: 6.FIN: 6.窗口：占两字节，[0-2^16-1],滑动窗口大小 7.检验和：参考UDP 8.紧急指针：在URG=1才有意义 9.选项：最开始只有MSS一个选项，后来有了窗口扩大，时间戳等，选择确认 时间戳：用来计算RTT","categories":[{"name":"网络学习","slug":"网络学习","permalink":"http://yoursite.com/categories/网络学习/"},{"name":"传输层","slug":"网络学习/传输层","permalink":"http://yoursite.com/categories/网络学习/传输层/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"http://yoursite.com/tags/TCP/"}]},{"title":"Linux_线程","slug":"Linux-线程","date":"2018-03-30T01:12:42.000Z","updated":"2018-03-30T11:04:20.779Z","comments":true,"path":"2018/03/30/Linux-线程/","link":"","permalink":"http://yoursite.com/2018/03/30/Linux-线程/","excerpt":"此篇博客主要介绍一下关于线程的概念及线程控制原语。 首先在Linux下并不存在真正意义上的线程，他是由进程模拟出来的。所以可以说线程是轻量级的进程，其本质也是进程。进程和线程的区别是进程有自己独立的地址空间（整租）而线程没有自己独立的地址空间（合租），从内核中看线程和进程是一样都有PCB，只不过PCB中指向资源的三级页表是相同的，创建线程和进程底层使用的函数都是clone，进程可以蜕变成线程，在Linux下，线程是最小的调度单位，CPU是最小的资源分配的单位，可以将进程看成只有一个线程的进程。","text":"此篇博客主要介绍一下关于线程的概念及线程控制原语。 首先在Linux下并不存在真正意义上的线程，他是由进程模拟出来的。所以可以说线程是轻量级的进程，其本质也是进程。进程和线程的区别是进程有自己独立的地址空间（整租）而线程没有自己独立的地址空间（合租），从内核中看线程和进程是一样都有PCB，只不过PCB中指向资源的三级页表是相同的，创建线程和进程底层使用的函数都是clone，进程可以蜕变成线程，在Linux下，线程是最小的调度单位，CPU是最小的资源分配的单位，可以将进程看成只有一个线程的进程。 线程之间共享的资源： 1.文件描述符表 2.每种信号的处理方式 3.当前工作目录 4.用户ID和组ID 5.内存地址空间 (.text/.data/.bss/heap/共享库) 线程非共享资源： 1.线程id 2.处理器现场和栈指针(内核栈) 3.独立的栈空间(用户空间栈) 4.errno变量 5.信号屏蔽字 6.调度优先级 线程的优缺点： 优点：1. 提高程序并发性 2. 开销小 3. 数据通信、共享数据方便 缺点 ：1. 使用的是库函数，不稳定 2. 调试、编写困难、gdb不支持 3. 对信号支持不好优点相对突出，缺点均不是硬伤。Linux下由于实现方法导致进程、线程差别不是很大。 下面来看一下关于线程中的控制原语 1.创建一个线程 #include &lt;pthread.h&gt; int pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine) (void *), void *arg); 参数： 1.pthread:是线程的ID，是线程库管理分配的用来操作使用线程.穿入传出参数 2.attr:表示所使用的线程属性，是一个结构体类型，里面包含了一些所创建的线程的属性值得设置，一般使用NULL，表示使用线程的默认属性 3.start_routine：表示我们所要创建的线程的函数，其类型是返回值void，参数也是void， 4.arg:表示给我们所创建的线程传的参数 注意： 1.当pthread_create成功返回的时候，新创建的线程ID会被设置为pthread指向的内存单元,新创建的线程从start_routine函数的地址开始运行，如果需要向函数传递多个参数的话，需要将这个参数放到一个结构体中，然后将结构体的地址 作为atg参数传递过去 2.在创建新线程的时候让主线程sleep(1)秒，不然的话新创建的线程还来不及执行，主线程已经返回退出了 2.获取线程的ID #include &lt;pthread.h&gt; pthread_t pthread_self(void); 此函数返回我们所创建的线程的ID，其实可以理解为线程在一个地址空间中的标识，用来方便我们使用这个线程，其类型是长整型，记得打印的时候使用lu。 3.线程的退出函数#include &lt;pthread.h&gt; void pthread_exit(void *retval); 参数：retval表示线程的退出状态，通常情况下传NULL。 注意：如果进程中的任意线程调用了exit,_Exit或者_exit，那么整个进程就会终止，与此类似的是如果某个线程收到了一个终止进程的信号，那么这个进程也会终止。 单线程的退出方式有三种 1.单线程可以从简单的启动例程返回。，返回值是线程的退出码。（return,不适用main函数 ） 2.其可以被同一进程中其他的线程取消(pthread_cancel) 3.线程调用上述 函数pthread_exit退出。 当某个线程调用了pthread_exit函数以后，则其他的线程可以调用如下的函数来获取线程的退出状态，调用这个函数的线程会阻塞，直到获取的线程调用pthread_exit或者从启动例程返回或者线程被取消 #include &lt;pthread.h&gt; int pthread_join(pthread_t thread, void **retval); 参数 1.要获取的线程的ID 2. 如果线程从例程返回(return)，则retval指向的内存单元中的值是return的返回值 如果线程被pthread_cancel掉，那么retval指向的内存单元中的值是PTHREAD_CANCELED 如果线程是pthread_exit，则retval指向的内存单元中的值是pthread_exit的参数 如果对其退出值不感兴趣，则将retval设置为null。 上面既然讲了pthread_cancel强迫线程退出，那么下面就来说一下这个函数 #include &lt;pthread.h&gt; int pthread_cancel(pthread_t thread); 一个线程调用这个函数可以请求取消同一进程中的其他线程。 注意：一个线程被其他线程调用pthread_cancel取消的话，有一定的延迟性，即被取消的线程需要等线程达到某个取消点或者检查点才能被杀死。这些检查点通常是一些系统调用。如果线程没有取消点，那么我们可以自己来设置这个取消点，使用pthreestcancel函数，对于一个被取消的线程，使用pthread_join回收的时候,返回值是-1（PTHREAD_CANCELED的宏定义）。 3.线程分离线程分离：指的是线程和当前的主控线程等线程脱离关系（状态上分开），线程结束后其退出状态不由其他的线程获取，而直接自己释放。一般情况下，线程终止后，其终止状态一直保留到其它线程调用pthread_join获取它的状态为止。但是线程也可以被置为detach状态，这样的线程一旦终止就立刻回收它占用的所有资源，而不保留终止状态。不能对一个已经处于detach状态的线程调用pthread_join，这样的调用将返回EINVAL错误。也就是说，如果已经对一个线程调用了pthread_detach就不能再调用pthread_join了。在设置线程分离的时候可以使用如下函数 #include &lt;pthread.h&gt; int pthread_detach(pthread_t thread); 4.比较两个线程ID是否相等 #include &lt;pthread.h&gt; int pthread_equal(pthread_t t1, pthread_t t2);","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"},{"name":"系统编程","slug":"Linux/系统编程","permalink":"http://yoursite.com/categories/Linux/系统编程/"}],"tags":[{"name":"线程","slug":"线程","permalink":"http://yoursite.com/tags/线程/"}]},{"title":"UDP概述","slug":"UDP概述","date":"2018-03-29T11:46:53.000Z","updated":"2018-03-29T13:56:04.551Z","comments":true,"path":"2018/03/29/UDP概述/","link":"","permalink":"http://yoursite.com/2018/03/29/UDP概述/","excerpt":"此篇博客主要介绍传输层的主要协议之一：用户数据协议报UDP协议（无连接协议），在只是实现传输层最基本的功能，复用和分用还有差错检验的功能。","text":"此篇博客主要介绍传输层的主要协议之一：用户数据协议报UDP协议（无连接协议），在只是实现传输层最基本的功能，复用和分用还有差错检验的功能。 UDP的特点： 1.UDP是无连接的：即发送数据之前不需要建立连接，当然发送数据结束的时候有也不需要断开或者释放连接，正因为这样减少了开销和发送数据之前的延迟。 2.UDP使用尽最大努力交付：即不保证可靠交付，因此主机里面不需要保存大量的维持连接状态的信息表（里面有很多参数） 3.UDP是面向报文的：即UDP对于从应用层拿到的报文或者从网络层接收到的报文及不拆分，也不合并，只是加头发送，去头向上传递，也就是说UDP一次交付一个完成的报文，所以应用程序必须自己选择合适的报文大小，因为选择的过于小了，到时候传递给IP层后会显得IP层的首部相对较大影响效率，如果选择的报文过大，则在IP层会发生IP切片。 4.UDP没有拥塞控制：所以当传输网路实现拥塞的时候，传输方的传输速率并不会降低，这对于一些实时的应用是很重要的（比如IP电话，即时视频会议等），其允许在网络拥塞是丢失部分数据，但是不允许有太大的延迟 5.UDP支持，1对1,1对多，多对1，多对多交互式通信 6.UDP的头部开销小：相对于TCP的20个字节来说。UDP头部只有八个字节。 下面给出UDP的协议报文图 1.16位源端口号：在需要对方回信时选用，不需要时全为0. 2.16为目的端口号：在报文交付时必须使用 3.16位UDP长度：其最小值为8（只有头部） 4.检验和：检测UDP用户数据报在传输中是否有错，有错则丢弃。 注意：如果接受方的UDP发现收到的报文目的端口号不正确，即不存在向对应的应用程序，则丢弃该报文，同时由网际控制报文协议ICMP发送“端口不可达”差错报文给发送端。 注意：虽然在UDP通信时要用到端口号，但是由于UDP的通信是无连接的，因此不需要使用套接字（TCP之间的通信必须使用两个套接字建立连接）。 最后来说说UDP的差错检验和： 在计算UDP的差错检验和的时候需要给UDP报文加上一个伪头部，用来更好的验证差错，这个伪头部并不是UDP的头部，它只是为了计算校验和临时得到的，即不向上传送，也不向下传送。下面给出示意图 UDP校验和的计算方法和IP的校验和相似，只不过IP的校验和仅仅是检验IP数据报首部的信息，而UDP校验和是检验首部和数据部分一起检验，检验其IP和端口号. 为什么需要伪头部？伪头部的目的是为了让UDP包接受者确定发送和接受的UDP包是来自正确的源且是发给自己的。 但是收到的UDP包只有源和目的的UDP端口号，并没有IP地址信息，所以要重新构造个伪头部，加上源IP和目的IP（从IP包中拿来），再计算校验和以确定数据包的正确性。因为传输层和UDP和IP不一定在一个协议栈，IP层携带的数据不一定就要发送给UDP，所以UDP需要 确定就是发送给我的! 计算举例如下： 发送方首先把全零放入检验和中，然后将加上伪头部的UDP数据报看成由许多16位串起来的，如果UDP的数据报数据部分不是偶数字节的，则要填入全0字节，但是此字节不发送。然后将这些16位二进制求和，将最后的结果反码写入校验和。在接收端，重新计算校验和，如果没有差错结果为1.（因为只是校验和不同，和其对应的是反码，反码+源码=1）。","categories":[{"name":"网络学习","slug":"网络学习","permalink":"http://yoursite.com/categories/网络学习/"},{"name":"传输层","slug":"网络学习/传输层","permalink":"http://yoursite.com/categories/网络学习/传输层/"}],"tags":[{"name":"UDP","slug":"UDP","permalink":"http://yoursite.com/tags/UDP/"}]},{"title":"TCP三次握手四次挥手","slug":"TCP三次握手四次挥手","date":"2018-03-27T08:11:52.000Z","updated":"2018-03-27T12:36:29.152Z","comments":true,"path":"2018/03/27/TCP三次握手四次挥手/","link":"","permalink":"http://yoursite.com/2018/03/27/TCP三次握手四次挥手/","excerpt":"首先来看一下TCP传输协议的报文格式中关于建立连接需要用到的一些比较重要的标志位。","text":"首先来看一下TCP传输协议的报文格式中关于建立连接需要用到的一些比较重要的标志位。 1.seq:32位序列号，占四个字节，范围在[0-2^32-1],因为TCP是面向字节流的，所以它需要为发送流中的每个字节编号，这个序列号是使用随机数产生器产生的。（只产生一次，后面顺序向上递增） 2.ACK：32位确认序号,仅当保留位旁边的ACK=1的时候确认序号才生效，其表示一个进程已经正确接收序列号为N的字节，要求下一次接收的应该是N+1序列号的字节，所以如果接收到了序列号为N，则ACK回复为N+1(注意和确认ACK位区分) 3.SYN:（同步位）同步序列号，用来发起一个连接，当SYN=1，ACK=0的时候，表示这是一个发起连接的报文请求段。如果对方同意建立连接则会回应SYN=1，ACK=1。（系统规定SYN=1的报文段不能携带数据，但是要消耗掉一个序列号） 4.FIN：（终止位）,终止位用来终止连接，当FIN=1,表示发送端的报文发送完毕，请求关闭连接。 好了下面来谈谈三次握手的建立连接的过程. 1.首先客户端和服务器端都处于CLOSE状态（关闭状态），并且服务器端已经创建了传输控制块TCB，即时刻准备接收客户端的请求，即服务器端就进入了LISTEN（监听状态）状态 2.客户端运行起来以后，也创建了传输控制块PCB，然后向B发送了连接请求的报文。这个报文首部的SYN标志位被设置成1，即SYN=1，同时随机选择一个初始的序号，这里假设为x,即seq=x(系统规定SYN=1的报文段不能携带数据，但是要消耗一个序列号)，当这个报文发送出去以后，客户端就有CLOSE变成了SYN_SENT状态（同步已经发送的状态） 3.服务器端接收到客户端发来的请求建立连接的报文请求得话则，则向A发送确认报文（也不带数据）。这个回复的报文中SYN=1,seq=y,ACK=x+1（确认序列号），告诉客户端你发的建立请求得要求我收到了，我同意和你建立请求，然后发送完后服务器端进入了SYN_RCVD的状态（准备接收，也可以说同步收到） 4.当客户端收到了服务器的同意建立连接请求后，还要给服务器端回应我收到了你的同意建立连接的报文,回复给服务器的报文是ACK=y+1,seq=x+1, TCP的标准规定，ACK的报文段可以携带数据。但如果不携带数据则不消耗序号，在这种情况下，下一个数据报文段的序号仍是seq = x+1。这时TCP连接已经建立，客户端进入ESTABLISHED（已建立连接）状态。当服务器收到收到客户端的确认后报文后，也进入ESTABLISHED状态。 致此整个连接建立的过程就完了，下面我来画个图说明一下 看图就是这么简单。。。。 下面来说一下四次挥手断开连接 在他们通信完成以后，双方还都是ESTABLISHED状态，并且断开连接的请求服务器和客户端都可以发起，我们这里说一下客户端先发起断开连接的请求。 1.当客户端准备结束这次的数据传输的时候，主动提出释放TCP连接时，它向服务器发送一个连接释放请求的报文，FIN=1，seq=u,(这里的u等于之前传送的数据最后一个字节的序列号+1)，然后客户端进入FIN_WAIT_1(释放等待1的状态,等待服务器端的确认),TCP规定：FIN报文段即使不携带数据，也要消耗掉一个序号。 2.当服务器端收到客户端的请求断开连接的报文后，需要向客户端发出已收到断开连接的报文请求得确认报文，ACK=u+1，seq=v（v表示服务器端之前发送的最后的数据的最后一个字节的序列号+1）,然后服务器进入CLOSE_WAIT状态。 注： TCP服务器进程此时应该通知高层应用进程，因为从A到B这个方向的连接已经关闭，这时的TCP进程属于半关闭（half_close）状态，即客户端已经不会给服务器发送数据了，但服务器要向客户端发送数据，客户端还得接收。 3.当客户端收到服务器发来的ACK（确认断开连接报文后），进入FIN_WAIT_2的状态（释放等待2的状态，等待服务器端发送断开连接的请求），如果服务器端没有数据要发送了，应用程序通知服务器发送断开连接的请求，即向客户端发送断开连接的请求报文FIN=1,seq=w(假设客服端发送断开连接请求以后，服务器还给客户端发送消息了)，并且还要重复确认之前的ACK=u+1,然后服务器就进入了LAST_ACK状态（等待客户端回应自己的断开连接请求） 4.当客户端收到了服务器发来的要断开连接的请求后，回复给服务器ACK=w+1,seq=u+1,然后进入TIME_WAIT等待时间的状态，但是，现在TCP连接还没有释放，必须经过时间等待计时器（TIME_WAIT timer）设置的时间2MSL后，A才能进入到CLOSED状态。 下面画出示意图： 这里说一下这个TIME_WAIT： 为了保证TCP连接释放过程的正常进行，TCP设置了时间等待器即TIME_WAIT timer.这个时间一般是2MSL（两个最长报文寿命时间），这个时间过后客户端才能真正进入CLOSE状态。 TCP状态转换图 CLOSED：表示初始状态。 LISTEN：该状态表示服务器端的某个SOCKET处于监听状态，可以接受连接。 SYN_SENT：这个状态与SYN_RCVD遥相呼应，当客户端SOCKET执行CONNECT连接时，它首先发送SYN报文，随即进入到了SYN_SENT状态，并等待服务端的发送三次握手中的第2个报文。SYN_SENT状态表示客户端已发送SYN报文。 SYN_RCVD: 该状态表示接收到SYN报文，在正常情况下，这个状态是服务器端的SOCKET在建立TCP连接时的三次握手会话过程中的一个中间状态，很短暂。此种状态时，当收到客户端的ACK报文后，会进入到ESTABLISHED状态。 ESTABLISHED：表示连接已经建立。 FIN_WAIT_1: FIN_WAIT_1和FIN_WAIT_2状态的真正含义都是表示等待对方的FIN报文。区别是：FIN_WAIT_1状态是当socket在ESTABLISHED状态时，想主动关闭连接，向对方发送了FIN报文，此时该socket进入到FIN_WAIT_1状态。 FIN_WAIT_2状态是当对方回应ACK后，该socket进入到FIN_WAIT_2状态，正常情况下，对方应马上回应ACK报文，所以FIN_WAIT_1状态一般较难见到，而FIN_WAIT_2状态可用netstat看到。 FIN_WAIT_2：主动关闭链接的一方，发出FIN收到ACK以后进入该状态。称之为半连接或半关闭状态。该状态下的socket只能接收数据，不能发。 TIME_WAIT: 表示收到了对方的FIN报文，并发送出了ACK报文，等2MSL后即可回到CLOSED可用状态。如果FIN_WAIT_1状态下，收到对方同时带 FIN标志和ACK标志的报文时，可以直接进入到TIME_WAIT状态，而无须经过FIN_WAIT_2状态。 CLOSING: 这种状态较特殊，属于一种较罕见的状态。正常情况下，当你发送FIN报文后，按理来说是应该先收到（或同时收到）对方的 ACK报文，再收到对方的FIN报文。但是CLOSING状态表示你发送FIN报文后，并没有收到对方的ACK报文，反而却也收到了对方的FIN报文。什么情况下会出现此种情况呢？如果双方几乎在同时close一个SOCKET的话，那么就出现了双方同时发送FIN报文的情况，也即会出现CLOSING状态，表示双方都正在关闭SOCKET连接。 CLOSE_WAIT: 此种状态表示在等待关闭。当对方关闭一个SOCKET后发送FIN报文给自己，系统会回应一个ACK报文给对方，此时则进入到CLOSE_WAIT状态。接下来呢，察看是否还有数据发送给对方，如果没有可以 close这个SOCKET，发送FIN报文给对方，即关闭连接。所以在CLOSE_WAIT状态下，需要关闭连接。 LAST_ACK: 该状态是被动关闭一方在发送FIN报文后，最后等待对方的ACK报文。当收到ACK报文后，即可以进入到CLOSED可用状态。 2MSL存在理由？ 在客户端发送出最后的ACK回复，但该ACK可能丢失。服务器如果没有收到ACK，服务器将不断重复给客户端发送FIN片段。所以客户端不能立即关闭，它必须确认服务器接收到了该ACK。客户端会在发送出ACK之后进入到TIME_WAIT状态。客户端会设置一个计时器，等待2MSL的时间。如果在该时间内再次收到FIN，那么客户端会重发ACK并再次等待2MSL。所谓的2MSL是两倍的MSL(Maximum Segment Lifetime)。MSL指一个片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间。如果直到2MSL，客户端都没有再次收到FIN，那么客户端推断ACK已经被成功接收，则结束TCP连接。 第二，防止类似与“三次握手”中提到了的“已经失效的连接请求报文段”出现在本连接中。客户端发送完最后一个确认报文后，在这个2MSL时间中，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样新的连接中不会出现旧连接的请求报文。 RFC 793中规定MSL为2分钟，实际应用中常用的是30秒，1分钟和2分钟等 为什么建立是三次握手，断开时四次握手呢？ 这是因为服务端的LISTEN状态下的SOCKET当收到SYN报文的建立连接请求后，它可以把ACK和SYN（ACK起应答作用，而SYN起同步作用）放在一 个报文里来发送。但关闭连接时，当收到对方的FIN报文通知时，它仅仅表示对方没有数据发送给你了；但你所有的数据未必都全部发送给对方了，所以你未必会马上会关闭SOCKET,即你可能还需要发送一些数据给对方之后，再发送FIN报文给对方来表示你同意现在可以关闭连接了，所以它这里的ACK报文和FIN报文多数情况下都是分开发送的。 如果已经建立了连接，但是客户端突然出现故障了怎么办？ TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75分钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。 为什么不能用两次握手进行连接？ 不用三次的话，server不能确定client是否收到自己的消息如果没有收到，可能client根本没收到，或者client响应了，但server没收到","categories":[{"name":"网络学习","slug":"网络学习","permalink":"http://yoursite.com/categories/网络学习/"},{"name":"传输层","slug":"网络学习/传输层","permalink":"http://yoursite.com/categories/网络学习/传输层/"}],"tags":[{"name":"传输层","slug":"传输层","permalink":"http://yoursite.com/tags/传输层/"}]},{"title":"Linux-信号","slug":"Linux-信号","date":"2018-03-26T03:42:02.000Z","updated":"2018-03-26T12:05:32.676Z","comments":true,"path":"2018/03/26/Linux-信号/","link":"","permalink":"http://yoursite.com/2018/03/26/Linux-信号/","excerpt":"此篇博客对于Linux中信号的相关知识点做介绍。 一.信号的概念什么是信号呢?","text":"此篇博客对于Linux中信号的相关知识点做介绍。 一.信号的概念什么是信号呢? 信号怎么说呢？比如古代的摔杯为号，比赛名枪为号，这都是信号。 这些信号都有一个共同的特性，那就是简单、不能携带大量信息，满足一点条件时才产生。 信号是软件中断，很多重要的程序的需要处理信号，信号提供了一种异步事件的方法，所以是系统中必不可少的东西！ Unix早期版本就提供了信号机制，但不可靠，信号可能丢失。Berkeley 和 AT&amp;T都对信号模型做了更改，增加了可靠信号机制。但彼此不兼容。POSIX.1对可靠信号例程进行了标准化。 信号的机制：A给B发送信号，B收到信号之前执行自己的代码，收到信号后，不管执行到程序的什么位置，都要暂停运行，去处理信号，处理完毕再继续执行。与硬件中断类似——异步模式。但信号是软件层面上实现的中断，早期常被称为“软中断”。 信号的特质：由于信号是通过软件方法实现，其实现手段导致信号有很强的延时性。但对于用户来说，这个延迟时间非常短，不易察觉。 首先来看一下Linux中的一些信号。这是linux系统中的提供的一些信号，一共是62个不是64个，但是我们只需要掌握了解1-31号信号（非实时信号，不可靠信号，不支持排队，容易丢失），34-64序列的信号是驱动层次的信号（实时信号，可靠信号，支持排队，不会丢失），我们一般接触不到！ 二.信号的产生方式1.当用户按某些中断键时，引发终端产生对应的信号，比如ctrl +c.这里详细说一下：当我们在shell下启动一个前台进程，这个时候当用户在键盘上按下ctrl+c,这个时候键盘输入产生一个硬件中断，如果当前cpu正在执行这个进程的代码，则该进程的用户空间代码暂停执行，cpu从用户态切入内核态处理硬件中断，终端驱动程序将ctrl+c解释成一个SIGINT信号，将这个信号记录在这个前台进程的pcb中，当某个时候准备从内核返回到该用户空间代码的时候，首先检查pcb中的记录，发现有信号SIGIN未处理，而且发现这个信号的处理动作是默认动作，因为其默认动作是终止进程，那么将直接终止进程而不再返回它的用户空间去执行刚才未执行完的代码。 注意：按键产生方式产生的信号只能发给前台进程。因为前台程序在执行的过程中用户随时可以按下组合件所以这体现了信号具有异步性。 还要说明一个问题那就是Core Dump，有的信号的默认处理动作是结束进程，但是有的信号在结束进程的同时并且Core Dump，下面解释一下Core Dump :当一个进程要异常终止的时候，可以选择把进程的用户空间内的数据全部保存在磁盘上，这个保存数据的文件名是core,这个动作就是Core Dump。进程异常终止的原因一般来说是有BUG,所以我们可以通过这个文件来找出我们的错误出在了哪里。。。但是系统默认是不支持core文件产生的，因为其中会保存关系用户密码等敏感信息，不安全，如果我们想使用的话需要用ulimit来进行设置。 接下来我们写一个死循环程序，让其在前台运行，然后通过ctrl+\\产生SIGQUIT（能产生core文件的信号） 需要找bug的话，使用gdb core-file +core文件，程序会自动跳到出错的地方 2.硬件异常产生的信号比如除数为0，无效的内存引用等。这些条件通常由硬件检测到，并通知内核，然后内核为产生该条件的进程发送一个信号（这里的发送其实实质上指的是在进程的PCB中做一些记录，后面我们在详细去讲） 3.调用系统函数向进程发送信号1.使用kill函数（man 2 kill可查看） #include &lt;sys/types.h&gt; #include &lt;signal.h&gt; int kill(pid_t pid, int sig); 成功返回0，失败-1 说明： id &gt; 0: 发送信号给指定的进程。 pid = 0: 发送信号给 与调用kill函数进程属于同一进程组的所有进程。 pid &lt; 0: 取|pid|发给对应进程组。 pid = -1：发送给进程有权限发送的系统中所有进程。 进程组：每个进程都属于一个进程组，进程组是一个或多个进程集合，他们相互关联，共同完成一个实体任务，每个进程组都有一个进程组长，默认进程组ID与进程组长ID相同。权限保护：super用户(root)可以发送信号给任意用户，普通用户是不能向系统用户发送信号的。 kill -9 (root用户的pid) 是不可以的。同样，普通用户也不能向其他普通用户发送信号，终止其进程。 只能向自己创建的进程发送信号。普通用户基本规则是：发送者实际或有效用户ID == 接收者实际或有效用户ID 2.使用kill命令（man 1 kill可查看）,此命令只是kill函数的一个借口，用来终止一个失控的后台程序 3.raise函数：给当前进程发送指定信号，自己给自己发 #include &lt;signal.h&gt; int raise(int sig); 成功返回0，失败返回-1 4.abort函数：自己给自己发送异常终止信号6）SIGARBT，终止自己并产生core文件 #include &lt;stdlib.h&gt; void abort(void); 因为这个函数和exit一样总会 成功执行，所以没有返回值 4.由软件条件产生的信号比如SIGPIPE，不过这次要重点介绍alarm函数 #include &lt;unistd.h&gt; unsigned int alarm(unsigned int seconds); 调用alarm函数可以给当前进程设置一个闹钟，也就是告诉内核早seconds秒之后给当前进程发送SIGALRM信号，该信号的默认处理动作是将当前进程终止。每个进程都有仅且唯一的一个定时器。 这个函数返回值如果是0，则说明闹铃正确设置并且只有一个闹铃，如果你当前已经设置了一个闹铃了，那么alarm(0)，表示取消之前所设置的闹铃，返回之前闹铃剩余的时间。假如在次使用alarm(10)，则表示重新设置闹铃为10秒，并且此时的闹铃返回之前 设置闹铃的剩余时间。 另外设置闹铃和进程的状态无关。使用time+可执行程序可以查看程序的执行时间。 另外除了alarm可以设置闹铃以外。setitimer函数也可以设置闹铃，并且它的计时功能更加的齐全。感兴趣的自己了解，，，这块我后面再补充吧。 三.信号在内核中的表示方法和信号的处理方法1.信号内核中的表示 block:是用来设置信号屏蔽的，如果里面对应的是1则表示该信号产生了，并且被屏蔽不能抵达，即如果block里面是1则,pending里面一定是1 pending:表示产生了一个信号。 默认执行动作：表示这个信号一旦抵达根据默认执行动作的指示执行相关动作，如果用户自己设置了捕捉函数的话，则将执行用户指定的函数。SIG_DFL：表示指针默认动作SIG_IGN:表示忽略此信号 注意：一个信号一旦被阻塞，如果在这信号阻塞期间多次产生这个信号的话，如果这个信号不是实时信号的话，则只记录一次，如果是实时信号的话，则将所有产生的信号放在一个队列里。 2.信号处理方法 1.执行其默认动作 2.忽略 3.用户自定义函数捕捉。 四.信号集操作函数内核通过读取未决信号集来判断信号是否应被处理。信号屏蔽字mask可以影响未决信号集。而我们可以在应用程序中自定义set来改变mask。已达到屏蔽指定信号的目的。 所以引入一种类型sigset_t 表示信号集类型，我们可以通过这个类型定义信号集变量，通过一些信号集操作函数来影响信号屏蔽字从而达到屏蔽指定信号的目的。 1.下面来介绍一下信号集的操作函数 #include &lt;signal.h&gt; int sigemptyset(sigset_t *set);//将自定义信号集所有位清为0 int sigfillset(sigset_t *set);//将自定义的信号集所有位清为1 int sigaddset(sigset_t *set, int signum);//将指定信号加入信号集 int sigdelset(sigset_t *set, int signum);//将指定信号从信号集中删除 int sigismember(const sigset_t *set, int signum);//判断某个信号是否在信号集中 这些函数都是成功返回0，错误返回-1，最后一个函数是一个布尔函数。 既然我们自定义的信号集已经设置好了，那么如何通过自定义的信号集取影响内核的信号屏蔽字呢？ 2.使用sigprocmask函数 #include &lt;signal.h&gt; int sigprocmask(int how, const sigset_t *set, sigset_t *oldset); 成功返回0，出错返回-1 参数 1.how有三个取值b，分别表示自定义的信号集和内核的信号屏蔽字做什么样的操作，即如果影响内核的信号屏蔽字 SIG_BLOCK：表示mask=mask | set,即将我们希望添加屏蔽的信号添加到信号屏蔽字当中去 SIG_UNBLOCK：表示mask=mask &amp;~ set ,表示我们想将信号屏蔽字中的哪些信号解除阻塞 SIG_SETMASK：表示mask=set，将内核中的信号屏蔽字的值替换为我们自己定义的值 2.set:表示我们自己定义的信号集 3.oldset:保存更改前的信号屏蔽字的值，可以为空 如果调用sigprocmask解除了对当前若干个未决信号的阻塞，则在sigprocmask返回前，至少将其中一个信号抵达 3.sigpending：读取当前未决信号集，由set传出 #include &lt;signal.h&gt; int sigpending(sigset_t *set); 五.信号捕捉函数1.signal #include &lt;signal.h&gt; typedef void (*sighandler_t)(int); sighandler_t signal(int signum, sighandler_t handler); 参数signum:表示要捕捉的信号 handlrt:表示要执行的捕捉动作，可以看出其实函数指针 2.signaction #include &lt;signal.h&gt; int sigaction(int signum, const struct sigaction *act, struct sigaction *oldact); 在这里只关系我标记星星的三个成员 参数： signum:表示要捕捉的信号 sa_handler:表示执行的捕捉动作 sa_mask表示在函数调用期间所要屏蔽的信号的信号集 sa_flag=0，系统默认设置 此函数的信号捕捉函数执行的时候，sa_mask中屏蔽的信号多次发过来的话，则等处理函数处理完只执行一次，在捕捉函数执行期间，信号屏蔽字由sa_mask决定！ 信号在 内核中的捕捉过程 当一个进程发生某种异常中断后，这个时候系统切换到内核状态处理中断，然后在要返回的时候检查进程有信号抵达，并且用户设置了自定义的信号捕捉函数，则内核调用handle_signal（）函数从而回到用户态去调用用户自定义的信号处理函数（这期间需要使用setup_frame或setup_rt_frame来为信号处理函数设置栈)，当内核回到用户态执行完用户自定义的处理函数以后，位于 setup_framesetup_rt_frame栈之上的返回代码(return code)被执行,这返回代码会执行sigreturn，再次进入内核回到上次从内核转到用户态的位置，然后返回用户态执行刚才主函数中断的 代码的下面的指令。 六.时序静态问题介绍时序静态之前就要说一下pause函数 #include &lt;unistd.h&gt; int pause(void); pause函数使进程挂起直到有信号抵达，如果信号的处理动作是终止进程，则进程终止，pause函数没有机会返回，如果信号处理动作是忽略，那么pause继续处于挂起状态不返回；如果信号的处理动作是捕捉，则调用了信号处理函数之后则pasue返回-1,errno设置EINTR，所以pause只有出错返回值！EINTR表示被信号中断。 时序静态问题是： 注册SIGALRM信号处理函数 （sigaction…)调用alarm(1) 函数设定闹钟1秒。 2.函数调用刚结束，开始倒计时1秒。当前进程失去cpu，内核调度优先级高的进程(有多个)取代当前进程。当前进程无法获得cpu，进入就绪态等待cpu。 3.1秒后，闹钟超时，内核向当前进程发送SIGALRM信号(自然定时法，与进程状态无关)，高优先级进程尚未执行完，当前进程仍处于就绪态，信号无法处理(未决) 优先级高的进程执行完，当前进程获得cpu资源，内核调度回当前进程执行。SIGALRM信号递达，信号设置捕捉，执行处理函数sig_alarm。 5.信号处理函数执行结束，返回当前进程主控流程，pause()被调用挂起等待。（欲等待alarm函数发送的SIGALRM信号将自己唤醒） SIGALRM信号已经处理完毕，pause不会等到。 即简单讲就是alarm和pause之间失去了cup的时候alarm发出了信号，当cpu切回来的时候捕捉了这个信号，这个时候pause才挂起，即变成了永久挂起。 问题就是我们想到了在pause挂起之前设置屏蔽SIGALLRM这个信号，这样就不会提前处理了，在pause挂起的时候在解除屏蔽。可是这样的话在解除屏蔽的时候cpu又被切走了,那么一样会永久挂起。所以要解决这个问题，就需要将解除屏蔽和pause挂起设置为一个原子操作，即中间不会失去cpu。这就需要我们用到这个函数 1.sigsuspend #include &lt;signal.h&gt; int sigsuspend(const sigset_t *mask); 这个函数的作用是，在调用sigsuspend函数的时候，进程的信号屏蔽字由其传入的mask决定，然后挂起等待，当sigsuspend返回的时候即信号屏蔽字恢复为原来的进程的值。 这个函数怎么用呢？ 我们可以进程原来的信号屏蔽字设置为屏蔽SIGALRM，这样的话无论你什么时候cpu切出去，切多久，你如果产生了SIGALRM信号的话，那么系统也不处理，当回来以后sigsuspend挂起后，这个时候将其中的信号屏蔽字并没有屏蔽SIGALRM信号，则立刻处理，然后结束挂起。这样就可以实现解除屏蔽和挂起的原子性从而解决时序竟态的问题 七.可重入函数一个函数在被调用执行期间(尚未调用结束)，由于某种时序又被重复调用，称之为“重入”。根据函数实现的方法可分为“可重入函数”和“不可重入函数”两种 注意事项1.定义可重入函数，函数内不能含有全局变量及static变量，不能使用malloc、free 2.信号捕捉函数应设计为可重入函数 3.信号处理程序可以调用的可重入函数可参阅man 7 signal 4.没有包含在上述列表中的函数大多是不可重入的，其原因为： a)使用静态数据结构 b)调用了malloc或free c)是标准I/O函数 八.SIGCHLD子进程在终止的时候会给父进程发送SIGCHLD信号，该信号的默认处理动作是忽略，父进程可以自定义SIGCHLD捕捉函数，在里面来回收子进程了。这样就弥补了wait的一直阻塞和waitpid的轮询回收缺点。 其实要想不产生僵尸进程还有另外一种办法就是父进程调用信号捕捉函数sigaction将SIGCHLD设置SIG_IGN，这样fork出来的子进程在终止时会自动清理掉，不会产生僵尸进程，也不会通知父进程。对于系统的默认胡洛和我们自己设置的忽略一般来说是没有区别的，但是就是这个比较特殊。同样是忽略，结果却不一样，此方法只对于Linux可用。 相关代码上传至github: https://github.com/lishuaiwq/Linux-System-programming/blob/master/signal/my_sleep_sigsuspend.c","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"},{"name":"系统编程","slug":"Linux/系统编程","permalink":"http://yoursite.com/categories/Linux/系统编程/"}],"tags":[{"name":"信号","slug":"信号","permalink":"http://yoursite.com/tags/信号/"}]},{"title":"Linux进程间通信(IPC)","slug":"Linux进程间通信","date":"2018-03-22T13:48:23.000Z","updated":"2018-03-25T02:41:50.329Z","comments":true,"path":"2018/03/22/Linux进程间通信/","link":"","permalink":"http://yoursite.com/2018/03/22/Linux进程间通信/","excerpt":"关于进程间通信就不多说了，接下来对于Linux间的进程通信的一些方式进行介绍，主要方式有下面的几种 管道 消息队列 共享内存 信号量 在这里要说要一下我们这里的消息队列、共享内存、信号量是System V版本下面的IPC，注意和POSIX区别。下面我来一个一个详细介绍","text":"关于进程间通信就不多说了，接下来对于Linux间的进程通信的一些方式进行介绍，主要方式有下面的几种 管道 消息队列 共享内存 信号量 在这里要说要一下我们这里的消息队列、共享内存、信号量是System V版本下面的IPC，注意和POSIX区别。下面我来一个一个详细介绍 一.管道管道是UNIX系统IPC的最古老的方式，所有UNIX系统都提供这种通信机制。管道分为匿名管道(pipe)和命名管道(fifo) 1.匿名管道：作用于有血缘关系的进程间通信，完成数据的传送，调用pipe系统函数即可创建一个匿名管道。 #include&lt;unistd.h&gt; int pipe(int pipefd[2]) 正确返回0，错误返回-1，并且设置errno值。 其本质是一个伪文件（实质是内核的一个缓冲区） 有两个文件描述符引用，一个表示读端，一个表示写端 规定数据从管道的写端流入管道fd[1]，从读端流出管道fd[0] 采用半双工通信方式，即数据同一时刻只能在一个方向上流动 一般情况下一个进程先会调用pipe，然后调用fork(),从而创建从父进程到子进程的IPC通道。fork之后对于数据的流向取决于我们。如果我们想让父进程写数据，则将父进程的读端关闭，即关闭fd[0]，将子进程的写端关闭fd[1]，反之亦然。 我们进行相应端的关闭就可以进行通信了 对于管道最后有几点要强调的： 1.如果写端文件描述被关闭，则读端返回0 2.如果读端被关闭，则写端会产生信号SIGPIPE，写端进程结束 3.当要写入的数据不大于PIPE_BUF时，linux将保证写入的原子性，如果大于PIPE_BUF时，则不保证其写入的原子性。 4.一般而言进程退出，管道释放，所以管道的声明周期随进程。 2.命名管道对于匿名管道的应用有个限制就是只能应用于有血缘关系的进程，而命名管道恰好弥补了这个缺点，可以在两个不相干的进程间通信。 创建匿名管道的方式有两种： 1.命令创建，使用mkfifo fifoname,这就创建了一个名字为fifoname的命名管道,然后两个进程分别打开这个文件就可以通信了 2.使用mkfifo函数打开。 #include &lt;sys/types.h&gt; #include &lt;sys/stat.h&gt; int mkfifo(const char *pathname, mode_t mode); 成功返回0，失败返回-1，并设置errno。 命名管道的打开方式和打开的时候的一些问题这里强调一下： 1.如果没有设定open FIFO的O_NONBLOCK权限的话，那么当前打开的操作默认是会产生阻塞，即是读打开的FIFO的话，如果此时没有进程以写的方式打开同一个FIFO文件的话，那么当前进程阻塞，直到有进程以写的方式打开同一个FIFO，反之亦然！ 2.如果open FIFO的时候指定了 O_NONBLOCK则不阻塞。但是会产生一些问题。 如果是写进程设置了不阻塞，但是当写进程运行了时候没有于之对应的读进程运行的话，那么这个写进程的open操作会立马返回失败，错误号为ENXIO(6)，使用errno全局变量可以打印出来。 如果是读进程设置了不阻塞，运行时没有写进程与之对应，则读进程open成功，只不过以读取值为0而退出。 所以一般情况下，就默认阻塞就可以了。。。免得产生一堆麻烦 对于设置了阻塞标志的写操作： 当要写入的数据量不大于PIPE_BUF时，linux将保证写入的原子性。如果此时管道空闲缓冲区不足以容纳要写入的字节数，则进入睡眠，直到当缓冲区中能够容纳要写入的字节数时，才开始进行一次性写操作。当要写入的数据量大于PIPE_BUF时，linux将不再保证写入的原子性。FIFO缓冲区一有空闲区域，写进程就会试图向管道写入数据，写操作在写完所有请求写的数据后返回。 对于没有设置阻塞标志的写操作： 当要写入的数据量大于PIPE_BUF时，linux将不再保证写入的原子性。在写满所有FIFO空闲缓冲区后，写操作返回。当要写入的数据量不大于PIPE_BUF时，linux将保证写入的原子性。如果当前FIFO空闲缓冲区能够容纳请求写入的字节数，写完后成功返回；如果当前FIFO空闲缓冲区不能够容纳请求写入的字节数，则返回EAGAIN错误，提醒以后再写； 对于运行时的一些操作： 如果两个进程正在进行读写操作，这个时候读端关闭了，那么写端再写的话，写进程会产生一个SIGPIPE（13）的信号，意思是写入没有读端的操作，那么会将写进程终止掉。自己可以去捕捉验证。如果是写进程先关闭的话，那么会给读进程产生一个文件结束标志，即读进程以读取值为0方式退出！ （划重点了！考试要考！注意共享资源printf的刷新fflush(stdout)，不然会影响两边的输出,切记！！！！，还有FIFO也是半双工，想要互相通信的话那么记得创建两个fifo来通信） 关于fifo的使用自己去练习吧，这里就不贴多余的代码了。 二.消息队列消息队列是消息的链表，存储在内核中，由消息队列标识符标识！它是内核给我们提供的一种IPC的方式。首先给出一个大概的示意图 再来看看系统为我们维护的消息队列的结构 在/usr/include/linux/msg.h中查看对于结构体中的第一个结构体ipc_perm在这里 在这里查看/usr/include/linux/ipc.h 所以说系统大概是 这么维护我们这个消息队列的！ 先简单概括一下怎么使用消息队列吧： 1.得到_key,用来生成一个唯一的消息队列的秘钥，然后得到一个消息队列的标识符，用这个标识符来进行相关操作。下面来介绍一些关于消息队列的使用函数。 1.获取_key的函数#include &lt;sys/types.h&gt; #include &lt;sys/ipc.h&gt; key_t ftok(const char *pathname, int proj_id); ftok的功能就是由一个路径名字和项目ID产生一个key。 参数： pathname:就是你自己指定一个文件名（已经存在的文件名），一般情况用当前目录。（.） proj_id:是1-255之间的字符值,不能取0值 man文档的描述： ftok（）函数使用由给定路径名命名的文件的标识（它必须引用现有的， 可访问的文件）和proj_id的最低有效8位（它必须是非零）来生成key_t类型 System V IPC密钥，适用于msgget（2），semget（2）或shmget（2）。 其返回值成功我们的秘钥，失败返回-1，这样通过这个函数就得到了_key. 2.创建消息队列#include &lt;sys/types.h&gt; #include &lt;sys/ipc.h&gt; #include &lt;sys/msg.h&gt; int msgget(key_t key, int msgflg); 参数： 1.key就是我们的秘钥 2.生成消息队列的一些权限和打开文件时的一些权限是一样的一般来说取IPC_CREATE、IPC_EXCL。如果想要创建一个新的消息队列，并且确保这个消息队列独一无二，则msgflag设置成IPC_CREATE | IPC_EXCL,这样的话当有重复消息队列的时候就会报错返回EEXIST。 成功返回消息队列的表示符，可以理解为我们创建的消息队列的名字，失败返回-1，设置errno 在这里一般情况是服务器进程创建消息队列，客户端进程只要拿到消息队列的标识符就可以和服务器通过消息队列通信 3.消息队列的控制函数#include &lt;sys/types.h&gt; #include &lt;sys/ipc.h&gt; #include &lt;sys/msg.h&gt; int msgctl(int msqid, int cmd, struct msqid_ds *buf); 成功返回0，出错返回-1 参数： 1.msqid：就是我们通过msgget获得的消息队列的标识符，用这个标识符就可以操作消息队列。 2.cmd:表示对我们要操作的消息队列要进行的操作，有三个取值 IPC_STAT: 将与msqid相关联的内核数据结构的信息复制到指向的msqid_ds结构中buf中。调用者必须具有消息队列的读取权限 IPC_SET:将与msqid相关联字段中的某些值，设置为buf所关联的消息队列中的值。执行此命令的进程需要一定的权限限制 IPC_RMID：从内核中删除消息队列及其所有的数据。这种删除立即生效。删除后扔在使用此消息队列的进程对消息队列再次进行操作的时候，将得到EIDRM错误。这个命令的执行也需要进程有一定的权限。（这三个操作同样也可以用于信号量和共享内存） 3.buf就是我们自己定义的结构体 4.往消息队列中放消息 #include &lt;sys/types.h&gt; #include &lt;sys/ipc.h&gt; #include &lt;sys/msg.h&gt; int msgsnd(int msqid, const void *msgp, size_t msgsz, int msgflg); 成功返回0，出错返回-1 在说这个函数之前，我们来看一下发送的消息的类型 是一个结构体里面的内容分别是消息的类型和消息的内容。消息的类型用来判断是客户端发的还是服务器发的，因为二者都在同一个消息队列中放数据不区别的话，很容易搞乱的！ 下面来看msgsnd的参数 1.msqid：消息队列的表示符 2.msgp:传入参数，表示指向我们所发送的消息，即上图中的消息的结构体类型 3.msgz:消息的长度，这个长度不包括结构体中消息类型的长度，仅仅是数据的长度 4.msgflg:控制着当前消息队列满或者到达系统上限时的处理方法。 magflg=IPC_NOWAIT:表示如果队列中的消息总数等于系统的限定值（消息结构体个数），或者消息队列中总的字节数等于系统限制，则立即出错返回EAGAIN. 如果没有指定magflg=NOWAIT的话，那么消息队列满了的话，则会一直阻塞到有空间可以容纳消息或者从系统中删除了这个消息队列或者收到某个信号，从信号处理返回程序。没有设置NOWAIT会返回EIDRM错误（消息队列被删除）或者返回EINTR错误（信号） 如果将消息队列删除了，那么再使用这个消息队列的进程会出错返回。 当msgnd函数成功返回的时候，msqid_ds中的内容会随之更新。 5.从消息队列中取消息#include &lt;sys/types.h&gt; #include &lt;sys/ipc.h&gt; #include &lt;sys/msg.h&gt; ssize_t msgrcv(int msqid, void *msgp, size_t msgsz, long msgtyp,int msgflg); 参数： 1.msqid:消息队列的标识符 2.msgp:指向我们自定义用来接收消息的结构体(传入传出参数) 3.msgz:消息的长度，这个长度不包括结构体中消息类型的长度，仅仅是数据的长度 4.msgtyp:表示读取消息时候的一些优先级。 msgtype==0,返回消息队列中的第一条消息 msgtype&gt;0,返回消息队列中类型为msgtype的第一条消息（就是找我们指定的消息） msgtype&lt;0,返回消息队列中类型值小于msgtype的绝对值的消息，如果这种消息有很多，则返回其中类型值最小的。（我觉得一般多个进程使用一个消息队列通信才会用到） 5.msgflg:如果队列中没有对应类型的消息将会发生的事 msgflg=IPC_NOWAIT,没有对应消息的时候不等待，返回ENOMSG错误 msgflg=MSG_NOERROR,消息大小超过magsz时被截断 msgflg=MSG_NOERROR并且msgtype&gt;0，接收类型不等于msgtype的第一条消息。 三.共享内存先用一张图来解释吧 共享内存就是一块物理内存可以映射到多个继承的共享区，那么每个进程都可以访问这块共享区，而且一个进程对这块区域的数据进行了了修改的坏，那么其他的进程都能看见，这就不需要将数据在两个进程之间复制来复制，不用进入内核，而直接实现通信，所以这是IPC最快的通信方式，但是只要多个进程对于共享区访问，就会出现同步互斥的问题，这是我们在使用共享内存唯一需要注意的地方，当然这个问题可以使用互斥锁和信号去解决。下面我们先来看看怎么使用共享内存实现进程间的通信。 首先系统为内存的你要的那块共享区域维护着一个数据结构在/usr/include/linux/shm.h中查看 我们同样可以看到个数据成员是ipc_perm，则说明我们想要创建一个共享内存则也需要一个独一无二的秘钥，即需要使用ftok函数。 1.使用ftok获取key秘钥2.创建共享内存#include &lt;sys/ipc.h&gt; #include &lt;sys/shm.h&gt; int shmget(key_t key, size_t size, int shmflg); 成功返回共享内存标识符，失败返回-1 参数： 1.key：用来创建共享内存的秘钥 2.size:共享内存的大小，以字节为单位 3.shmflg：创建时的一些权限比如IPC_CREAT、IPC_EXCL 3.将共享内存段连接到进程的虚拟地址空间 #include &lt;sys/types.h&gt; #include &lt;sys/shm.h&gt; void *shmat(int shmid, const void *shmaddr, int shmflg); 成功返回一个指针，指向共享内存的第一个字节（共享区的内存），失败返回-1 参数： 1.shmid:共享内存的标识符（物理内存） 2.shmaddr:指定连接的地址，即自己定义在虚拟内存中的地址，但是其又和shmflag参数有关系 3.shflag:其有两个取值，SHM_RND（表示取整的意思）或者SHM_RDONLY（只读） 当shmaddr==NULL,核心自动选择一个地址,用返回值返回 当shmaddr!=NULL,并且shflag没有设置SHM_RND标记，则以shmaddr为连接地址 当shmaddr!=NULL,且shmflag设置了SHM_RND标记，则连接的地址会自动向下调整为SHMLBA的整数倍。（公式：shmaddr-(shmaddr%SHMLBA)），SHMLBA意思是“低边界地址倍数，总是2的乘方”。 当shflag==SHM_RDONLY,表示连接操作用来只读共享内存，不具备写的操作。否则具备读写的权限。 一般情况下都将shmaddr设置为0，由系统去选择地址。如果shmat调用成功，则shmid_ds结构中的计数器+1。如果一个进程使用完了共享内存，则应该调用shmdt将其映射关系分离，那么shmid_ds中的计数器就会-1，但是这个分离操作并不会删除我们之前在内存中创建的共享内存，这需要我们手动去删除。 4.将共享内存段与当前进程脱离关系#include &lt;sys/types.h&gt; #include &lt;sys/shm.h&gt; int shmdt(const void *shmaddr); 成功返回0，失败返回-1 参数： shmaddr:建立的连接地址，即由shmat返回的地址。特别注意脱离关系不代表删除了共享内存。 5.用于控制共享内存（内存中的共享内存） #include &lt;sys/ipc.h&gt; #include &lt;sys/shm.h&gt; int shmctl(int shmid, int cmd, struct shmid_ds *buf); 成功返回0，失败返回-1 参数： 1.shmid：共享内存的标识符 2.cmd:将要采取的处理动作，有三个值。 3.自己定义的struct shmid_ds *buf结构体 当cmd==IPC_STAT：把自定义shmid_ds结构中的数据设置为共享内存当前的关联值 当cmd==IPC_SET:把共享内存的 shmid_ds设置为自定义的 shmid_ds的值 当cmd==IPC_RMID:删除共享内存。因为shmid_ds中的shmid_nattch是一个计数器，所以当使用该共享内存的最后一个进程删除，否则不会真的删除。 四.信号量信号量其实是一个计数器，用来完成多个进程访问共享资源的同步互斥问题。（即让每个进程有条理的访问共享资源，而不会出现混乱访问），其本身并不具有传递数据的功能，出现在这里只是以为了说明使用共享内存访问的一些问题。但是信号量也是临界资源。多个进程可以访问的，所以算是进程间通信的一种，只不过没有其他的 几种方式那么严格罢了。 这里对于一些概念的解释： 临界资源：不同进程访问的同一资源称为临界资源。 临界区：访问访问临界资源的代码 同步：有顺序的取执行 互斥：同一时刻只能有一个进程访问临界区。 因为说信号量本质是一个计数器，所以其伴随着两个原子操作（这种操作中间不会失去时间轮片，瞬间完成的），P操作和V操作。我们给出信号量结构体的伪代码 struct semaphore { int value; poniter_PCB queue; } P操作： p(s) { s.value=s.value--; if(s.value&lt;0) { 该进程的状态设置为等待状态 将该进程的PCB插入信号量结构体的等待队列中s.queue } V操作 p(s) s.value=s.value++; { 唤醒等待的队列s.queue中一个等待的进程 改变其状态为就绪，将其插入就绪队列准备运行 } 操作系统为我们维护了一个信号量集 在/usr/include/linux/sem.h中查看 由此我们可以看到想得到一个信号量集，也需要我们用秘钥key取去获得！ 下面 就来介绍一下关于信号量集和信号量的一些操作函数,如何获得秘钥key这里就不多说了 1.创建一个信号量集 #include &lt;sys/types.h&gt; #include &lt;sys/ipc.h&gt; #include &lt;sys/sem.h&gt; int semget(key_t key, int nsems, int semflg); 参数： 1.key:秘钥 2.信号集中信号量的个数 3.创建信号量集时候的一些参数IPC_CREAT 、IPC_EXCL 2.对于信号量集做的一些操作#include &lt;sys/types.h&gt; #include &lt;sys/ipc.h&gt; #include &lt;sys/sem.h&gt; int semctl(int semid, int semnum, int cmd, ...); 参数： 1.semid:信号量集的标识符 2.semnum:要操作哪个信号量 3.cmd:将要采取的措施。 4…：主要取决去cmd要执行什么动作，这里就需要一个联合体了 因为根据cmd不同的动作，我们都要使用到联合体中的一个成员变量。 当cmd==SETVAL的时候,使用val设置对应的信号量的计数值。 当cmd==GETVAL的时候获取信号量集中对应信号量的计数值 当cmd==IPC_STAT把联合体中semid_ds结构体的值设置为当前信号集的值 当cmd==IPC_SET把当前信号集的值设置为自己定义的semid_ds的值 当cmd==IPC_RMID删除信号集 3.对信号量集的信号量进行操作(PV操作) #include &lt;sys/types.h&gt; #include &lt;sys/ipc.h&gt; #include &lt;sys/sem.h&gt; int semop(int semid, struct sembuf *sops, unsigned nsops); 参数： 1.semid:信号量集的标识符 2.sops:对应一个strutc sembuf* 3.nsops：信号集中信号量的个数 其中struct sembuf的结构是 struct sembuf { short sem_num; short sem_op; short sem_flag; } num:表示信号量的编号 sen_op:取-1，表示p操作–(表示获取信号量控制的资源)，取+1，v操作（表示释放该信号量控制的资源） sem_flag:一般来说取IPC_NOWAIT或者IPC_UNDO。详见unpe458页。 好了关于Linux的进程间通信的一些方法就说完了，当然这里讲的是共享内存，还有一种通信方式是内存映射，即借助同一个文件在不同进程的共享区映射一个区域，当进程在这个区域进程操作 时，相当于在文件中操作，也可以进程通信，这个就需要使用mmap()函数，当然关于这种通信方式也在我的CSDN博客中介绍了。感兴趣的可以了解一下 内存共享和内存映射的区别https://blog.csdn.net/it_iverson/article/details/79303567 还有进程间也可以直接借助文件来进行通信！ 关于本篇博客中进程间通信方式的联系源代码已经上传至github https://github.com/lishuaiwq/linux_ipc 如果博客中有什么不对的地方希望大家提出来！","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"},{"name":"系统编程","slug":"Linux/系统编程","permalink":"http://yoursite.com/categories/Linux/系统编程/"}],"tags":[{"name":"进程间通信","slug":"进程间通信","permalink":"http://yoursite.com/tags/进程间通信/"}]},{"title":"每日五题06","slug":"每日五题06","date":"2018-03-17T01:16:32.000Z","updated":"2018-03-22T12:21:19.483Z","comments":true,"path":"2018/03/17/每日五题06/","link":"","permalink":"http://yoursite.com/2018/03/17/每日五题06/","excerpt":"问题1：fopen,open;fwrite write;fread,read他们的区别和那些的移植性好一些在说这个问题之前，首先补充一点小知识，就是文件描述符和文件指针的区别。（FILE* ,fd） 简单的来说文件描述符就是用linux系统I/O函数open打开文件的时候会返回一个文件描述符，内核会为每一个运行中的进程在进程控制块pcb中维护一个打开文件的记录表，每一个表项都有一个指针指向打开的文件，上边的索引值是记录表的索引值。文件描述符的优点：兼容POSIX标准，许多系统调用都依赖于它；缺点是不能移植到unix之外的系统上去。。","text":"问题1：fopen,open;fwrite write;fread,read他们的区别和那些的移植性好一些在说这个问题之前，首先补充一点小知识，就是文件描述符和文件指针的区别。（FILE* ,fd） 简单的来说文件描述符就是用linux系统I/O函数open打开文件的时候会返回一个文件描述符，内核会为每一个运行中的进程在进程控制块pcb中维护一个打开文件的记录表，每一个表项都有一个指针指向打开的文件，上边的索引值是记录表的索引值。文件描述符的优点：兼容POSIX标准，许多系统调用都依赖于它；缺点是不能移植到unix之外的系统上去。。而FILE*是使用c语言库函数fopen打开文件的时候，返回一个FILE结构的指针，这个结构中主要的内容就是文件描述符和缓冲区。所以说c语言的I/O库函数会维护一个缓冲区，而linux中没有缓冲区，需要我们自己去定义。所以可以说FILE是索引的索引！ 使缓冲区写入磁盘的几种情况： 1.fflush:int fflush(FILE *stream) 2.缓冲区满了，自动写入 3.正常的关闭文件 发fclose,return(main函数中),exit(main函数中) 4.回车键 5.遇到\\n换行结束 下面来一个一个说： 1.fopen和open 上面已经说过了fopen会返回一个FILE类型的指针，而open返回的是文件描述符，并且fopen是c语言的库函数，有缓冲区，open是系统函数，没有缓冲区。并且fopen的可移植性较高，open不可移植。 2.fread和read fread：size_t fread ( void buffer, size_t size, size_t count, FILE stream) buffer：用于接收数据的内存地址（一般情况是自己定义的数组） size：要读的每个数据项的字节数，单位是字节 count：要读count个数据项，每个数据项size个字节 stream：输入流 在这里fwrite也是c库函数，它从文件流中读数据，最多读取count个项，每个项size个字节，如果调用成功返回实际读取到的项个数（小于或等于count），如果不成功或读到文件末尾返回 0。也是库函数，并且有缓冲区，read是linux的系统调用函数，一般来说fread底层也是调用的read，所以fread的效率更高，而且功能比read更强大，read是从文件中读取多少个字节，返回值是读取的字节数。read返回实际读到的字节数，返回0表示已经读到了文件末尾或者没有文件可读，如果出错返回-1并设置错误码。 3.fwrite和write 和fread和read对应着理解这里就不多说了，可移植性肯定是c语言库函数比较好。 问题2：typeid类型检查在c++中，typeid用于返回指针或引用所指对象的实际类型。注意：typeid是操作符，不是函数！ 运行时获知变量类型名称，可以使用 typeid(变量).name()，需要注意不是所有编译器都输出”int”、”float”等之类的名称，对于这类的编译器可以这样使用：float f = 1.1f; if( typeid(f) == typeid(0.0f) ) …… 补充：对非引用类型，typeid是在编译时期识别的，只有引用类型才会在运行时识别。 问题3:模板中的非类型参数与类型参数的区别首先解释一下什么是类型模板参数和非类型模板参数呢？ 我们知道，用模板的时候可以为他提供两种类型的模板形参：一种是类型模板形参，一种是非类型模板形参。例如如下声明： template&lt;class T&gt;void foo(T t); //用的类型模板形参 template&lt;class T,int n&gt;void foo(T t); //用了类型模板形参，同时还用到了非类型模板形参int 两者的区别是：对应类型模板形参，编译器会根据实参（对应模板函数）或者用户指定类型来实例化对应的模板函数或类型。而非类型模板形参主要是用来在模板函数调用时指定该形参的值。非类型模板形参最常用的是用来自动获取数组的维数。 template&lt;class T,int N&gt; void print(T (&amp;r)[N]) { for (int i=0;i&lt;N;++i) { cout&lt;&lt;r[i]&lt;&lt;&quot;,&quot;; } cout&lt;&lt;endl; } 数组的模板形式一般写成这个样子。还有关于非类型的模板参数的一些详解我给出如下博客的链接：http://blog.csdn.net/u012999985/article/details/50780311 问题4:static_cast和reinterpret_cast区别http://blog.csdn.net/deyili/article/details/5354242 问题5：继承中析构函数最好为虚函数，为什么？为什么不建议在构造函数中调用虚函数？1.http://blog.csdn.net/it_iverson/article/details/785316512.http://blog.csdn.net/it_iverson/article/details/78541948","categories":[{"name":"面试题","slug":"面试题","permalink":"http://yoursite.com/categories/面试题/"},{"name":"c/c++","slug":"面试题/c-c","permalink":"http://yoursite.com/categories/面试题/c-c/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"http://yoursite.com/tags/面试题/"}]},{"title":"多路I/O转接-poll","slug":"多路I-O转接-poll","date":"2018-03-13T12:35:19.000Z","updated":"2018-03-22T13:46:31.813Z","comments":true,"path":"2018/03/13/多路I-O转接-poll/","link":"","permalink":"http://yoursite.com/2018/03/13/多路I-O转接-poll/","excerpt":"首先多路I/O是在select的基础上进行升级改版的。既然是升级版的那肯定就比select好用。下面我来说说poll相对于select的优点","text":"首先多路I/O是在select的基础上进行升级改版的。既然是升级版的那肯定就比select好用。下面我来说说poll相对于select的优点 1.突破了select受FD_SETSIZE限制只能最多只能监控1024个文件描述符的缺点。我们可以通过修改当前配置文件来改变这个文件数，但是不能超过硬件允许的最大的数量。（我们可以通过cat /proc/sys/fs/file-max这个命令来查看当前硬件允许最大的打开文件的的数量） 可以看到我这里允许最大的数是101015，在用ulimit -a查看一下当前默认的打开数值上限 可以看到上限是1024 现在我们将其修改到4096，vim /etc/security/limits.conf，在文档处添加如下内容然后注销用户或者重启就生效了。 2.select的监听事件和返回事件是一个集合，但是在poll中，它将这两个事件分开了。 3.poll的搜范围变小了，仅限制于我们自己所定义的数组的范围。 但是poll还是有不足的地方，比如我监听了500个文件描述，但是只有3个文件描述符满足动作条件，但是poll还是会遍历整个500个文件描述符，效率有些低，所以我们的理想状态是直接将三个满足条件的文件描述符找出来，这个在epoll中可以做到，我们后面再介绍。 下面来看poll函数： 当然返回值和select是一样的。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"},{"name":"网络编程","slug":"Linux/网络编程","permalink":"http://yoursite.com/categories/Linux/网络编程/"}],"tags":[{"name":"多路I/O转接","slug":"多路I-O转接","permalink":"http://yoursite.com/tags/多路I-O转接/"}]},{"title":"多路I/O转接-select","slug":"多路I-O转接-select","date":"2018-03-10T14:32:04.000Z","updated":"2018-03-22T13:47:00.598Z","comments":true,"path":"2018/03/10/多路I-O转接-select/","link":"","permalink":"http://yoursite.com/2018/03/10/多路I-O转接-select/","excerpt":"为什么会出现多路I/O转接服务器呢？","text":"为什么会出现多路I/O转接服务器呢？因为虽然多线程和多进程服务器可以实现多个客户端同时连接服务器进行数据交流，但是这种实现方式都是进程来监听客户端是否有动静，比如accept,read，如果进程或者线程执行到这些函数的时候没有相关的动作发生则就会发生阻塞等待，函数就不能返回,这样大大的影响了程序的效率。为了解决这个问题，我们提出了一种方法，就是把监听的任务交给内核来帮我们做，当内核发现有相关动作发生以后则给当前进程一个反馈，这个时候进程在进行相关函数的调用去处理这个动作，这样的就不会产生阻塞了。实现这个要求的就是select函数，下面我来详细介。 select() select()，本函数用于确定一个或多个套接口的状态，对每一个套接口，调用者可查询它的可读性、可写性及错误状态信息，用fd_set结构来表示一组等待检查的套接口，在调用返回时，这个结构存有满足一定条件的套接口组的子集，并且select()返回满足条件的套接口的数目。有一组宏可用于对fd_set的操作，这些宏与Berkeley Unix软件中的兼容，但内部的表达是完全不同的。 函数原型和相关参数的解释： int select(int nfds, fd_set *readfds, fd_set *writefds,fd_set *exceptfds, struct timeval *timeout); nfds:监控的文件描述符集里最大文件描述符+1，因为此参数会告诉内核检测前多少个文件描述符的状态 readfds： 监控有读数据到达文件描述符集合，传入传出参数 writefds： 监控写数据到达文件描述符集合，传入传出参数 exceptfds： 监控异常发生达文件描述符集合,如带外数据到达异常，传入传出参数 timeout： 定时阻塞监控时间，3种情况 1.NULL，永远等下去 2.设置timeval，等待固定时间 3.设置timeval里时间均为0，检查描述字后立即返回，轮询 struct timeval { long tv_sec; /* seconds */ long tv_usec; /* microseconds */ }; void FD_CLR(int fd, fd_set *set); //把文件描述符集合里fd清0 int FD_ISSET(int fd, fd_set *set); //测试文件描述符集合里fd是否置1 void FD_SET(int fd, fd_set *set); //把文件描述符集合里fd位置1 void FD_ZERO(fd_set *set); //把文件描述符集合里所有位清0 select有三个可能的返值： 1）返回值－1表示出错。例在未有描述符准备好数据时捕捉到一个信号时 2）返回值0表示没有描述符准备好。若指定的描述符都没有准备好，并且指定的时间已到，则发生这种情况。 3）返回一个正数，说明已经准备好的描述符数，在这种情况下。三个描述符集中仍旧打开的位是已准备好的描述符位。 另外：1.select能监听的文件描述符个数受限于FD_SETSIZE,一般为1024，单纯改变进程打开的文件描述符个数并不能改变select监听文件个数 2.解决1024以下客户端时使用select是很合适的，但如果链接客户端过多，select采用的是轮询模型，会大大降低服务器响应效率，不应在select上投入更多精力。 下面给出select的编程大概思路 1.首先监听int sfd=socket（） 2.然后判断sfd是否有行动，如果有行动则调用int cfd=accept()函数 3.将cfd加入allfd 4.然后判断是否有写入动作，有的话进行写入。 代码已经上传至githubhttps://github.com/lishuaiwq/linux-","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"},{"name":"网络编程","slug":"Linux/网络编程","permalink":"http://yoursite.com/categories/Linux/网络编程/"}],"tags":[{"name":"多路I/O转接","slug":"多路I-O转接","permalink":"http://yoursite.com/tags/多路I-O转接/"}]},{"title":"每日五题05","slug":"每日五题05","date":"2018-03-06T00:52:42.000Z","updated":"2018-03-06T04:24:58.352Z","comments":true,"path":"2018/03/06/每日五题05/","link":"","permalink":"http://yoursite.com/2018/03/06/每日五题05/","excerpt":"问题1：new delete free malloc的关系先简单介绍一下他们。1.new和delete 在c++中使用new和delete动态的创建和释放数组和单个对象。动态创建对象时，只需指定其数据类型，而不必为该对象命名，new表达式返回指向该新创建对象的指针，我们可以通过指针来访问此对象。","text":"问题1：new delete free malloc的关系先简单介绍一下他们。1.new和delete 在c++中使用new和delete动态的创建和释放数组和单个对象。动态创建对象时，只需指定其数据类型，而不必为该对象命名，new表达式返回指向该新创建对象的指针，我们可以通过指针来访问此对象。并且动态创建的对象可以直接初始化： int *p=new int(100);*p=10; int *p=new string(10,&apos;9&apos;);p=&quot;999999999&quot; int *p=int;//未初始化 int *p=int();//初始化为0 int *p=string();//调用默认构造函数 new delete和new []和delete []成对出现！不能混合使用，尽管对于内置类型来说，混合使用不会出错，但是最好不要混合使用。 1.malloc free malloc 向系统申请分配指定size个字节的内存空间，返回类型是 void 类型。void 表示未确定类型的指针。C,C++规定，void* 类型可以强制转换为任何其它类型的指针。 free用来释放malloc在堆上申请的空间。注意：malloc以后要对指针进行转换，free以后要将其置空，还要判断malloc是否成功。 有人在网上说new是在 自由存储区申请的，我觉得这句话可以直接屏蔽，当做没看见！ 下面说说他们的区别:.malloc和new的区别1.new返回指定类型的指针，并且可以自动计算需要的大小，而malloc需要我们自己计算所需空间的大小，并且需要将返回的 void *类型进行指定类型的转换 2.malloc在分配内存的时候只能分配，而不具有初始化的功能，而new具有。 3.malloc和free是标准库函数，而new/delete是C++的运算符，支持重载。malloc和free不支持 4.对于c++自定义类型，new和delete分别会调用对象的构造和析构函数，而这一点malloc/free做不到。 5.对于内置类型而言两者没有太大的区别！ 这里附上一篇博客： http://blog.csdn.net/bat67/article/details/52022105 问题2：子类析构时候要调用父类的析构函数吗？需要：前提子类B继承父类A1.先调用父类的构造函数，然后调用子类的构造函数。准确的说是在子类的构造函数中调用父类的构造函数。先析构子类，再析构父类（B b） 2.用父类指针指向子类对象，如果父类的析构函数不是虚函数的话，则不会释放子类对象，因为不会产生多态，所以因为是父类指针就只调用父类的析构函数。http://blog.csdn.net/it_iverson/article/details/78531651 问题3：描述内存分配及他们的区别1）从静态存储区域分配。内存在程序编译的时候就已经分配好，这块内存在程序的整个运行期间都存在。例如全局变量，static变量。 2）在栈上创建。在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集。 3）从堆上分配，亦称动态内存分配。程序在运行的时候用malloc或new申请任意多少的内存，程序员自己负责在何时用free或delete释放内存。动态内存的生存期由程序员决定，使用非常灵活，但问题也最多。 问题4：分别写出BOOL,int,float,指针类型的变量a与“零”的比较语句1.对于bool型来说和0比较完全可以使用==0或者!=0,但是这种表达形式体现不出来true和false所以应该使用if(a)和if(!a) 2.对于int类型来说就要使用==和!=if(a==0)和if(a!=0) 3.对于float类型来说，不能使用！=和==的符号。因为浮点数是有误差的，它只能规定在这个范围内，所以判断两个浮点数是否相等需要，需要判断他们是否在一个区间内。所以在这里我们定义属于 [-EPSINON,EPSINON] 内得浮点数就可以认为是0，EPSINON是float类型的，只不过使用了typedef而已。 const EXPRESSION EXP = 0.000001 if ( a &lt; EXP&amp;&amp; a &gt;-EXP) 4.对于指针类型if(a==NULL)或者if(a!=NULL) 问题5：数组和指针的区别数组就是数组，指针就是指针。两个数组名除了在sizeof的情况下，都表示数组下标为0的元素的地址！int arr[3];int p=arr;int arr[][3];int p=arr;int **p=arr;这种赋值严格来说是错的，类型不匹配，在C++编译器下是无法通过的。","categories":[{"name":"面试题","slug":"面试题","permalink":"http://yoursite.com/categories/面试题/"},{"name":"c/c++","slug":"面试题/c-c","permalink":"http://yoursite.com/categories/面试题/c-c/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"http://yoursite.com/tags/面试题/"}]},{"title":"每日五题04","slug":"每日五题04","date":"2018-03-04T00:59:53.000Z","updated":"2018-03-06T04:25:15.720Z","comments":true,"path":"2018/03/04/每日五题04/","link":"","permalink":"http://yoursite.com/2018/03/04/每日五题04/","excerpt":"问题1：指针和引用的区别1.引用在定义的时候必须被初始化，而指针不用必须被初始化 2.引用初始化以后不能改变其引用对象，指针可以改变 3.不存在指向空值的引用，但是存在指向空值的指针","text":"问题1：指针和引用的区别1.引用在定义的时候必须被初始化，而指针不用必须被初始化 2.引用初始化以后不能改变其引用对象，指针可以改变 3.不存在指向空值的引用，但是存在指向空值的指针4.sizeof引用得到的是所指对象的大小，sizeof指针得到的是指针变量的大小和其指向的内容没有关系 5.指针和引用的自增运算意义不一样 6.引用的创建和销毁不会调用构造和析构函数 7.指针可以有多级，而引用只有一级 8.引用实质也是指针，const int *p=&amp;a，只不过这个工作是编译器帮我们做的 下面附上我关于引用的博客：http://blog.csdn.net/it_iverson/article/details/76832741 问题2：for(;1;)有什么问题？这是一个死循环，for中两个分好中间为判断条件，为真则执行。这里为1，相当于true，也就是死循环。等价于for(;;)也等价于while(1)。 那么下面来说说for(;;)和while(1)的区别 1、 for（；；）死循环里的两个；；代表两个空语句，编译器一般会优化掉它们，直接进入循环体。while（1）死循环里的1被看成表达式，每循环一次都要判断常量1是不是等于零。即，相对来说for式死循环更加高效一点当然以上条件成立还要看编译器的优化，一些编译器优化的两者并无区别，但是，并非所有的编译器都做了这样的优化。 2、for（；；）只有7个字符和while（1）相比省一个字符 问题3：用宏定义写swap(x,y)#define Swap(x,y) (x)=(x)+(y);(y)=(x)-(y);(x)=(x)-(y) #define Swap(x,y) (x)=((x)^(y));(y)=((x)^(y));(x)=((x)^(y)) 问题4：关键字const 和volatilehttp://blog.csdn.net/it_iverson/article/details/78488249这篇博客是关于const的详解下面说说volatile volatile 关键字是一种类型修饰符，用它声明的类型变量表示可以被某些编译器未知的因素更改，比如：操作系统、硬件或者其它线程等。遇到这个关键字声明的变量，编译器对访问该变量的代码就不再进行优化，从而可以提供对特殊地址的稳定访问。声明时语法：int volatile vInt; 当要求使用 volatile 声明的变量的值的时候，系统总是重新从它所在的内存读取数据，即使它前面的指令刚刚从该处读取过数据。而且读取的数据立刻被保存 当一个 变量被const和volatile同时修饰的时候： 主要要搞清楚 编译期 和 运行期的关系。编译期就是 C 编译器将 源代码转化为 汇编再到机器代码 的过程。运行期就是 实际的机器代码在CPU执行 的过程。很多书上说的东西，其实都只是指编译期进行的事情。const 和 volatile 也一样，所谓的 const ，只是告诉编译器要保证在 C的“源代码”里面，没有对该变量进行修改的地方，就是该变量不能而出现在赋值符号左边。实际运行的时候则不是 编译器 所能管的了。同样，volatile的所谓“可能被修改”，是指“在运行期间”可能被修改。也就是告诉编译器，这个变量不是“只”会被这些 C的“源代码”所操纵，其它地方也有操纵它们的地方。所以，C编译器就不能随便对它进行优化了 。所以每次读它要在它内存中读，不要在寄存器中读备份。 问题5：struct和class的区别首先c++中对于struct进行了极大的改进和优化。下面我们来讲讲其和class的区别1.首先是对于默认访问权限的 区别。class如果不写的话就是私有，而struct是public的，c++中的struct也可以继承，实现多态，包含成员函数。所以class和struct可以混合继承，但是这里的继承权限取决于子类是struct还是class ,如果子类是 class 并且没有写继承权限的话就是私有继承，如果是struct并且没有写继承权限的话就是私有继承。 2.class可以用于定义模板参数，而struct不行 3.struct可以默认使用{}初始化，而class不行，因为其默认访问权限是private的,所以将其默认权限改成public的话class也可以使用{}。但是如果给struct加入构造函数，则struct也不能使用{}初始化了。","categories":[{"name":"面试题","slug":"面试题","permalink":"http://yoursite.com/categories/面试题/"},{"name":"c/c++","slug":"面试题/c-c","permalink":"http://yoursite.com/categories/面试题/c-c/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"http://yoursite.com/tags/面试题/"}]},{"title":"每日五题03","slug":"每日五题03","date":"2018-03-02T02:37:28.000Z","updated":"2018-03-03T02:50:43.706Z","comments":true,"path":"2018/03/02/每日五题03/","link":"","permalink":"http://yoursite.com/2018/03/02/每日五题03/","excerpt":"问题1：c++中为什么有时候要用extern “C”extern “C’的作用是：告诉C++编译器，我用extern “C”声明的函数，你给我当成C语言中的函数来处理，别走你的c++路线就可以了。为什么要这样呢？举个例子","text":"问题1：c++中为什么有时候要用extern “C”extern “C’的作用是：告诉C++编译器，我用extern “C”声明的函数，你给我当成C语言中的函数来处理，别走你的c++路线就可以了。为什么要这样呢？举个例子a.c文件内容如下： #include&lt;stdio.h&gt; int fun() { return 10; } b.cpp文件内容如下: #include&lt;iostream&gt; using namesapce std; extern int fun();//声明fun函数是外部的 int main() { cout&lt;&lt;fun()&lt;&lt;endl; return 0; } 现在a.c文件的内容我照c编译器取去编译汇编生成二进制文件a.o(gcc -c a.c),下面我们来编译b.cpp文件 g++ b.cpp a.o 我们会发现编译器会报错：错误内容是fun函数未定义，这是为什么呢？明明已经用extern声明了fun函数了还会报错。这就牵扯到了c++和c编译器对于函数的处理c++因为其支持函数重载，所以c++编译器在对函数名处理的过程中需要结合其函数名，参数类型等生成一个独一无二的函数名，而c编译器就只是简单的处理了一下函数名就完了。所以在上面的问题主要是c++编译器将b.cpp中的fun函数可能处理成了_fun_int_（假设）这种类型，而a.c中的函数被c编译器处理成了_fun这种类型，所以在连接的过程中b.cpp在a.c文件中只能找到_fun这个类型函数，和自己文件中的_fun_int_函数无法匹配，所以调用失败，所以显示的未定义。这个时候extern “C”就闪亮登场了。用extern “C”在b.cpp中声明fun函数,像这样 1 extern &quot;C&quot; int fun(); 2 extern &quot;C&quot; { int fun();} 两种形式都可以。那么c++编译器在处理b.cpp的时候就会把fun（）函数按照c语言的命名规则来处理，处理成_fun，这样的话刚好在a.c中找到了_fun，就可以调用成功了！这就是extern “C”的作用！ 强调： 1.gcc -c a.c将a.c生成目标文件等着连接器连接呢会生成a.o g++ b.cpp a.o问题2：全局变量和局部变量的区别 有区别：全局变量保存在内存的全局存储区中，占用静态的存储单元；局部变量保存在栈中，只有在所在函数被调用时才动态地为变量分配存储单元。当一个c程序占用内存以下的几个部分 栈：由编译器进行管理，自动分配和释放，存放函数调用过程中的各种参数、局部变量、返回值以及函数返回地址。操作方式类似数据结构中的栈。 堆：用于程序动态申请分配和释放空间。C语言中的malloc和free，C++中的new和delete均是在堆中进行的。正常情况下，程序员申请的空间在使用结束后应该释放，若程序员没有释放空间，则程序结束时系统自动回收。注意：这里的“堆”并不是数据结构中的“堆”。 全局（静态）存储区:分为DATA段和BSS段。DATA段（全局初始化区）存放初始化的全局变量和静态变量；BSS段（全局未初始化区）存放未初始化的全局变量和静态变量。程序运行结束时自动释放。其中BBS段在程序执行之前会被系统自动清0，所以未初始化的全局变量和静态变量在程序执行之前已经为0。 常量区：存放常量字符串。程序结束后由系统释放。 代码段：存放程序的二进制代码。 问题3:堆栈溢出一般由什么原因造成的1.没有回收垃圾资源 2.递归层次太深 3.分配了超额的空间 问题4：什么函数不能声明为虚函数首先先解释一下什么是虚函数，以及他的作用！然后再回答主问题 1.普通的函数，即不在类中。 因为普通的函数只能被重载，不能被继承，也不能被重写，在编译期间就绑定的函数，所以不能声明为虚函数，没意义。如果你 这样做了 ，编译器会告诉你声明无效！ 2.构造函数 这个我上篇文章中就很详细的说明了这里就不多解释了 3.内联函数 inline函数在编译时被展开，用函数体去替换函数，而virtual是在运行期间才能动态绑定的，这也决定了inline函数不可能为虚函数。（inline函数体现的是一种编译机制，而virtual体现的是一种动态运行机制） 4.静态成员函数 静态成员函数是类的组成部分，但是不是任何对象的组成部分，所有对象共享一份，没有必要动态绑定，也不能被继承【效果能，但机理不能。静态成员函数就一份实体，在父类里；子类继承父类时也无需拷贝父类的静态函数，但子类可以使用父类的静态成员函数】，并且静态成员函数只能访问静态变量。所以不能为virtual。 5.友元函数 友员函数不是类的成员函数，C++不支持友员被继承，所以不能为virtual。 能是虚函数的条件： 1.是类的成员函数； 2.能被继承； 3.动态编译绑定，动态；迟联编译： 注意：空指针不能调用虚函数，因为虚指针在创建对象时创建，没有创建对象就没有虚指针，那么用空指针调用虚函数就会崩溃！！ 空指针可以调用成员函数，前提是该成员函数没有调用类的成员变量，因为指针只要拿到函数的入口地址就可以调用该函数，但是如果调用了成员变量，则因为找不到成员变量而崩溃！！！学习自:http://blog.csdn.net/gogokongyin/article/details/51121974 问题5：全局变量可不可以定义在可被多个.C文件包含的头文件中？为什么？可以！只能用static声明就行！因为用static声明的全局变量就会变成静态全局变量此时他的作用域仅限于定义它的源文件，其他源文件不可见所以不会引起命名冲突和重定义！不然的话全局变量可以在多个源文件中声明，但是只能在一个源文件中定义，不然的话就会引起变量重定义的错误！","categories":[{"name":"面试题","slug":"面试题","permalink":"http://yoursite.com/categories/面试题/"},{"name":"c/c++","slug":"面试题/c-c","permalink":"http://yoursite.com/categories/面试题/c-c/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"http://yoursite.com/tags/面试题/"}]},{"title":"每日五题02","slug":"每日五题","date":"2018-03-01T01:20:34.000Z","updated":"2018-03-01T05:07:15.808Z","comments":true,"path":"2018/03/01/每日五题/","link":"","permalink":"http://yoursite.com/2018/03/01/每日五题/","excerpt":"问题1：构造函数能不能是虚函数？为什么？答：构造函数不能是虚函数。解释如下： 1.存储角度：虚函数对应一个虚表，而这个虚表又对应了一个vptr指针，这个指针是在对象的存储空间中的，但是调用虚函数需要用vptr找到虚表中的虚函数来调用，所以对象还没有构造呢 ？构造函数怎么能是虚函数呢？这是矛盾的一点。","text":"问题1：构造函数能不能是虚函数？为什么？答：构造函数不能是虚函数。解释如下： 1.存储角度：虚函数对应一个虚表，而这个虚表又对应了一个vptr指针，这个指针是在对象的存储空间中的，但是调用虚函数需要用vptr找到虚表中的虚函数来调用，所以对象还没有构造呢 ？构造函数怎么能是虚函数呢？这是矛盾的一点。 2.使用角度：虚函数的作用在于通过父类的指针或者引用来调用它的时候能够变成调用子类的那个成员函数。而构造函数是在创建对象时自动调用的，不可能通过父类的指针或者引用去调用，因此也就规定构造函数不能是虚函数。 3.从实现上看：构造一个对象的时候，必须知道对象的实际类型，而虚函数行为是在运行期间确定实际类型的。而在构造一个对象时，由于对象还未构造成功。编译器无法知道对象 的实际类型，是该类本身，还是该类的一个派生类，或是更深层次的派生类。无法确定。。。 问题2：什么是大小端？如何判断机器的大小端？首先给出大小端的来源： 端模式出自Jonathan Swift书写的《格列佛游记》一书，这本书根据将鸡蛋敲开的方法不同将所有的人分为两类，从圆头开始将鸡蛋敲开的人被归为Big Endian，从尖头开始将鸡蛋敲开的人被归为Littile Endian。小人国的内战就源于吃鸡蛋时是究竟从大头（Big-Endian）敲开还是从小头（Little-Endian）敲开。 在计算机业Big Endian和Little Endian也几乎引起一场战争。在计算机业界，Endian表示数据在存储器中的存放顺序。 大端：高位存在低地址，低位存在高地址； 小端：高位存在高地址，低位存在低地址；（intel的x86，ARM普遍都是属于小端） 你只需要记住：大端：高低，低高。小端：低低高高。大小端在网络字节序中也需要注意这个后面再补充。举个例子：那么怎么判断自己的机器的大小端呢？首先强调一句：CPU对数据的读取是从低地址到高地址的 int is_endian() { union MyUnion { int a; char b; }un; un.a =100;//0x0001不知道放在高端还是低端了， return un.b;//如果返回1的话，证明我们机器是低字节，低地址，即为小端 }//等于1证明为小端，等于0证明为大端 这里就列举一种方法当然还有其他方法，比如说强制类型转换，打印变量地址观察。 问题3：模拟实现strncpy,memcpy,memove1.简单描述strncpy:指定拷贝n个字节，n大于拷贝字节数则多余的补’\\0’,如果n&gt;存储空间，则正常崩溃，n小于拷贝字节，则自己在最后加一个’\\0’. char* my_strncpy(char *dest, char *src, size_t count) { assert(dest&amp;&amp;src); char *p = dest; while (count &amp;&amp; (*dest++ = *src++)) { count--; } if (count &gt; 0)//上述循环出来就意味着&apos;\\0&apos;都复制进去了 { while (--count) *dest++ = &apos;\\0&apos;; } return p; } 2.memcpy拷贝的时候容易覆盖，比图12345，我要把123拷贝到234的位置讲道理拷贝完以后应该是11235，但是用memcpy的话结果就是11115,因为当走到2的时候2已经被1覆盖了，则用1继续覆盖3…，所以我们就需要用memove来拷贝，它 可以实现逆向拷贝即从后往前拷贝,上述例子的拷贝就会是这个样子，把3给4，把2给3，把1给2，这样就不会出现覆盖的问题了即得到我们要的答案，11235 void* my_memcpy(void* dest, void* src, size_t count) { void* ret = dest; char *str1 = (char *)dest; char *str2 = (char *)src; assert(str1&amp;&amp;str2); while (count--) { *str1++ = *str2++; } return ret; } void* my_memove(void* dest, void* src, size_t count) { void* ret = dest; char *str1 = (char *)dest; char *str2 = (char *)src; assert(str1&amp;&amp;str2); if (str1 &gt; str2)//目标位置大于起始位置//使用反向拷贝 { while (count--) { *(str1 + count) = *(str2 + count); } } else { while (count--) { *str1++ = *str2++; } } return ret; } 问题4：“dynamic_cast”和“static _ cast”的区别首先C++提供了两个在层次间转换的关键字那么就是他们两个 首先来说说dynamic_cast： 该运算符把expression转换为type-id类型，但没有运行时类型检查来保证转换的安全性。它主要有如下几种用法： ①用于类层次结构中基类（父类）和派生类（子类）之间指针或引用的转换。 进行上行转换（把派生类的指针或引用转换成基类表示）是安全的； 进行下行转换（把基类指针或引用转换成派生类表示）时，由于没有动态类型检查，所以是不安全的。 ②用于基本数据类型之间的转换，如把int转换成char，把int转换成enum。这种转换的安全性也要开发人员来保证。 ③把空指针转换成目标类型的空指针。 ④把任何类型的表达式转换成void类型。 注意：static_cast不能转换掉expression的const、volatile、或者__unaligned属性。 http://blog.csdn.net/qq_26849233/article/details/62218385 问题5： C++数据类型所表示的值及范围http://blog.csdn.net/a775992553/article/details/8790241","categories":[{"name":"面试题","slug":"面试题","permalink":"http://yoursite.com/categories/面试题/"},{"name":"c/c++","slug":"面试题/c-c","permalink":"http://yoursite.com/categories/面试题/c-c/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"http://yoursite.com/tags/面试题/"}]},{"title":"每日五题01","slug":"每日十题","date":"2018-02-28T02:39:09.000Z","updated":"2018-03-06T00:50:21.713Z","comments":true,"path":"2018/02/28/每日十题/","link":"","permalink":"http://yoursite.com/2018/02/28/每日十题/","excerpt":"问题1：写一个不能被继承的类，并且可以正常使用首先一个类不能被继承，则意味着继承这个类的类并没有办法正常工作，比如无法创建对象。所以根据我们对继承的了解，在构造子类对象时先调用基类的构造函数构造子类中基类的部分，所以我们可以在 这里讲父类的构造函数和析构函数设置为私有 ，这样的话，子类就无法正常的创建对象，也就实现了我们的题目所描述的问题了。代码如下：","text":"问题1：写一个不能被继承的类，并且可以正常使用首先一个类不能被继承，则意味着继承这个类的类并没有办法正常工作，比如无法创建对象。所以根据我们对继承的了解，在构造子类对象时先调用基类的构造函数构造子类中基类的部分，所以我们可以在 这里讲父类的构造函数和析构函数设置为私有 ，这样的话，子类就无法正常的创建对象，也就实现了我们的题目所描述的问题了。代码如下： class Base//基类 { private: Base() {}; ~Base(){}; }; Dervice :public Base//派生类 {}; 上面的这个例子中类Base就不能被继承。这样写虽然实现了问题的描述，不过也显得太挫了吧，因为虽然不能被继承，但是同时类Base也无法使用呀，因为其私有的构造函数和析构函数，我们没有办法在类外创建对象。这个时候你可能就会又有一个点子了，在类Base中使用static函数创建一个对象给外界使用不就好了嘛，因为static函数的调用不需要创建对象就可以调用，这样就可以在外界使用类Base了，这确实是个不错的注意。我们来看代码 class Base { private: Base() {}; ~Base(){}; public: static Base* getobj()//生产对象 { Base *p = new Base; return p; } static void delobj(Base *p)//再把对象送进来销毁 { delete p; p = NULL; } }; class Dervice :public Base {}; 这样的话，我们通过对static函数调用（Base s=Base::getobj()）从而实现对类Base的调用，并且如果需要参数的话还可以通过函数将参数传进去。但是这样的话貌似只能在堆上创建对象，而不能在栈上创建对象。可能有人会说你把new 改成 Base s,然后return s不就行了，呵呵。。你可别忘了，Base的析构函数也是私有的，所以在函数退出的地方没法调用私有函数。所以行不通。所以还是不够完美。那么我们接下来该如何优化呢？先给出代码 class Parent { private: ~Parent(){}; Parent(){}; friend class Base; }; class Base : virtual public Parent { public: Base(){}; ~Base(){}; }; class Dervice :public Base { public: Dervice(){}; ~Dervice(){}; }; 我们给通过这种形式就可以使Base可以正常的使用，并且他不能被继承。注意Base一定是虚继承Parent,因为只有根据虚继承的特性，当子类继承了Base以后，创建对象的时候直接去调用Parent的构造对象，从而无法成功。才使Base不能被继承。如果不使用虚继承的话，就会通Base的构造函数去调用，Parent的构造函数，这样是可以的，所以Base就能被继承了在这里需要注意一下！ 问题2：解释一下多态，并且一个多态的例子；说明一个类的默认函数有哪些。1.多态：通俗的说就是同样的调用语句有不同的表现形式。根据实际的对象类型从而决定调用语句的具体的调用目标。C++中对于多态的支持是通过virtual关键字，即使用virtual声明的函数被重写后可以实现多态性。多态只能发生在父类和子类之间。想实现多态有三个固定的条件缺一不可： ①：要有继承，即父类子类这种形式 ②要有虚函数的重写 ③需要父类的指针或者引用 说道多态其实又能牵扯到静态联编和动态联编 联编：就是指一个程序模块代码之间相互关联的一个过程 静态联编：静态联编是指联编工作在编译阶段完成的，这种联编过程是在程序运行之前完成的，又称为早期联编。要实现静态联编，在编译阶段就必须确定程序中的操作调用（如函数调用）与执行该操作代码间的关系，确定这种关系称为束定，在编译时的束定称为静态束定。静态联编对函数的选择是基于指向对象的指针或者引用的类型。其优点是效率高，但灵活性差。（比如重载函数使用静态联编） 动态联编：程序联编推迟到运行时刻进行，所以又成为晚期联编，迟邦定，比如switch和if语句。 不写virtual关键字，编译器实行的是静态联编，不管因为是父类类型所以不管参数类型是什么在编译阶段就确定执行父类的函数了，而动态联编就是在运行时根据不同对象决定调用哪个函数！ 至于多态的实现原理呢？ 1.当类中声明虚函数时，编译器会在类中生成一个虚函数表 2.虚函数表是一个存储类成员函数指针的数据结构 3.虚函数表是由编译器自动生成与维护的 4.virtual成员函数会被编译器放入虚函数表中 5.当存在虚函数时，每个对象中都有一个指向虚函数的指针（C++编译器给父类对象，子类对象提前布局vptr指针），当进行test(parent *base)函数的时候，C++编译器不需要区分子类或者父类对象，只需要再base指针中，找到vptr指针即可） 6.vptr一般作为类对象的第一个成员。 2.类的默认成员函数有：这个是我CSDN博客的详解http://blog.csdn.net/it_iverson/article/details/78511564 问题3：一个指针指向的内容经常变化，如何防止编译器去优化它答：这里考察的是volatitlehttp://blog.csdn.net/turkeyzhou/article/details/8953911 问题4：写一个字符串转浮点型在这个里考察的是atof的模拟实现首先对于算法中强调几点： 1.字符数字-‘\\0’=数字本身，举个例子‘1’的ascii的值为48,‘\\0’的ascii值为47,则48-47=1; 2.对于字符串需要判断是否有+-号 3.需要判断字符串是否有小数点 4.判断空格，是否属于0-9等等一些情况 double my_atof(char *ptr) { int count=0; double sum = 0.0; int flag = 0;//标志位判断是否有+-号,0负数，1正数 while (*ptr) { if (count) count *= 10; if (*ptr == &apos;+&apos;) { ptr++; flag = 1; } else if (*ptr == &apos;-&apos;) ptr++; else if (*ptr == &apos;.&apos;) { ptr++; count++; } else if (*ptr&gt;&apos;0&apos;&amp;&amp;*ptr&lt;&apos;9&apos;) { sum = sum*10 + (*ptr - &apos;0&apos;); ptr++; } else if (*ptr == &apos; &apos;) { ptr++; } else return 0; } sum = sum / count; if (flag == 0) return sum*(-1); else return sum; } 问题5：写一个strcpy函数char* my_strcpy(char *str, char *dest) { assert(str); assert(dest); char *src = str; while (*str++ = *dest++) ; return src; }","categories":[{"name":"面试题","slug":"面试题","permalink":"http://yoursite.com/categories/面试题/"},{"name":"c/c++","slug":"面试题/c-c","permalink":"http://yoursite.com/categories/面试题/c-c/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"http://yoursite.com/tags/面试题/"}]},{"title":"深度探索c++对象模型-第四章Function语意学","slug":"深度探索c++对象模型-第四章Function语意学","date":"2018-02-26T12:52:36.000Z","updated":"2018-05-13T03:22:51.545Z","comments":true,"path":"2018/02/26/深度探索c++对象模型-第四章Function语意学/","link":"","permalink":"http://yoursite.com/2018/02/26/深度探索c++对象模型-第四章Function语意学/","excerpt":"此篇文章主要的内容是向我们介绍C++中的一些函数的调用方式，比如成员函数，非常成员函数，静态成员函数，虚函数等等，其中每一种类型的函数的调用方式都不相同。并且除了说明此章节的主题意外还告诉我们了一个小知识点,那就是","text":"此篇文章主要的内容是向我们介绍C++中的一些函数的调用方式，比如成员函数，非常成员函数，静态成员函数，虚函数等等，其中每一种类型的函数的调用方式都不相同。并且除了说明此章节的主题意外还告诉我们了一个小知识点,那就是:①静态成员函数不可能直接存取非静态成员变量，因为它没有this指针，②静态成员函数不可能被声明为const，因为const修饰函数是防止他去修改成员变量的值，而静态成员函数根本不能访问成员，所以修饰它无任何意义，所以规定不能用const 修饰静态成员函数。 1.非静态成员函数作者告诉我们设计非静态成员函数的最起码这个函数需要和一般的非成员函数有同样的效率，假如有如下的两个函数 float magnitude3d(const Point3d *_this){..};//Point3d是类名 float Point3d::magnitude3d() const {..}; 我们看起来是不是成员函数相对来说没有 带来什么负担，反而效率似乎还能高一点，因为非成员函数中还需要经形参取值才能运用成员呢。其实吧，成员函数看着小清新，其实在真正使用的时候，成员函数也是被内化非成员函数的形式了，下面作者就介绍了这个内化的过程！ 1. 改写成员函数的原型，给其安插一个额外的参数到成员函数中，用来提供成员的操作，使得类对象可以将这个函数调用，而这个额外的参数就被称作this指针！代码如下： float Point3d::magnitude3d(Point3d *const this) const {..}; 如果说成员函数是const的，则会变为: float Point3d::magnitude3d(const Point3d *const this) const {..}; 2. 将对成员的存取操作变成这个样子 { this-&gt;_x*this-&gt;y; } 3.将成员函数重新写成一个外部函数（全局函数）。将函数名经过”mangling”处理，使他在程序中独一无二。（这里mangling就是给函数的变量和函数名字经过编译器自己的一些算法，重新起一个独一无二名字，这么做是为了支持C++重载）。致此，函数就内化完成了 extern magnitude_7Point3dFv(register Point3d* const this); 既然函数都被改的飞起来了，那么函数的调用毋庸置疑也被改掉了 Point obj; Point *ptr=&amp;obj; obj.magnitude();------&gt;magnitude_7Point3dFv(&amp;obj) ptr-&gt;magnitude();------&gt;magnitude_7Point3dFv(ptr) 2.虚函数对于虚函数的调用，如果是对象指针调用的话 Point *ptr=&amp;obj; ptr-&gt;normalize();//这个函数是虚函数的话 那么可能会是如下形式： (*(ptr-&gt;vptr[1]))(ptr); 这句话是调用虚函数。，ptr等同于this指针 3.静态成员函数首先先给出两个转换形式， obj.normalize();//静态成员函数调用 normalize_7Point3dSFv(); ptr-&gt;normalize(); normalize_7Point3dSFv(); 会将其转换成非成员函数的调用，即普通的调用。后面即介绍了一下静态成员函数的特点 1.没有this指针，所以不能访问成员变量 2.不能够被声明为volatitle,virtual,const. 3.不需要经过对象就可以调用。 因为其没有this指针的特性，所以其和非成员函数有点类似，所以对其取地址，得到的是非成员函数的指针而非成员函数的指针刑（int (Ponit3d::*)()).….然后此章节后面的内容就是介绍虚拟函数包括其一些对象模型。在这里就不多说了直接附上我的两篇模型剖析的博客，感兴趣的 自己去看看CSDN:http://blog.csdn.net/it_iverson/article/details/78206211自己的博客：http://lishuaii.top/2018/02/26/c++%E5%AF%B9%E8%B1%A1%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%89%96%E6%9E%90/#more 后面我在抓抓本章的重点内容写一写吧！嗯…… 然后没发现什么哈哈！！这里在附上一篇inline的详解的博客咯：http://blog.csdn.net/it_iverson/article/details/78473778","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://yoursite.com/categories/读书笔记/"}],"tags":[{"name":"function语意学","slug":"function语意学","permalink":"http://yoursite.com/tags/function语意学/"}]},{"title":"C++对象模型的剖析","slug":"c++对象模型的剖析","date":"2018-02-26T07:11:42.000Z","updated":"2018-02-26T10:08:22.289Z","comments":true,"path":"2018/02/26/c++对象模型的剖析/","link":"","permalink":"http://yoursite.com/2018/02/26/c++对象模型的剖析/","excerpt":"1.单继承对象模型（含有虚函数）首先阐述对象模型：","text":"1.单继承对象模型（含有虚函数）首先阐述对象模型：1.子类和父类都拥有各自的虚函数表 2.如果子类重写了父类的虚函数，则在子类的虚函数表中替换同名的父类虚函数，如果没有重写，则子类的虚函数表中是父类的虚函数（注意在这里只要子类的函数 中有和父类一样的，不管子类加不加vartual，都是重写父类的虚函数） 3.如果子类有自己新写的虚函数，则该虚函数放在虚函数表的后面 class Base { public: int a; public: virtual void fun1() { cout &lt;&lt; &quot;base::fun1()&quot; &lt;&lt; endl; } virtual void fun2() { cout &lt;&lt; &quot;base::fun2()&quot; &lt;&lt; endl; } }; class Dervice :public Base { public: int b; public: virtual void fun2() { cout &lt;&lt; &quot;Dervice::fun2()&quot; &lt;&lt; endl; } virtual void fun3() { cout &lt;&lt; &quot;Dervice::fun3()&quot; &lt;&lt; endl; } }; void test() { Base b; Dervice d; Base *p = &amp;d; b.a = 10; d.b = 20; d.a = 30; } 首先来看base类的对象模型：然后看d的对象模型下面来验证一下 ： typedef void(*fun)(); fun *pp = (fun*)(*(int*)&amp;d); (*pp)(); pp++; (*pp)(); pp++; (*pp)(); 2.简单多继承对象模型简单描述： 1.如果子类新增虚函数，则放在声明的第一个父类的虚函数表中（理解成继承下来的虚表比较好理解）， 2.如果子类重写了父类的虚函数（两个父类中都有的那个虚函数），所有父类虚函数表都要改变。 3.子类内存布局中父类按照其声明顺序排列 class Base1 { public: int base1; public: virtual void fun1() { cout &lt;&lt; &quot;base1::fun1()&quot; &lt;&lt; endl; } }; class Base2 { public: int base2; public: virtual void fun1() { cout &lt;&lt; &quot;base2::fun1()&quot; &lt;&lt; endl; } virtual void fun2() { cout &lt;&lt; &quot;base2::fun2()&quot; &lt;&lt; endl; } }; class Dervice :public Base1,public Base2 { public: int b; public: virtual void fun1() { cout &lt;&lt; &quot;Dervice::fun1()&quot; &lt;&lt; endl; } virtual void fun3() { cout &lt;&lt; &quot;Dervice::fun3()&quot; &lt;&lt; endl; } }; void test() { Base1 b1; Base2 b2; Dervice d; b1.base1 = 10; b2.base2 = 20; d.b = 30; d.base1 = 40; d.base2 = 50; } 验证输出： typedef void(*fun)(); fun *pp = (fun*)(*(int*)&amp;d); (*pp)(); pp++; (*pp)(); pp += 2; /*pp++;*/ (*pp)(); pp++; (*pp)(); 3.简单虚继承对象模型简单阐述： 1.虚继承的子类，如果本身定义了新的虚函数，则编译器为其生成一个新的vptr指针和和虚表，将其新定义的虚函数放进去，并且这个vptr位于对象的最前面 2.虚继承的子类也保留了父类的vptr和虚表 3.虚继承的子类有虚基类表指针vbptr，虚基类表中放的第一个是基类表指针到到对象首地址的偏移地址，后面的则放的是到第二个，第三个虚继承父类的偏移值。 class Base1 { public: int base1; public: virtual void fun1() { cout &lt;&lt; &quot;base1::fun1()&quot; &lt;&lt; endl; } virtual void fun2() { cout &lt;&lt; &quot;base1::fun2()&quot; &lt;&lt; endl; } }; class Dervice :virtual public Base1 { public: int b; public: virtual void fun1() { cout &lt;&lt; &quot;Dervice::fun1()&quot; &lt;&lt; endl; } virtual void fun3() { cout &lt;&lt; &quot;Dervice::fun3()&quot; &lt;&lt; endl; } }; void test() { Base1 b1; Dervice d; b1.base1 = 10; d.b = 20; d.base1 = 30; } 4.菱形继承对象模型菱形继承是多继承和虚继承的复合 class A { public: int _a; virtual void fun1() { cout &lt;&lt; “A::fun1” &lt;&lt; endl; } virtual void fun2() { cout &lt;&lt; “A::fun2” &lt;&lt; endl; } }; class B1 : virtual public A { public: int _b1; virtual void fun1() { cout &lt;&lt; “B1::fun1” &lt;&lt; endl; } virtual void fun3() { cout &lt;&lt; “B1::fun3” &lt;&lt; endl; } }; class B2 :virtual public A { public: int _b2; virtual void fun1() { cout &lt;&lt; &quot;B2::fun1&quot; &lt;&lt; endl; } virtual void fun4() { cout &lt;&lt; &quot;B2::fun4&quot; &lt;&lt; endl; } }; class C :public B1, public B2 { public: int _c; virtual void fun1() { cout &lt;&lt; &quot;C::fun1&quot; &lt;&lt; endl; } virtual void fun3() { cout &lt;&lt; &quot;C::fun3&quot; &lt;&lt; endl; } virtual void fun4() { cout &lt;&lt; &quot;C::fun4&quot; &lt;&lt; endl; } virtual void fun5() { cout &lt;&lt; &quot;C::fun5&quot; &lt;&lt; endl; } };void test() { cout &lt;&lt; &quot;A:&quot; &lt;&lt; sizeof(A) &lt;&lt; endl; cout &lt;&lt; &quot;B1:&quot; &lt;&lt; sizeof(B1) &lt;&lt; endl; cout &lt;&lt; &quot;B2:&quot; &lt;&lt; sizeof(B2) &lt;&lt; endl; cout &lt;&lt; &quot;C:&quot; &lt;&lt; sizeof(C) &lt;&lt; endl; A a; B1 b1; B2 b2; C c; a._a = 10; b1._a = 10; b1._b1 = 20; b2._b2 = 30; b2._a = 10; c._c = 40; c._a = 10; c._b1 = 20; c._b2 = 30; }","categories":[{"name":"c/c++","slug":"c-c","permalink":"http://yoursite.com/categories/c-c/"}],"tags":[{"name":"对象模型剖析","slug":"对象模型剖析","permalink":"http://yoursite.com/tags/对象模型剖析/"}]},{"title":"c陷阱与缺陷","slug":"c陷阱与缺陷","date":"2018-02-25T15:10:39.000Z","updated":"2018-02-26T06:53:49.448Z","comments":true,"path":"2018/02/25/c陷阱与缺陷/","link":"","permalink":"http://yoursite.com/2018/02/25/c陷阱与缺陷/","excerpt":"1.词法陷阱1.注意不要讲=和==混用，还有&amp;和&amp;&amp;是两回事，这个自己都要搞清楚。","text":"1.词法陷阱1.注意不要讲=和==混用，还有&amp;和&amp;&amp;是两回事，这个自己都要搞清楚。 2.词法分析使用的是贪心法，即读取一个字符以后，如果该字符可能组成一个符号，则继续读入下一个 字符，然后判断两个字符组成的字符串是否可以是一个符号的组成部分，如果是则继续读入依此类推。 3.用单引号引起来的一个字符实际上表示一个整数，整数值对应其ascii的值。而双引号引起来的字符串表示的是一个指向无名数组起始字符的指针，该数组被双引号引起来的字符和一个额外的’\\0’初始化 4.用int a=’abc’,则a的值是616263即每个字符对应的ascii的序列，用char a=’abc’，则a的值是c。即c将ab覆盖 5.a+++++b的解释，词法分析的贪心算法可以解得为a ++ ++ + b即((a++)++)+b,但是a++不能当左值，所以这应该是个错误的写法。 2.语法陷阱1. (*(void(*)())0)() 将0转换为函数指针（这个函数指针返回值为void参数为空），然后再调用这个函数.用typedef比较好理解 typedef void (*funcptr)(); (*(funcptr)0)(); 2. (void)(*signal(int,void(*)(int)))(int); signal的参数是整形和函数指针,返回值也是函数指针。用typedef比较好理解 typedef (void ) (*handler)(int); handler signal(int,handler); 3.else总是和同一对括号内最近的未匹配的if相结合。 3.语义陷阱1.如果我们在该使用指针的，确使用了数组名来替换，那么数组名就被当做指向该数组下标为0的元素的指针，所以我们可以这样写 int arr[]={1,2,3}; int *p=arr;//没有任何问题 注意在上述代码中我们并没有写成如下形式 int *p=&amp;arr; 其实这是不合法的操作，因为其类型不匹配，&amp;arr表示整个数组的指针其类型是int[3]*,所以如果你这么写了可能会被视为非法也可能被视为和p=arr一样的操作。 要强调的是：数组名除了在sizeof中以外，其余的所有情形都表示数组下标为0的元素的指针。 （上述问题的背景还限于一维数组，下面我们来讨论一下二维数组） 二维数组其实也是由一维数组组成的，只不过这个一维数组中的每个元素都是一个一维数组。所以如果你这么赋值是不对的 int arr[][3]={1,2,3,4,5,6,7,8,9} int *p=a;错 int **p=a;错 因为a表示数组下标为0的元素的指针，因为其实二维数组，其下标为0的元素也是个数组，所以a的类型就是int (*)[3],类型不兼容的！如果你这么使用了，虽然可能会通过编译，那么将失去了二维数组的意义，就是将二维数组变成了一维数组。我们正确的方式应该是这样的 int (*p)[3]=a; 2.对于指针的复制并不是复制指针的内容，而是使两个指针指向同一块区域，还有就是对字符串常量的修改是非法的！不能对空指针解引用！即使输出空指针的内容也是不合法的！ 3.关于数组越界的无限循环问题 int i, arr[10] = {0}; for (i = 0; i &lt;= 12; i++) { arr[i] = 0; printf(&quot;hello\\n&quot;); } 此代码会无限输出hello,原因如下 4.连接1.连接器：就是想编译汇编产生的若干目标模块，整和成一个被称为载入模块或者可执行程序文件的实体，该实体可以被操作系统直接执行。并且会检查是否有重命名的函数和变量。 2.为了避免发生不必要的麻烦，每个外部变量在所有源文件中只能定义一次。 3.使用static可以防止不同源文件的命名冲突问题，因为它限制了变量的作用域。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://yoursite.com/categories/读书笔记/"}],"tags":[{"name":"c陷阱与缺陷","slug":"c陷阱与缺陷","permalink":"http://yoursite.com/tags/c陷阱与缺陷/"}]},{"title":"链表随笔","slug":"链表随笔","date":"2018-02-25T09:29:58.000Z","updated":"2018-05-13T03:17:11.703Z","comments":true,"path":"2018/02/25/链表随笔/","link":"","permalink":"http://yoursite.com/2018/02/25/链表随笔/","excerpt":"此篇文章的主要内容是介绍一些有关链表的核心算法的总结。","text":"此篇文章的主要内容是介绍一些有关链表的核心算法的总结。 1.查找链表倒数第k个结点算法：此算法需要使用快慢指针，举个例子，加入需要查找倒数第3个结点。则指针先走k-1步，然后快慢指针一起走，当快指针指向最后一个结点的 时候，这个时候慢指针则指向我们要查找的倒数第3个结点。代码如下 int K_data(int location)//查找倒数第k个结点 { if (location &gt; 0)//不能小于0 { assert(_head); PNode fast = _head; PNode slow = _head; while (--location) { fast = fast-&gt;_next;// if (fast == NULL) exit(1);//不能超过结点个数 } while (fast-&gt;_next != NULL) { fast = fast-&gt;_next; slow = slow-&gt;_next; } return slow-&gt;_data; } else { exit(0);//直接退出 } } 强调： 1.注意判断查找点是否小于0或大于结点个数，还有结点是否为空 2.使快指针先走k-1步的方法是使用while循环并且使用前置– 3.快慢指针同时走的结束标志是fast-&gt;next！=null，这样就保证了fast刚好走到最后一个结点，如果使用fast!=null的话，则fast就会多走一步，同样慢指针也会多走，算法就会出错！ 2.查找链表中间结点算法：此方法和查找倒数第k个结点的算法思想是一样的，也是使用快慢指针，只不过这个很简单，即快指针走两步，慢指针走一步，这样当快指针到最后一个结点的位置的时候，慢指针则指向中间的结点。 int Find_Middle()//查找中间元素 { PNode fast = _head; PNode slow = _head; while (fast&amp;&amp;fast-&gt;_next) { fast = fast-&gt;_next-&gt;_next; slow = slow-&gt;_next; } return slow-&gt;_data; } 强调： 1.需要对链表进行判空，上述代码没有进行这个操作 2.while循环中的fast和fast-_next的位置步能放反不然就会出错，因为当fast走了两步以后，可能已经为空了，如果你放反了的话，则用空指next，肯定会报错的！ 3.链表逆置算法：逆置链表就是改变结点中的next的指向嘛，所以我们需要定义三个指针，一个指向当前需要逆置的结点的前一个结点，一个指向当前需要逆置的结点，一个指向当前需要逆置结点的后一个结点，然后将当前结点的指针指向前一个结点，然后三个指针同时向前走一步。直到遍历完整个链表注意这里的判断依据是指向需要逆置的结点的这个指针为空的时候则整个链表逆置完成。 void rever()//逆置链表 { if (_head == NULL) return; PNode pre =NULL; PNode next = NULL; PNode cur = _head; while (cur) { next = cur-&gt;_next;//首先让next先走一步 cur-&gt;_next = pre;//改变当前结点的_next pre = cur;//前一个结点走到当前结点 cur = next;//当前结点向前走 } _head = pre; } 强调： 1.注意while循环的指针的指向 2.开始的时候前指针和后指针都是指向空的。 3.最后记得将头指针更新，即最后一个结点变为头指针！ 4.合并两个有序链表合并后的链表也是有序链表算法：选取连个链表中头结点较小的作为头指针，定义一个指向最新的结点的指针，然后作为头指针的链表向后走一步，然后开始判断两个链表谁的结点数小，将其小补在新补的结点后面，然后链表向后走依次比较，直到有一个链表遍历完为止，然后需要判断一下是哪个链表遍历完了，将未遍历完的链表续在其后面。 PNode MergeList(List&lt;T&gt;&amp; s2) { PNode cur1=(*this)._head; PNode cur2 = s2._head; PNode head=NULL; PNode p = NULL; if (cur1 == NULL || cur2 == NULL) return NULL; if (cur1 == cur2) return cur1; if (cur1 != NULL&amp;&amp;cur2 == NULL) return cur1; if (cur2 != NULL&amp;&amp;cur1 == NULL) return cur2; if (cur1-&gt;_data &gt; cur2-&gt;_data)//选较小的作为新链表的头节点 { head = cur2; cur2 = cur2-&gt;_next; } else { head = cur1; cur1 = cur1-&gt;_next; } p = head;//p永远指向最新的结点 while (cur1&amp;&amp;cur2)//如果跳出循环至少有一个为空 { if (cur1-&gt;_data &gt; cur2-&gt;_data)// { p-&gt;_next = cur2; cur2 = cur2-&gt;_next; } else { p-&gt;_next = cur1; cur1 = cur1-&gt;_next; } p = p-&gt;_next; } if (cur1 == NULL) { p-&gt;_next = cur2; } else { p-&gt;_next = cur1; } return head; } 强调： 1.要有指向最新的结点的指针 2.需要对两个链表进行判空操作 5.判断链表是否带坏算法：这个也是需要两个指针，让快指针一次走两步慢指针一次走一步，然后判断快指针是否等于慢指针，等于的话直接返回，证明其带环，因为如果链表带环的话，他们一定会在环上相遇的，如果当fast等于null的时候则说明不带环 PNode JudgeisCircle()//判断链表是否带环 { PNode fast = _head; PNode slow = _head; while (fast&amp;&amp;fast-&gt;_next) { fast = fast-&gt;_next-&gt;_next; slow = slow-&gt;_next; if (fast == slow) return fast;//返回相遇点 } return NULL; } 强调： 1.循环的结束条件是fast&amp;&amp;fast-&gt;_next不等于null，并且顺序不能放反，原理和查找中间结点的理由一样。这样做是为了避免一个结点的时候走两步产生的错误 2.这里返回的是连个结点的相遇点，这个很重要，在求入口点的时候能够用的到 6.求带环链表的交点，即环的入口点算法：这个算法需要用到一点数学思维，先说结果吧即从像雨点到入口点的距离等于从起点到入口点的距离，下面我画图说明吧。下面给出代码： PNode EntrancePoint() { PNode cur = JudgeisCircle();//相遇点 PNode start = _head; while (cur != start) { cur = cur-&gt;_next; start = start-&gt;_next; } return cur; } 强调： 1.一定要将如何推倒这个结论的过程屡清楚 2.循环里面的内容是cur!=start 7.复杂链表的复制方法1：首先复制原链表，然后回去继续遍历原链表处理随机指针，假如处理第一个结点的随机指针的时候，从结点头部开始往后走，并记录从头走到随机结点位置的步数，然后根据步数在去更新复制链表中第一个结点的随机指针。因为每次处理一个结点都要从头开始，所以时间复杂度为O（N^2） 方法2：使用map（key,value）键值对，即在复制原来链表的时候，将原结点p和新结点p*加入map，依次类推，即每个原结点都对应一个新的结点，接下来遍历原链表去处理随机指针，那么假如第一个结点的随机指针指向第三个结点，那么根据map找个找到第三个结点，那么第三个结点对应的就是复制过来的第三个结点，那么只需要让复制过来的第一个结点指向找到的这个复制过来的第三个结点就可以了。 方法3：将复制的链表插在原结点后面，那么新结点的随机 指针将是原结点随机指针的下一个结点。","categories":[{"name":"数据结构随笔","slug":"数据结构随笔","permalink":"http://yoursite.com/categories/数据结构随笔/"}],"tags":[{"name":"链表","slug":"链表","permalink":"http://yoursite.com/tags/链表/"}]},{"title":"static详解","slug":"static详详解","date":"2018-02-25T05:15:28.000Z","updated":"2018-02-25T08:14:11.678Z","comments":true,"path":"2018/02/25/static详详解/","link":"","permalink":"http://yoursite.com/2018/02/25/static详详解/","excerpt":"static关键字是c和c++中都有的，只不过在c语言中它修饰局部变量，全局变量，和函数,在C++中它除了上述的功能外还可以修饰成员变量和成员函数。","text":"static关键字是c和c++中都有的，只不过在c语言中它修饰局部变量，全局变量，和函数,在C++中它除了上述的功能外还可以修饰成员变量和成员函数。 作用： 1.限定作用域 2.保持变量的内容持久化 1.C语言中的static1.修饰全局变量当一个进程的全局变量被static修饰以后，它就可以成为全局静态变量，全局静态变量和其他的全局变量的存储地是一样的，都是在.data段（存放已经初始化了的全局变量）或者.bss段（存放未初始化的全局变量），具体在哪里取决于你有没有初始化这个全局变量。在这里static的作用就是限定作用域了，即被修饰的全局变量只能在定义它的源文件内有效，其他源文件无法访问。 举例如下： .h文件 #include&lt;stdio.h&gt; extern int a;//声明全局变量 void fun();//声明函数 b.c文件 b.c文件 #include&quot;head.h&quot; static int a = 10;//静态全局变量，放在了.data段 void fun() { printf(&quot;%d\\n&quot;, a); } a.c文件 #include&quot;head.h&quot; int main() { printf(&quot;%d&quot;, a); return 0; } 在上述例子中，a.c文件无法使用源文件b.c的被static修饰的全局变量，编译会报错！但是如果在a.c中调用fun函数，在这个函数中使用a就可以，因为其作用域就在其定义的源文件，所以被自己的源文件内的函数访问是没有问题的。 2.修饰局部变量被static修饰的局部变量会被放在.data段，注意这里不是在.bss段，所以这个变量的生命周期在整个程序的生命周期中存在，尽管被放在.data段，但是同样它也只能被自己作用域内的函数或者变量所访问，不能被外界访问。同样static在这里的作用相当于改变了局部变量的生命周期。注意这里解释一下为什么放在了.data段，因为如果用户没有初始化的话，编译器会自动给其赋值0，所以放在了.data段。所以以后每次调用这个变量的时候相当于一直读取同一位置的这个变量，在这里注意和局部变量区别开来。就是因为这一特性，内含静态局部变量的函数是不可重入函数。 b.c文件 #include&quot;head.h&quot; void fun() { static int a; printf(&quot;%d\\n&quot;, a++); } a.c文件 #include&quot;head.h&quot; int main() { fun(); fun(); fun(); getchar(); return 0; } 这样的输出结果是0 1 2. 3.修饰函数这里static的作用也是限定了函数的作用，使被static修饰的函数不能被其他源文件所调用。这里很简单的就不举例子了。static函数可以很好的解决不同源文件中的函数重名的问题，因为每个函数的名字仅自己可见，肯定不会发生冲突的！ 2.C++中的staticC++的中的static关键字主要要讲的就是其修饰的成员变量和成员函数。 1.static修饰成员变量当一个类的成员变量被static关键字修饰以后就变成了静态数据成员了，静态数据成员有一下特点： 1.静态数据成员是类的成员而非对象的成员，它对于所有的对象是共享的，即无论对象被定义了多少个这个静态的成员只有一份，即只分配一次内存，这一样某种程度来说还节省了空间 2.静态成员存储在全局数据区，静态成员在定义的时候要分配空间，所以不不能再类声明的时候定义，需要在类外使用如下形式定义 int myclass::a=0; 3.静态成员同样遵守三个访问限制，同时即使不定义类对象也可以对它进行操作 4.静态成员的作用就是在多个对象拥有同一个属性的时候，使用它可以方便操作，改变一次就全部改变，使用静态数据成员也不存在和其他全局变量的名字冲突，因为其有访问限制属性所以可以实现信息隐藏。 2.static修饰成员函数1.同样静态成员函数也是被所有对象共享，并且他没有this指针，所以他不能访问成员函数和成员变量只能访问静态成员函数和静态成员变量，但是非静态成员函数可以访问静态成员函数和静态变量 2.因为没有this指针，其速度相对于成员函数来说会快一些 3.调用静态成员函数的方式和调用静音胎成员的方式差不多，可以使用.，-&gt;和::","categories":[{"name":"c/c++","slug":"c-c","permalink":"http://yoursite.com/categories/c-c/"}],"tags":[{"name":"static","slug":"static","permalink":"http://yoursite.com/tags/static/"}]},{"title":"堆随笔","slug":"堆随笔","date":"2018-02-24T13:59:15.000Z","updated":"2018-05-13T03:17:03.902Z","comments":true,"path":"2018/02/24/堆随笔/","link":"","permalink":"http://yoursite.com/2018/02/24/堆随笔/","excerpt":"这篇博客的主要内容是对于堆的一些总结","text":"这篇博客的主要内容是对于堆的一些总结 1.创建堆首先堆这个对象的框架你要能够很清楚的记得，即私有成员是vecotr的容器比较好，还有一个就是size用来记录堆中的元素，这样可以用来盛放外界数组的元素，其构造函数主要的作用就是将外界数组元素保存到自己的容器中，然后如果你想创建小堆则用向下调整法，这样堆最开始的创建的就结束了。 2.向下调整法此方法用于建立小堆的时候可以使用，首先数组是根据完全二叉树的方式在数组中存储的，所以我们可以借助树的模型来简化我们的操作，首先需要找到倒数第一个叶子结点的父结点从这里开始调整,这个父结点的位置怎么找呢？举个例子找到父结点的位置以后开始进行调整，首先需要根据父结点在找出其孩子结点的位置，这个很好找就是父结点的位置*2+1就是孩子结点的位置，因为是向下调整发，所以需要判断左右孩子哪个大，找出最小的那个孩子，然后让他和父结点去比较，然后继续向下走继续比较，依此类推。再次我给出代码 // void _Adjustdown(size_t parent) // { // size_t child = parent * 2 + 1;//保存左孩子 // while (child &lt; _size)//在这里的条件给成child&lt;size比较好 // { // Compare s;//定义仿函数对象 // //if (child + 1&lt;_size&amp;&amp;_array[child] &gt;_array[child + 1])//找最小的孩子 // // ++child; // if (child + 1 &lt; _size&amp;&amp;s(_array[child], _array[child + 1]))//找最小的孩子 // ++child; // if (/*child&lt;_size*/s(_array[parent], _array[child])) // { // swap(_array[parent], _array[child]); // parent = child; // child = parent * 2 + 1; // } // else//已经交换好了 // { // break; // } // } // } 在上述代码我想想强调的只有两点： 1.在判断左右孩子的时候当心父结点是单支结点，所以要判断chil+1&lt;size 2.在判断父结点和孩子结点谁小的时候，要当心孩子就结点超出size的大小，需要判断child=0;i–);来循环调整 3.堆的插入操作堆的插入使用的是向上调整法，因为插入之前堆已经建立好了则意味着调整好了，所以插入一个新结点以后意味着，插入的那棵和那棵树的祖先可能会不满足堆的性质，所以只需要顺着那一个方向一直向上调整就可以了，和向下调整法的差别不大，不过这个没有for循环，因为不需要挨个调整呀。给出代码： // void _Adjustup(int child)//向上调整 // { // int parent =(child-1)&gt;&gt;1; // while (parent&gt;=0) // { // if (Compare()(_array[parent], _array[child]))//使用简单的比较器 // { // swap(_array[parent], _array[child]); // child = parent; // parent = (child - 1) &gt;&gt; 1; // } // else // break; // } // } // //}; 在这个算法中我要强调的就是： 1.首先要根据孩子结点找到父结点2.循环的条件是parent&gt;=0 3.堆的pop堆的pop使用的算法有点乾坤大挪移的感觉，将堆顶元素和最后一个元素互换，然后使size–，然后使用向下调整法就解决了，是不是很奇妙 // void Heap_del()//删除堆顶的元素 // { // if (_array.empty()) // return;//空的话直接返回 // int size_last = _size - 1; // swap(_array[0], _array[size_last]); // _array.pop_back();//弹出去 // _size--; // if (_size &gt; 0) // { // _Adjustdown(0); // } // } 重点：1.从头开始调整，但是不需要循环调整！这里就牵扯到了你的向下调整的for循环是写在哪里了。 4.堆排序堆排序的思路也很简单主要是利用堆的性质，如果你要升序排序的话建立大堆，你要降序排序的话建立小堆，然后和删除的思路基本一致，首尾互换然后size– // void Head_Sort() // { // while (_size &gt; 1) // { // swap(_array[0], _array[_size - 1]); // //这里和删除的区别只是不弹出 // --_size; // _Adjustdown(0); // } // } 注意：这里和删除的区别就是不用弹出元素.还有就是break可以直接换成return; 5.优先级队列如何用堆来建立优先级队列呢？首选封装优先级队列的对象里面的成员就是堆，然后只需要使用堆的插入和删除就可以实现优先级队列了。 关于堆的优化就是加入仿函数。","categories":[{"name":"数据结构随笔","slug":"数据结构随笔","permalink":"http://yoursite.com/categories/数据结构随笔/"}],"tags":[{"name":"heap","slug":"heap","permalink":"http://yoursite.com/tags/heap/"}]},{"title":"sizeof详解","slug":"sizeof详解","date":"2018-02-24T07:42:50.000Z","updated":"2018-02-24T13:14:35.584Z","comments":true,"path":"2018/02/24/sizeof详解/","link":"","permalink":"http://yoursite.com/2018/02/24/sizeof详解/","excerpt":"首先对于sizeof做一个简单的介绍让你知道什么是sizoef，从心里对它有个大致的印象。","text":"首先对于sizeof做一个简单的介绍让你知道什么是sizoef，从心里对它有个大致的印象。 定义： sizeof是C/C++中的一个操作符（operator），简单的说其作用就是返回一个对象或者类型所占的内存字节数。 MSDN上的解释为：The sizeof keyword gives the amount of storage, in bytes, associated with a variable or a type(including aggregate types). This keyword returns a value of type size_t. 其返回值类型为size_t，在头文件stddef.h中定义。这是一个依赖于编译系统的值，一般定义为 typedef unsigned int size_t; 好了现在你应该对于sizoef有了一个大概的认识了，现在我们来看看sizoef的基本用法： sizeof(对象）； sizeof(类型）； sizeof 对象；//这个主意和1区分 对于上面的三种用法，其实你只需要掌握sizoef()的这种用法就够了，另外一个自己知道就可以了，因为根本没人去那么用。好了划重点了：记住sizeof计算对象的大小也是转换成对应的类型来计算的，这句话的言外之意就是不同的对象如果类型一样的话，sizoef计算的值是一样的。 用法： 接下来我就所说sizeof的一些应用场景和用法 1 sizeof对一个表达式求值注意：对于表达式求值，编译器会根据表达式结果的类型来计算，一般不会对表达式进行计算 举例如下： int fun(int a) { cout &lt;&lt; &quot;fun::sizoef&quot; &lt;&lt; endl; return a; } void test() { cout &lt;&lt; sizeof(fun(4)); } 此例子的输出就是 4，不会输出fun::sizeof,证明函数没有执行。 2.sizoef的常量性sizeof的计算是放生在编译期间的，所以其可以被当做常量表达式使用 举例如下： int n=10; int arr[sizeof(n)]; 3.sizeof和指针变量注意：当sizoef的对象是指针变量的时候，它的结果和指针所指的内容没有任何的关系，所以在32位计算机中指针变量是4,64位计算机中是8 4.sizeof和数组sizoef的数组的值等于数组所占的内存字节数，这里我在CSDN的博客写的很清楚了，感兴趣的可以自己去看http://blog.csdn.net/it_iverson/article/details/74733426 这里还要强调的一个重点就是数组传参的时候。 void fun(int arr[]) { cout &lt;&lt; sizeof(arr); } void test() { int arr[10] = { 0 }; fun(arr); } 这里的sizoef的输出是4而不是40，因为在函数的形参那里arr已经不是数组类型了，而是蜕变成了指针。相当于int *arr,因为数组是传址传参的，只是把数组首地址传过去了，所以接受地址的自然就是指针变量了，那么正如上文所说，指针变量的大小和其指向的内容没有关系，所以大小为4 5.sizeof和结构体这里主要强调的是结构体内存对其的一些知识在CSDN的博客中也有详细说明 http://blog.csdn.net/it_iverson/article/details/74790127 6.含有位字段的结构体 注意：单独的位字段成员不能被sizeof求值 那么什么是为字段呢？ 位字段是C语言中一种存储结构，不同于一般结构体的是它在定义成员的时候需要指定成员所占的位数。主要应用于嵌入开发 如下： struct stu { char a : 4;//占4位 char b : 3;//占3位 char c : 8;//占8位 };//大小为两个字节 在这里要注意的是： 1.如果相邻的位字段的类型相同，且其位数之和小于自身类型数，则后面的字段和紧挨着前面的字段存储，直到这个不能容纳为止 2.如果相邻的位字段类型相同，且其位数之和大于自身的类型数，则后面的字段从新的存储单元开始。 3.如果相邻位字段类型不同，则根据编译器的不同，是否采取压缩存储就不一定了。 4.如果位字段之间穿插着非为字段，则不进行压缩存储 7.sizeof和联合体因为联合体是重叠式存储，各成员共享一段内存，所以整个联合体的大小就是最大成员所占的空间的大小，假如联合体中有一个结构体成员，那么这个联合体的大小就是这个结构体的大小。","categories":[{"name":"c/c++","slug":"c-c","permalink":"http://yoursite.com/categories/c-c/"}],"tags":[{"name":"sizeof","slug":"sizeof","permalink":"http://yoursite.com/tags/sizeof/"}]}]}